################################################################################
# --------------- Base type for model:
################################################################################
"""
AbstractFittedModel

Base type for fitted models.
"""
abstract type AbstractFittedModel end

# -------- Linear Logistic Model:
# This is an example of how to construct a AbstractFittedModel subtype:
"""
    LogisticModel(W::Matrix,b::AbstractArray)

Constructs a logistic classifier based on arrays containing coefficients `w` and constant terms `b`.

# Examples

```julia-repl
w = [1.0 -2.0] # estimated coefficients
b = [0] # estimated constant
ùë¥ = CounterfactualExplanations.Models.LogisticModel(w, b);
```

See also: 
- [`logits(ùë¥::LogisticModel, X::AbstractArray)`](@ref)
- [`probs(ùë¥::LogisticModel, X::AbstractArray)`](@ref)
"""
struct LogisticModel <: AbstractFittedModel
    W::Matrix
    b::AbstractArray
end

# What follows are the two required outer methods:
"""
    logits(ùë¥::LogisticModel, X::AbstractArray)

Computes logits as `WX+b`.

# Examples

```julia-repl
using CounterfactualExplanations.Models
w = [1.0 -2.0] # estimated coefficients
b = [0] # estimated constant
ùë¥ = LogisticModel(w, b);
x = [1,1]
logits(ùë¥, x)
```

See also [`LogisticModel(W::Matrix,b::AbstractArray)`](@ref).
"""
logits(ùë¥::LogisticModel, X::AbstractArray) = ùë¥.W*X .+ ùë¥.b

"""
    probs(ùë¥::LogisticModel, X::AbstractArray)

Computes predictive probabilities from logits as `œÉ(WX+b)` where 'œÉ' is the [sigmoid function](https://en.wikipedia.org/wiki/Sigmoid_function). 

# Examples

```julia-repl
using CounterfactualExplanations.Models
w = [1.0 -2.0] # estimated coefficients
b = [0] # estimated constant
ùë¥ = LogisticModel(w, b);
x = [1,1]
probs(ùë¥, x)
```

See also [`LogisticModel(W::Matrix,b::AbstractArray)`](@ref).
"""
probs(ùë¥::LogisticModel, X::AbstractArray) = NNlib.œÉ.(logits(ùë¥, X))

# -------- Bayesian model:
"""
    BayesianLogisticModel(Œº::Matrix,Œ£::Matrix)

Constructs a Bayesian logistic classifier based on maximum a posteriori (MAP) estimates `Œº` (coefficients including constant term(s)) and `Œ£` (covariance matrix). 

# Examples

```julia-repl
using Random, LinearAlgebra
Random.seed!(1234)
Œº = [0 1.0 -2.0] # MAP coefficients
Œ£ = Symmetric(reshape(randn(9),3,3).*0.1 + UniformScaling(1.0)) # MAP covariance matrix
ùë¥ = CounterfactualExplanations.Models.BayesianLogisticModel(Œº, Œ£);
```

See also:
- [`logits(ùë¥::BayesianLogisticModel, X::AbstractArray)`](@ref)
- [`probs(ùë¥::BayesianLogisticModel, X::AbstractArray)`](@ref)
"""
struct BayesianLogisticModel <: AbstractFittedModel
    Œº::Matrix
    Œ£::Matrix
    BayesianLogisticModel(Œº, Œ£) = length(Œº)^2 != length(Œ£) ? throw(DimensionMismatch("Dimensions of Œº and its covariance matrix Œ£ do not match.")) : new(Œº, Œ£)
end

# What follows are the three required outer methods:
"""
    logits(ùë¥::BayesianLogisticModel, X::AbstractArray)

Computes logits as `Œº[1·µÄ X·µÄ]·µÄ`.

# Examples

```julia-repl
using CounterfactualExplanations.Models
using Random, LinearAlgebra
Random.seed!(1234)
Œº = [0 1.0 -2.0] # MAP coefficients
Œ£ = Symmetric(reshape(randn(9),3,3).*0.1 + UniformScaling(1.0)) # MAP covariance matrix
ùë¥ = BayesianLogisticModel(Œº, Œ£);
x = [1,1]
logits(ùë¥, x)
```

See also [`BayesianLogisticModel(Œº::Matrix,Œ£::Matrix)`](@ref)
"""
function logits(ùë¥::BayesianLogisticModel, X::AbstractArray)
    if !isa(X, AbstractMatrix)
        X = reshape(X, length(X), 1)
    end
    X = vcat(ones(size(X)[2])', X) # add for constant
    return ùë¥.Œº * X
end

"""
    probs(ùë¥::BayesianLogisticModel, X::AbstractArray)

Computes predictive probabilities using a Probit approximation. 

# Examples

```julia-repl
using CounterfactualExplanations.Models
using Random, LinearAlgebra
Random.seed!(1234)
Œº = [0 1.0 -2.0] # MAP coefficients
Œ£ = Symmetric(reshape(randn(9),3,3).*0.1 + UniformScaling(1.0)) # MAP covariance matrix
ùë¥ = BayesianLogisticModel(Œº, Œ£);
x = [1,1]
probs(ùë¥, x)
```

See also [`BayesianLogisticModel(Œº::Matrix,Œ£::Matrix)`](@ref)
"""
function probs(ùë¥::BayesianLogisticModel, X::AbstractArray)
    Œº = ùë¥.Œº # MAP mean vector
    Œ£ = ùë¥.Œ£ # MAP covariance matrix
    # Inner product:
    z = logits(ùë¥, X)
    # Probit approximation
    if !isa(X, AbstractMatrix)
        X = reshape(X, length(X), 1)
    end
    X = vcat(ones(size(X)[2])', X) # add for constant
    v = [X[:,n]'Œ£*X[:,n] for n=1:size(X)[2]]    
    Œ∫ = 1 ./ sqrt.(1 .+ œÄ/8 .* v) # scaling factor for logits
    z = Œ∫' .* z
    # Compute probabilities
    p = NNlib.œÉ.(z)
    p = size(p)[2] == 1 ? vec(p) : p
    return p
end