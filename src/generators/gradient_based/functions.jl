
################################################################################
# --------------- Base type for gradient-based generator:
################################################################################
"""
    AbstractGradientBasedGenerator

An abstract type that serves as the base type for gradient-based counterfactual generators. 
"""
abstract type AbstractGradientBasedGenerator <: AbstractGenerator end

# ----- Julia models -----
"""
    âˆ‚â„“(generator::AbstractGradientBasedGenerator, M::Union{Models.LogisticModel, Models.BayesianLogisticModel}, counterfactual_state::CounterfactualState.State)

The default method to compute the gradient of the loss function at the current counterfactual state for gradient-based generators. It assumes that `Zygote.jl` has gradient access.
"""
function âˆ‚â„“(generator::AbstractGradientBasedGenerator, M::Models.Models.AbstractDifferentiableModel, counterfactual_state::CounterfactualState.State)
    gradient(() -> â„“(generator, counterfactual_state), Flux.params(counterfactual_state.sâ€²))[counterfactual_state.sâ€²]
end

# ----- RTorch model -----
using RCall
"""
    âˆ‚â„“(generator::AbstractGradientBasedGenerator, M::Models.RTorchModel, counterfactual_state::CounterfactualState.State)

The default method to compute the gradient of the loss function at the current counterfactual state for gradient-based generators. It assumes that `Zygote.jl` has gradient access.
"""
function âˆ‚â„“(generator::AbstractGradientBasedGenerator, M::Models.RTorchModel, counterfactual_state::CounterfactualState.State) 
    nn = M.model
    s_cf = counterfactual_state.sâ€²
    t = counterfactual_state.target_encoded
    Interoperability.prep_R_session()
    R"""
    x <- torch_tensor($s_cf, requires_grad=TRUE)
    t <- torch_tensor($t, dtype=torch_float())
    output <- $nn(x)
    obj_loss <- nnf_binary_cross_entropy_with_logits(output,t)
    obj_loss$backward()
    """
    grad = rcopy(R"as_array(x$grad)")
    return grad
end

# ----- PyTorch model -----
using PyCall
"""
    âˆ‚â„“(generator::AbstractGradientBasedGenerator, M::Models.RTorchModel, counterfactual_state::CounterfactualState.State)

The default method to compute the gradient of the loss function at the current counterfactual state for gradient-based generators. It assumes that `Zygote.jl` has gradient access.
"""
function âˆ‚â„“(generator::AbstractGradientBasedGenerator, M::Models.PyTorchModel, counterfactual_state::CounterfactualState.State) 
    py"""
    import torch
    from torch import nn
    """
    nn = M.model
    sâ€² = counterfactual_state.sâ€²
    t = counterfactual_state.target_encoded
    x = reshape(sâ€², 1, length(sâ€²))
    py"""
    x = torch.Tensor($x)
    x.requires_grad = True
    t = torch.Tensor($[t]).squeeze()
    output = $nn(x).squeeze()
    obj_loss = nn.BCEWithLogitsLoss()(output,t)
    obj_loss.backward()
    """
    grad = vec(py"x.grad.detach().numpy()")
    return grad
end

"""
    âˆ‚h(generator::AbstractGradientBasedGenerator, counterfactual_state::CounterfactualState.State)

The default method to compute the gradient of the complexity penalty at the current counterfactual state for gradient-based generators. It assumes that `Zygote.jl` has gradient access.
"""
âˆ‚h(generator::AbstractGradientBasedGenerator, counterfactual_state::CounterfactualState.State) = gradient(() -> h(generator, counterfactual_state), Flux.params(counterfactual_state.sâ€²))[counterfactual_state.sâ€²]

# Gradient:
"""
    âˆ‡(generator::AbstractGradientBasedGenerator, M::Models.AbstractDifferentiableModel, counterfactual_state::CounterfactualState.State)

The default method to compute the gradient of the counterfactual search objective for gradient-based generators. It simply computes the weighted sum over partial derivates. It assumes that `Zygote.jl` has gradient access.
"""
âˆ‡(generator::AbstractGradientBasedGenerator, M::Models.AbstractDifferentiableModel, counterfactual_state::CounterfactualState.State) = âˆ‚â„“(generator, M, counterfactual_state) + generator.Î» * âˆ‚h(generator, counterfactual_state)

"""
    generate_perturbations(generator::AbstractGradientBasedGenerator, counterfactual_state::CounterfactualState.State)

The default method to generate feature perturbations for gradient-based generators through simple gradient descent.
"""
function generate_perturbations(generator::AbstractGradientBasedGenerator, counterfactual_state::CounterfactualState.State) 
    ğ â‚œ = âˆ‡(generator, counterfactual_state.M, counterfactual_state) # gradient
    Î”sâ€² = - (generator.Ïµ .* ğ â‚œ) # gradient step
    return Î”sâ€²
end

"""
    mutability_constraints(generator::AbstractGradientBasedGenerator, counterfactual_state::CounterfactualState.State)

The default method to return mutability constraints that are dependent on the current counterfactual search state. For generic gradient-based generators, no state-dependent constraints are added.
"""
function mutability_constraints(generator::AbstractGradientBasedGenerator, counterfactual_state::CounterfactualState.State)
    mutability = counterfactual_state.params[:mutability]
    return mutability # no additional constraints for GenericGenerator
end 

"""
    conditions_satisified(generator::AbstractGradientBasedGenerator, counterfactual_state::CounterfactualState.State)

The default method to check if the all conditions for convergence of the counterfactual search have been satisified for gradient-based generators.
"""
function conditions_satisified(generator::AbstractGradientBasedGenerator, counterfactual_state::CounterfactualState.State)
    ğ â‚œ = âˆ‡(generator, counterfactual_state.M, counterfactual_state)
    status = all(abs.(ğ â‚œ) .< generator.Ï„) 
    return status
end

##################################################
# Specific Generators
##################################################

# Baseline
include("GenericGenerator.jl") # Wachter et al. (2017)
include("GreedyGenerator.jl") # Schut et al. (2021)
include("DiCEGenerator.jl") # Mothilal et al. (2020)

# Latent space
"""
    AbstractLatentSpaceGenerator

An abstract type that serves as the base type for gradient-based counterfactual generators that search in a latent space. 
"""
abstract type AbstractLatentSpaceGenerator <: AbstractGradientBasedGenerator end

include("REVISEGenerator.jl") # Joshi et al. (2019)