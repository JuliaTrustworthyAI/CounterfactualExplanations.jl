{
  "hash": "6ec31cf8b2a9dee20a60e82f19766dbf",
  "result": {
    "engine": "jupyter",
    "markdown": "```@meta\nCurrentModule = CounterfactualExplanations \n```\n\n\n\n# Categorical Features\n\nTo illustrate how data is preprocessed under the hood, we consider a simple toy dataset with three categorical features (`name`, `grade` and `sex`) and one continuous feature (`age`):\n\n::: {.cell execution_count=2}\n``` {.julia .cell-code}\nX = (\n    name=categorical([\"Danesh\", \"Lee\", \"Mary\", \"John\"]),\n    grade=categorical([\"A\", \"B\", \"A\", \"C\"], ordered=true),\n    sex=categorical([\"male\",\"female\",\"male\",\"male\"]),\n    height=[1.85, 1.67, 1.5, 1.67],\n)\nschema(X)\n```\n:::\n\n\nCategorical features are expected to be one-hot or dummy encoded. To this end, we could use `MLJ`, for example:\n\n::: {.cell execution_count=3}\n``` {.julia .cell-code}\nhot = OneHotEncoder()\nmach = fit!(machine(hot, X))\nW = transform(mach, X)\nschema(W)\n```\n\n::: {.cell-output .cell-output-display execution_count=4}\n```\n┌──────────────┬────────────┬─────────┐\n│ names        │ scitypes   │ types   │\n├──────────────┼────────────┼─────────┤\n│ name__Danesh │ Continuous │ Float64 │\n│ name__John   │ Continuous │ Float64 │\n│ name__Lee    │ Continuous │ Float64 │\n│ name__Mary   │ Continuous │ Float64 │\n│ grade__A     │ Continuous │ Float64 │\n│ grade__B     │ Continuous │ Float64 │\n│ grade__C     │ Continuous │ Float64 │\n│ sex__female  │ Continuous │ Float64 │\n│ sex__male    │ Continuous │ Float64 │\n│ height       │ Continuous │ Float64 │\n└──────────────┴────────────┴─────────┘\n```\n:::\n:::\n\n\nThe matrix that will be perturbed during the counterfactual search looks as follows:\n\n::: {.cell execution_count=4}\n``` {.julia .cell-code}\nX = permutedims(MLJBase.matrix(W))\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```\n10×4 Matrix{Float64}:\n 1.0   0.0   0.0  0.0\n 0.0   0.0   0.0  1.0\n 0.0   1.0   0.0  0.0\n 0.0   0.0   1.0  0.0\n 1.0   0.0   1.0  0.0\n 0.0   1.0   0.0  0.0\n 0.0   0.0   0.0  1.0\n 0.0   1.0   0.0  0.0\n 1.0   0.0   1.0  1.0\n 1.85  1.67  1.5  1.67\n```\n:::\n:::\n\n\nThe `CounterfactualData` constructor takes two optional arguments that can be used to specify the indices of categorical and continuous features. If nothing is supplied, all features are assumed to be continuous. For categorical features, the constructor expects and array of arrays of integers (`Vector{Vector{Int}}`) where each subarray includes the indices of a all one-hot encoded rows related to a single categorical feature. In the example above, the `name` feature is one-hot encoded across rows 1, 2 and 3 of `X`.\n\n::: {.cell execution_count=5}\n``` {.julia .cell-code}\nfeatures_categorical = [\n    [1,2,3,4],    # name\n    [5,6,7],    # grade\n    [8,9]       # sex\n]\nfeatures_continuous = [10]\n```\n:::\n\n\nWe propose the following simple logic for reconstructing categorical encodings after perturbations:\n\n- For one-hot encoded features with multiple classes, choose the maximum.\n- For binary features, clip the perturbed value to fall into $[0,1]$ and round to the nearest of the two integers.\n\n::: {.cell execution_count=6}\n``` {.julia .cell-code}\nfunction reconstruct_cat_encoding(x)\n    map(features_categorical) do cat_group_index\n        if length(cat_group_index) > 1\n            x[cat_group_index] = Int.(x[cat_group_index] .== maximum(x[cat_group_index]))\n            if sum(x[cat_group_index]) > 1\n                ties = findall(x[cat_group_index] .== 1)\n                _x = zeros(length(x[cat_group_index]))\n                winner = rand(ties,1)[1]\n                _x[winner] = 1\n                x[cat_group_index] = _x\n            end\n        else\n            x[cat_group_index] = [round(clamp(x[cat_group_index][1],0,1))]\n        end\n    end\n    return x\nend\n```\n:::\n\n\nLet's look at a few simple examples to see how this function works. Firstly, consider the case of perturbing a single element:\n\n::: {.cell execution_count=7}\n``` {.julia .cell-code}\nx = X[:,1]\nx[1] = 1.1\nx\n```\n\n::: {.cell-output .cell-output-display execution_count=8}\n```\n10-element Vector{Float64}:\n 1.1\n 0.0\n 0.0\n 0.0\n 1.0\n 0.0\n 0.0\n 0.0\n 1.0\n 1.85\n```\n:::\n:::\n\n\nThe reconstructed one-hot-encoded vector will look like this: \n\n::: {.cell execution_count=8}\n``` {.julia .cell-code}\nreconstruct_cat_encoding(x)\n```\n\n::: {.cell-output .cell-output-display execution_count=9}\n```\n10-element Vector{Float64}:\n 1.0\n 0.0\n 0.0\n 0.0\n 1.0\n 0.0\n 0.0\n 0.0\n 1.0\n 1.85\n```\n:::\n:::\n\n\nNext, consider the case of perturbing multiple elements:\n\n::: {.cell execution_count=9}\n``` {.julia .cell-code}\nx[2] = 1.1\nx[3] = -1.2\nx\n```\n\n::: {.cell-output .cell-output-display execution_count=10}\n```\n10-element Vector{Float64}:\n  1.0\n  1.1\n -1.2\n  0.0\n  1.0\n  0.0\n  0.0\n  0.0\n  1.0\n  1.85\n```\n:::\n:::\n\n\nThe reconstructed one-hot-encoded vector will look like this: \n\n::: {.cell execution_count=10}\n``` {.julia .cell-code}\nreconstruct_cat_encoding(x)\n```\n\n::: {.cell-output .cell-output-display execution_count=11}\n```\n10-element Vector{Float64}:\n 0.0\n 1.0\n 0.0\n 0.0\n 1.0\n 0.0\n 0.0\n 0.0\n 1.0\n 1.85\n```\n:::\n:::\n\n\nFinally, let's introduce a tie:\n\n::: {.cell execution_count=11}\n``` {.julia .cell-code}\nx[1] = 1.0\nx\n```\n\n::: {.cell-output .cell-output-display execution_count=12}\n```\n10-element Vector{Float64}:\n 1.0\n 1.0\n 0.0\n 0.0\n 1.0\n 0.0\n 0.0\n 0.0\n 1.0\n 1.85\n```\n:::\n:::\n\n\nThe reconstructed one-hot-encoded vector will look like this: \n\n::: {.cell execution_count=12}\n``` {.julia .cell-code}\nreconstruct_cat_encoding(x)\n```\n\n::: {.cell-output .cell-output-display execution_count=13}\n```\n10-element Vector{Float64}:\n 0.0\n 1.0\n 0.0\n 0.0\n 1.0\n 0.0\n 0.0\n 0.0\n 1.0\n 1.85\n```\n:::\n:::\n\n\n",
    "supporting": [
      "categorical_files"
    ],
    "filters": []
  }
}