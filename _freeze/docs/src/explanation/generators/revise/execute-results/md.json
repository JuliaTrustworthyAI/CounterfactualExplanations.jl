{
  "hash": "ea650a3a1eae80dee50fcb8f6299a814",
  "result": {
    "engine": "jupyter",
    "markdown": "```@meta\nCurrentModule = CounterfactualExplanations \n```\n\n\n\n# `REVISEGenerator`\n\nREVISE is a Latent Space generator introduced by @joshi2019realistic.\n\n## Description\n\nThe current consensus in the literature is that Counterfactual Explanations should be realistic: the generated counterfactuals should look like they were generated by the data-generating process (DGP) that governs the problem at hand. With respect to Algorithmic Recourse, it is certainly true that counterfactuals should be realistic in order to be actionable for individuals.^[In general, we believe that there may be a trade-off between creating counterfactuals that respect the DGP vs. counterfactuals reflect the behaviour of the black-model in question - both accurately and complete.] To address this need, researchers have come up with various approaches in recent years. Among the most popular approaches is **Latent Space Search**, which was first proposed in @joshi2019realistic: instead of traversing the feature space directly, this approach relies on a separate generative model that learns a latent space representation of the DGP. Assuming the generative model is well-specified, access to the learned latent embeddings of the data comes with two **advantages**:\n\n1. Since the learned DGP is encoded in the latent space, the generated counterfactuals will respect the learned representation of the data. In practice, this means that counterfactuals will be realistic.\n2. The latent space is typically a compressed (i.e. lower dimensional) version of the feature space. This makes the counterfactual search less costly.\n\nThere are also certain **disadvantages** though:\n\n1. Learning generative models is (typically) an expensive task, which may well outweigh the benefits associated with utlimately traversing a lower dimensional space. \n2. If the generative model is poorly specified, this will affect the quality of the counterfactuals.^[We believe that there is another potentially crucial disadvantage of relying on a separate generative model: it reallocates the task of learning realistic explanations for the data from the black-box model to the generative model.]\n\nAnyway, traversing latent embeddings is a powerful idea that may be very useful depending on the specific context. This tutorial introduces the concept and how it is implemented in this package. \n\n## Usage\n\nThe approach can be used in our package as follows:\n\n::: {.cell execution_count=2}\n``` {.julia .cell-code}\ngenerator = REVISEGenerator()\nce = generate_counterfactual(x, target, counterfactual_data, M, generator)\nplot(ce)\n```\n\n::: {.cell-output .cell-output-display execution_count=3}\n![](revise_files/figure-commonmark/cell-3-output-1.svg){}\n:::\n:::\n\n\n### Worked 2D Examples\n\nBelow we load 2D data and train a VAE on it and plot the original samples against their reconstructions.\n\n::: {.cell execution_count=3}\n``` {.julia .cell-code}\n# output: true\n\ncounterfactual_data = CounterfactualData(load_overlapping()...)\nX = counterfactual_data.X\ny = counterfactual_data.y\ninput_dim = size(X, 1)\nusing CounterfactualExplanations.GenerativeModels: VAE, train!, reconstruct\nvae = VAE(input_dim; nll=Flux.Losses.mse, epochs=100, λ=0.01, latent_dim=2, hidden_dim=32)\nflux_training_params.verbose = true\ntrain!(vae, X)\nX̂ = reconstruct(vae, X)[1]\np0 = scatter(X[1, :], X[2, :], color=:blue, label=\"Original\", xlab=\"x₁\", ylab=\"x₂\")\nscatter!(X̂[1, :], X̂[2, :], color=:orange, label=\"Reconstructed\", xlab=\"x₁\", ylab=\"x₂\")\np1 = scatter(X[1, :], X̂[1, :], color=:purple, label=\"\", xlab=\"x₁\", ylab=\"x̂₁\")\np2 = scatter(X[2, :], X̂[2, :], color=:purple, label=\"\", xlab=\"x₂\", ylab=\"x̂₂\")\nplt2 = plot(p1,p2, layout=(1,2), size=(800, 400))\nplot(p0, plt2, layout=(2,1), size=(800, 600))\n```\n:::\n\n\nNext, we train a simple MLP for the classification task. Then we determine a target and factual class for our counterfactual search and select a random factual instance to explain.\n\n::: {.cell execution_count=4}\n``` {.julia .cell-code}\nM = fit_model(counterfactual_data, :MLP)\ntarget = 2\nfactual = 1\nchosen = rand(findall(predict_label(M, counterfactual_data) .== factual))\nx = select_factual(counterfactual_data, chosen)\n```\n:::\n\n\nFinally, we generate and visualize the generated counterfactual:\n\n::: {.cell execution_count=5}\n``` {.julia .cell-code}\n# Search:\ngenerator = REVISEGenerator()\nce = generate_counterfactual(x, target, counterfactual_data, M, generator)\nplot(ce)\n```\n\n::: {.cell-output .cell-output-display execution_count=6}\n![](revise_files/figure-commonmark/cell-6-output-1.svg){}\n:::\n:::\n\n\n### 3D Example\n\nTo illustrate the notion of Latent Space search, let's look at an example involving 3-dimensional input data, which we can still visualize. The code chunk below loads the data and implements the counterfactual search. \n\n::: {.cell execution_count=6}\n``` {.julia .cell-code}\n# Data and Classifier:\ncounterfactual_data = CounterfactualData(load_blobs(k=3)...)\nX = counterfactual_data.X\nys = counterfactual_data.output_encoder.labels.refs\nM = fit_model(counterfactual_data, :MLP)\n\n# Randomly selected factual:\nx = select_factual(counterfactual_data,rand(1:size(counterfactual_data.X,2)))\ny = predict_label(M, counterfactual_data, x)[1]\ntarget = counterfactual_data.y_levels[counterfactual_data.y_levels .!= y][1]\n\n# Generate recourse:\nce = generate_counterfactual(x, target, counterfactual_data, M, generator)\n```\n:::\n\n\nThe figure below demonstrates the idea of searching counterfactuals in a lower-dimensional latent space: on the left, we can see the counterfactual search in the 3-dimensional feature space, while on the right we can see the corresponding search in the latent space.\n\n::: {.cell execution_count=7}\n\n::: {.cell-output .cell-output-display execution_count=8}\n![](revise_files/figure-commonmark/cell-8-output-1.svg){}\n:::\n:::\n\n\n## MNIST data\n\nLet's carry the ideas introduced above over to a more complex example. The code below loads MNIST data as well as a pre-trained classifier and generative model for the data.\n\n::: {.cell execution_count=8}\n``` {.julia .cell-code}\nusing CounterfactualExplanations.Models: load_mnist_mlp, load_mnist_ensemble, load_mnist_vae\ncounterfactual_data = CounterfactualData(load_mnist()...)\nX, y = CounterfactualExplanations.DataPreprocessing.unpack_data(counterfactual_data)\ninput_dim, n_obs = size(counterfactual_data.X)\nM = load_mnist_mlp()\nvae = load_mnist_vae()\n```\n:::\n\n\n::: {.cell execution_count=9}\n\n::: {.cell-output .cell-output-display .cell-output-markdown execution_count=10}\nThe F1-score of our pre-trained image classifier on test data is: 0.94\n\n:::\n:::\n\n\nBefore continuing, we supply the pre-trained generative model to our data container:\n\n::: {.cell execution_count=10}\n``` {.julia .cell-code}\ncounterfactual_data.input_encoder = vae # assign generative model\n```\n:::\n\n\nNow let's define a factual and target label:\n\n::: {.cell execution_count=11}\n``` {.julia .cell-code}\n# Randomly selected factual:\nRandom.seed!(2023)\nfactual_label = 8\nx = reshape(X[:,rand(findall(predict_label(M, counterfactual_data).==factual_label))],input_dim,1)\ntarget = 3\nfactual = predict_label(M, counterfactual_data, x)[1]\n```\n:::\n\n\n::: {.cell execution_count=12}\n\n::: {.cell-output .cell-output-display .cell-output-markdown execution_count=13}\nUsing REVISE, we are going to turn a randomly drawn 8 into a 3.\n\n:::\n:::\n\n\nThe API call is the same as always:\n\n::: {.cell execution_count=13}\n``` {.julia .cell-code}\nγ = 0.95\nconv = \n  CounterfactualExplanations.Convergence.DecisionThresholdConvergence(decision_threshold=γ)\n# Define generator:\ngenerator = REVISEGenerator(opt=Flux.Adam(0.1))\n# Generate recourse:\nce = generate_counterfactual(x, target, counterfactual_data, M, generator; convergence=conv)\n```\n:::\n\n\nThe chart below shows the results:\n\n::: {.cell execution_count=14}\n\n::: {.cell-output .cell-output-display execution_count=15}\n![](revise_files/figure-commonmark/cell-15-output-1.svg){}\n:::\n:::\n\n\n## References\n\n",
    "supporting": [
      "revise_files"
    ],
    "filters": []
  }
}