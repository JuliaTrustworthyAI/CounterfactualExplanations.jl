{
  "hash": "f391a6f60fb995805a0182b9b2a43754",
  "result": {
    "engine": "jupyter",
    "markdown": "```@meta\nCurrentModule = CounterfactualExplanations \n```\n\n\n\n# Counterfactual Generators [@id generators_explanation]\n\nCounterfactual generators form the very core of this package. The [`generator_catalogue`](@ref) can be used to inspect the available generators:\n\n::: {.cell execution_count=2}\n``` {.julia .cell-code}\ngenerator_catalogue\n```\n\n::: {.cell-output .cell-output-display execution_count=3}\n```\nDict{Symbol, Any} with 11 entries:\n  :gravitational   => GravitationalGenerator\n  :growing_spheres => GrowingSpheresGenerator\n  :revise          => REVISEGenerator\n  :clue            => CLUEGenerator\n  :probe           => ProbeGenerator\n  :dice            => DiCEGenerator\n  :feature_tweak   => FeatureTweakGenerator\n  :claproar        => ClaPROARGenerator\n  :wachter         => WachterGenerator\n  :generic         => GenericGenerator\n  :greedy          => GreedyGenerator\n```\n:::\n:::\n\n\nThe following sections provide brief descriptions of all of them.\n\n## Gradient-based Counterfactual Generators\n\nAt the time of writing, all generators are gradient-based: that is, counterfactuals are searched through gradient descent. In @altmeyer2023endogenous we lay out a general methodological framework that can be applied to all of these generators:\n\n```math\n\\begin{aligned}\n\\mathbf{s}^\\prime &= \\arg \\min_{\\mathbf{s}^\\prime \\in \\mathcal{S}} \\left\\{  {\\text{yloss}(M(f(\\mathbf{s}^\\prime)),y^*)}+ \\lambda {\\text{cost}(f(\\mathbf{s}^\\prime)) }  \\right\\} \n\\end{aligned} \n```\n\n\"Here $\\mathbf{s}^\\prime=\\left\\{s_k^\\prime\\right\\}_K$ is a $K$-dimensional array of counterfactual states and $f: \\mathcal{S} \\mapsto \\mathcal{X}$ maps from the counterfactual state space to the feature space.\" [@altmeyer2023endogenous]\n\nFor most generators, the state space *is* the feature space ($f$ is the identity function) and the number of counterfactuals $K$ is one. Latent Space generators instead search counterfactuals in some latent space $\\mathcal{S}$. In this case, $f$ corresponds to the decoder part of the generative model, that is the function that maps back from the latent space to inputs.\n\n## References\n\n",
    "supporting": [
      "overview_files"
    ],
    "filters": []
  }
}