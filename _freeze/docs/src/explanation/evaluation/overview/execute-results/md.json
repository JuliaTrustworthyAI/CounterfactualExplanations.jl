{
  "hash": "fee04a3c332a5fd65ed3fbcc2b4f8df4",
  "result": {
    "engine": "jupyter",
    "markdown": "```@meta\nCurrentModule = CounterfactualExplanations \n```\n\n\n\n# Evaluation\n\nEvaluation of counterfactual explanations is an integral part of the counterfactual explanation process. It is important to evaluate the quality of the generated counterfactual explanations to ensure that they are meaningful and useful. The [tutorial](@ref evaluation) provides an overview of the evaluation metrics and methods that can be used to evaluate counterfactual explanations. In this part of the documentation, we dive deeper into specific evaluation metrics and methods that can be used to evaluate counterfactual explanations.\n\n",
    "supporting": [
      "overview_files"
    ],
    "filters": []
  }
}