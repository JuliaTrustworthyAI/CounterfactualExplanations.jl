---
format: 
  commonmark:
    variant: -raw_html
    wrap: none
    self-contained: true
crossref:
  fig-prefix: Figure
  tbl-prefix: Table
bibliography: https://raw.githubusercontent.com/pat-alt/bib/main/bib.bib
output: asis
execute: 
  eval: false
  echo: true
jupyter: julia-1.6
---

``` @meta
CurrentModule = CounterfactualExplanations
```

# From üê± to üê∂ - a motivating example

Suppose we have a sample of cats and dogs with information about two features: height and tail length. Based on these two features we have trained two black box classifiers to distinguish between cats and dogs: firstly, an artificial neural network with weight regularization and secondly, that same neural network but its Bayesian counterpart (@fig-predictive below). One individual cat ‚Äì let‚Äôs call her Kitty üê± ‚Äì is friends with a lot of cool dogs and wants to be part of that group. Let's see how we can generate counterfactual paths for her.

```{julia}
#| echo: false
using Pkg.Artifacts
img_path = joinpath(artifact_path(artifact_hash("cats_dogs_images", "../../Artifacts.toml")), "cats_dogs_images")
if !isdir("www")
    mkdir("www")
end
[cp(joinpath(img_path, file), joinpath("www", file), force=true) for file in readdir(img_path)];
```

```{julia}
#| echo: false
using Images
mlp = load(joinpath(img_path, "predictive_mlp.png"))
laplace = load(joinpath(img_path, "predictive_laplace.png"))
img = mosaic(mlp, laplace, ncol=2)
save("www/predictive.png",img)
```

![Classification for toy dataset of cats and dogs. The contour indicates confidence in predicted labels. Left: MLP with weight regularization. Right: That same MLP, but with Laplace approximation for posterior predictive.](www/predictive.png){#fig-predictive}

### From basic principles ...

Counterfactual search happens in the feature space: we are interested in understanding how we need to change üê±'s attributes in order to change the output of the black-box classifier. We will start with the first model, that relies on simple plugin estimates to produce its predictions. The model was pre-trained using Flux.jl and can be loaded as follows:

```{julia}
using CounterfactualExplanations.Data: cats_dogs_model
model = cats_dogs_model()
```

In order to make the Flux.jl model compatible with CounterfactualExplanations.jl we need to run the following (more on this in the [models tutorial](https://www.paltmeyer.com/CounterfactualExplanations.jl/dev/tutorials/models/)):

```{julia}
import CounterfactualExplanations.Models: logits, probs # import functions in order to extend

# Step 1)
struct NeuralNetwork <: Models.AbstractFittedModel
    model::Any
end

# Step 2)
logits(ùë¥::NeuralNetwork, X::AbstractArray) = ùë¥.model(X)
probs(ùë¥::NeuralNetwork, X::AbstractArray)= œÉ.(logits(ùë¥, X))
ùë¥ = NeuralNetwork(model);
```

Let `x` be the 2D-feature vector describing Kitty üê±. Based on those features she is currently labelled as `y = 0.0`. We have set the target label to `1.0` and the desired confidence in the prediction to `Œ≥ = 0.75`.  Now we can use the `GenericGenerator` for our counterfactual search as follows:

```{julia}
generator = GenericGenerator(0.01,2,1e-5,:logitbinarycrossentropy,nothing)
counterfactual = generate_counterfactual(generator, x, ùë¥, target, Œ≥)
```

The `GenericGenerator` implements the search algorithm first proposed by @wachter2017counterfactual. The resulting counterfactual path is shown in @fig-recourse-mlp below. We can see that üê± travels through the feature space until she reaches a destination where the black-box model predicts that with a probability of more than $75\%$ she is actually a dog. Her counterfactual self is in the target class so the algorithmic recourse objective is satisfied. We have also gained an intuitive understanding of how the black-model arrives at its decisions: increasing height and decreasing tail length both raise the predicted probability that üê± is actually a dog. 

![Classification for toy dataset of cats and dogs. The contour indicates confidence in predicted labels. Left: MLP with weight regularization. Right: That same MLP, but with Laplace approximation for posterior predictive.](www/recourse_mlp.gif){#fig-recourse-mlp}

### ... towards realistic counterfactuals.

The generic search above yielded a counterfactual sample that is still quite distinct from all other individuals in the target class. While we successfully fooled the black-box model, a human might look at üê±'s counterfactual self and get a little suspicious. One of the requirements for algorithmic recourse is that counterfactuals are realistic and unambigous. A straight-forward way to meet this requirement is to generate counterfactuals by implicitly minimizing predictive uncertainty [@schut2021generating]. The simple neural network does not incorporate uncertainty, but its Bayesian counterpart does: note how in @fig-predictive above the contours for the Bayesian neural network (Laplace) fan out away from the sample. As before we will be using a pre-trained model. Laplace approximation was implemented using [BayesLaplace.jl](https://www.paltmeyer.com/BayesLaplace.jl/dev/) (see [here](https://towardsdatascience.com/go-deep-but-also-go-bayesian-ab25efa6f7b) for an introduction). The pre-trained Bayesian model can be loaded as follows:

```{julia}
using CounterfactualExplanations.Data: cats_dogs_laplace
la = cats_dogs_laplace()
```

As before we need to make the model compatible with CounterfactualExplanations.jl:

```{julia}
# Step 1)
struct LaplaceNeuralNetwork <: Models.AbstractFittedModel
    la::BayesLaplace.LaplaceRedux
end

# Step 2)
logits(ùë¥::LaplaceNeuralNetwork, X::AbstractArray) = ùë¥.la.model(X)
probs(ùë¥::LaplaceNeuralNetwork, X::AbstractArray)= BayesLaplace.predict(ùë¥.la, X)
ùë¥·¥∏ = LaplaceNeuralNetwork(la);
```

Using the same target and desired confidence `Œ≥` as above we finally use the `GreedyGenerator` generator for our counterfactual search:

```{julia}
generator = GreedyGenerator(0.1,20,:logitbinarycrossentropy,nothing)
counterfactual = generate_counterfactual(generator, x, ùë¥·¥∏, target, Œ≥); # generate recourse
```

The `GreedyGenerator` implements the approach proposed in @schut2021generating: by maximizing the predicted probability of the Bayesian model in @fig-recourse-laplace below, we implicitly minimize the predictive uncertainty around the counterfactual. This way we end up generating a counterfactual that looks more like the individuals üê∂ in the target class and is therefore more realistic. 

![Classification for toy dataset of cats and dogs. The contour indicates confidence in predicted labels. Left: MLP with weight regularization. Right: That same MLP, but with Laplace approximation for posterior predictive.](www/recourse_laplace.gif){#fig-recourse-laplace}

### References

