<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Motivating example Â· CounterfactualExplanations.jl</title><script data-outdated-warner src="../assets/warner.js"></script><link rel="canonical" href="https://pat-alt.github.io/CounterfactualExplanations.jl/cats_dogs/"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.039/juliamono-regular.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.11/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">CounterfactualExplanations.jl</a></span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li class="is-active"><a class="tocitem" href>Motivating example</a></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../tutorials/binary/">Binary target</a></li><li><a class="tocitem" href="../tutorials/models/">Models</a></li><li><a class="tocitem" href="../tutorials/multi/">Multi-class target</a></li><li><a class="tocitem" href="../tutorials/loss/">Loss functions</a></li></ul></li><li><span class="tocitem">More examples</span><ul><li><input class="collapse-toggle" id="menuitem-4-1" type="checkbox"/><label class="tocitem" for="menuitem-4-1"><span class="docs-label">Image data</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../examples/image/MNIST/">MNIST</a></li></ul></li></ul></li><li><a class="tocitem" href="../reference/">Reference</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Motivating example</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Motivating example</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/pat-alt/CounterfactualExplanations.jl/blob/master/docs/src/cats_dogs.md#" title="Edit on GitHub"><span class="docs-icon fab">ï‚›</span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="From-to-a-motivating-example"><a class="docs-heading-anchor" href="#From-to-a-motivating-example">From ğŸ± to ğŸ¶ - a motivating example</a><a id="From-to-a-motivating-example-1"></a><a class="docs-heading-anchor-permalink" href="#From-to-a-motivating-example" title="Permalink"></a></h1><p>Suppose we have a sample of cats and dogs with information about two features: height and tail length. Based on these two features we have trained two black box classifiers to distinguish between cats and dogs: firstly, an artificial neural network with weight regularization and secondly, that same neural network but its Bayesian counterpart (<a href="#fig-predictive">FigureÂ 1</a> below). One individual cat â€“ letâ€™s call her Kitty ğŸ± â€“ is friends with a lot of cool dogs and wants to be part of that group. Letâ€™s see how we can generate counterfactual paths for her.</p><p><img src="../www/predictive.png" alt="Figure 1: Classification for toy dataset of cats and dogs. The contour indicates confidence in predicted labels. Left: MLP with weight regularization. Right: That same MLP, but with Laplace approximation for posterior predictive."/></p><h3 id="From-basic-principles-â€¦"><a class="docs-heading-anchor" href="#From-basic-principles-â€¦">From basic principles â€¦</a><a id="From-basic-principles-â€¦-1"></a><a class="docs-heading-anchor-permalink" href="#From-basic-principles-â€¦" title="Permalink"></a></h3><p>Counterfactual search happens in the feature space: we are interested in understanding how we need to change ğŸ±â€™s attributes in order to change the output of the black-box classifier. We will start with the first model, that relies on simple plugin estimates to produce its predictions. The model was pre-trained using Flux.jl and can be loaded as follows:</p><pre><code class="language-julia hljs">using CounterfactualExplanations.Data: cats_dogs_model
model = cats_dogs_model()</code></pre><p>In order to make the Flux.jl model compatible with CounterfactualExplanations.jl we need to run the following (more on this in the <a href="https://www.paltmeyer.com/CounterfactualExplanations.jl/dev/tutorials/models/">models tutorial</a>):</p><pre><code class="language-julia hljs">import CounterfactualExplanations.Models: logits, probs # import functions in order to extend

# Step 1)
struct NeuralNetwork &lt;: Models.FittedModel
    model::Any
end

# Step 2)
logits(ğ‘´::NeuralNetwork, X::AbstractArray) = ğ‘´.model(X)
probs(ğ‘´::NeuralNetwork, X::AbstractArray)= Ïƒ.(logits(ğ‘´, X))
ğ‘´ = NeuralNetwork(model);</code></pre><p>Let <code>xÌ…</code> be the 2D-feature vector describing Kitty ğŸ±. Based on those features she is currently labelled as <code>yÌ… = 0.0</code>. We have set the target label to <code>1.0</code> and the desired confidence in the prediction to <code>Î³ = 0.75</code>. Now we can use the <code>GenericGenerator</code> for our counterfactual search as follows:</p><pre><code class="language-julia hljs">generator = GenericGenerator(0.01,2,1e-5,:logitbinarycrossentropy,nothing)
recourse = generate_counterfactual(generator, xÌ…, ğ‘´, target, Î³)</code></pre><p>The <code>GenericGenerator</code> implements the search algorithm first proposed by Wachter, Mittelstadt, and Russell (2017). The resulting counterfactual path is shown in <a href="#fig-recourse-mlp">FigureÂ 2</a> below. We can see that ğŸ± travels through the feature space until she reaches a destination where the black-box model predicts that with a probability of \&gt;75% she is actually a dog. Her counterfactual self is in the target class so the algorithmic recourse objective is satisfied. We have also gained an intuitive understanding of how the black-model arrives at its decisions: increasing height and decreasing tail length both raise the predicted probability that ğŸ± is actually a dog.</p><p><img src="../www/recourse_mlp.gif" alt="Figure 2: Classification for toy dataset of cats and dogs. The contour indicates confidence in predicted labels. Left: MLP with weight regularization. Right: That same MLP, but with Laplace approximation for posterior predictive."/></p><h3 id="â€¦-towards-realistic-counterfactuals."><a class="docs-heading-anchor" href="#â€¦-towards-realistic-counterfactuals.">â€¦ towards realistic counterfactuals.</a><a id="â€¦-towards-realistic-counterfactuals.-1"></a><a class="docs-heading-anchor-permalink" href="#â€¦-towards-realistic-counterfactuals." title="Permalink"></a></h3><p>The generic search above yielded a counterfactual sample that is still quite distinct from all other individuals in the target class. While we successfully fooled the black-box model, a human might look at ğŸ±â€™s counterfactual self and get a little suspicious. One of the requirements for algorithmic recourse is that counterfactuals are realistic and unambigous. A straight-forward way to meet this requirement is to generate counterfactuals by implicitly minimizing predictive uncertainty (Schut et al. 2021). The simple neural network does not incorporate uncertainty, but its Bayesian counterpart does: note how in <a href="#fig-predictive">FigureÂ 1</a> above the contours for the Bayesian neural network (Laplace) fan out away from the sample. As before we will be using a pre-trained model. Laplace approximation was implemented using <a href="https://www.paltmeyer.com/BayesLaplace.jl/dev/">BayesLaplace.jl</a> (see <a href="https://towardsdatascience.com/go-deep-but-also-go-bayesian-ab25efa6f7b">here</a> for an introduction). The pre-trained Bayesian model can be loaded as follows:</p><pre><code class="language-julia hljs">using CounterfactualExplanations.Data: cats_dogs_laplace
la = cats_dogs_laplace()</code></pre><p>As before we need to make the model compatible with CounterfactualExplanations.jl:</p><pre><code class="language-julia hljs"># Step 1)
struct LaplaceNeuralNetwork &lt;: Models.FittedModel
    la::BayesLaplace.LaplaceRedux
end

# Step 2)
logits(ğ‘´::LaplaceNeuralNetwork, X::AbstractArray) = ğ‘´.la.model(X)
probs(ğ‘´::LaplaceNeuralNetwork, X::AbstractArray)= BayesLaplace.predict(ğ‘´.la, X)
ğ‘´á´¸ = LaplaceNeuralNetwork(la);</code></pre><p>Using the same target and desired confidence <code>Î³</code> as above we finally use the <code>GreedyGenerator</code> generator for our counterfactual search:</p><pre><code class="language-julia hljs">generator = GreedyGenerator(0.1,20,:logitbinarycrossentropy,nothing)
recourse = generate_counterfactual(generator, xÌ…, ğ‘´á´¸, target, Î³); # generate recourse</code></pre><p>The <code>GreedyGenerator</code> implements the approach proposed in Schut et al. (2021): by maximizing the predicted probability of the Bayesian model in <a href="#fig-recourse-laplace">FigureÂ 3</a> below, we implicitly minimize the predictive uncertainty around the counterfactual. This way we end up generating a counterfactual that looks more like the individuals ğŸ¶ in the target class and is therefore more realistic.</p><p><img src="../www/recourse_laplace.gif" alt="Figure 3: Classification for toy dataset of cats and dogs. The contour indicates confidence in predicted labels. Left: MLP with weight regularization. Right: That same MLP, but with Laplace approximation for posterior predictive."/></p><h3 id="References"><a class="docs-heading-anchor" href="#References">References</a><a id="References-1"></a><a class="docs-heading-anchor-permalink" href="#References" title="Permalink"></a></h3><p>Schut, Lisa, Oscar Key, Rory Mc Grath, Luca Costabello, Bogdan Sacaleanu, Yarin Gal, et al. 2021. â€œGenerating Interpretable Counterfactual Explanations by Implicit Minimisation of Epistemic and Aleatoric Uncertainties.â€ In <em>International Conference on Artificial Intelligence and Statistics</em>, 1756â€“64. PMLR.</p><p>Wachter, Sandra, Brent Mittelstadt, and Chris Russell. 2017. â€œCounterfactual Explanations Without Opening the Black Box: Automated Decisions and the GDPR.â€ <em>Harv. JL &amp; Tech.</em> 31: 841.</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../">Â« Home</a><a class="docs-footer-nextpage" href="../tutorials/binary/">Binary target Â»</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.15 on <span class="colophon-date" title="Monday 21 March 2022 07:33">Monday 21 March 2022</span>. Using Julia version 1.7.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
