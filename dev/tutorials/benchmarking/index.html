<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Benchmarking Explanations · CounterfactualExplanations.jl</title><meta name="title" content="Benchmarking Explanations · CounterfactualExplanations.jl"/><meta property="og:title" content="Benchmarking Explanations · CounterfactualExplanations.jl"/><meta property="twitter:title" content="Benchmarking Explanations · CounterfactualExplanations.jl"/><meta name="description" content="Documentation for CounterfactualExplanations.jl."/><meta property="og:description" content="Documentation for CounterfactualExplanations.jl."/><meta property="twitter:description" content="Documentation for CounterfactualExplanations.jl."/><meta property="og:url" content="https://juliatrustworthyai.github.io/CounterfactualExplanations.jl/stable/tutorials/benchmarking/"/><meta property="twitter:url" content="https://juliatrustworthyai.github.io/CounterfactualExplanations.jl/stable/tutorials/benchmarking/"/><link rel="canonical" href="https://juliatrustworthyai.github.io/CounterfactualExplanations.jl/stable/tutorials/benchmarking/"/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.svg" alt="CounterfactualExplanations.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">CounterfactualExplanations.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">🏠 Home</a></li><li><span class="tocitem">🫣 Tutorials</span><ul><li><a class="tocitem" href="../">Overview</a></li><li><a class="tocitem" href="../simple_example/">Simple Example</a></li><li><a class="tocitem" href="../whistle_stop/">Whiste-Stop Tour</a></li><li><a class="tocitem" href="../data_preprocessing/">Handling Data</a></li><li><a class="tocitem" href="../data_catalogue/">Data Catalogue</a></li><li><a class="tocitem" href="../models/">Handling Models</a></li><li><a class="tocitem" href="../model_catalogue/">Model Catalogue</a></li><li><a class="tocitem" href="../generators/">Handling Generators</a></li><li><a class="tocitem" href="../evaluation/">Evaluating Explanations</a></li><li class="is-active"><a class="tocitem" href>Benchmarking Explanations</a><ul class="internal"><li><a class="tocitem" href="#Post-Hoc-Benchmarking"><span>Post Hoc Benchmarking</span></a></li><li><a class="tocitem" href="#Ad-Hoc-Benchmarking"><span>Ad Hoc Benchmarking</span></a></li><li><a class="tocitem" href="#Multiple-Datasets"><span>Multiple Datasets</span></a></li></ul></li><li><a class="tocitem" href="../parallelization/">Parallelization</a></li><li><a class="tocitem" href="../convergence/">Convergence</a></li></ul></li><li><span class="tocitem">🤓 Explanation</span><ul><li><a class="tocitem" href="../../explanation/">Overview</a></li><li><a class="tocitem" href="../../explanation/architecture/">Package Architecture</a></li><li><input class="collapse-toggle" id="menuitem-3-3" type="checkbox"/><label class="tocitem" for="menuitem-3-3"><span class="docs-label">Generators</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../explanation/generators/overview/">Overview</a></li><li><a class="tocitem" href="../../explanation/generators/generic/">Generic</a></li><li><a class="tocitem" href="../../explanation/generators/clap_roar/">ClaPROAR</a></li><li><a class="tocitem" href="../../explanation/generators/clue/">CLUE</a></li><li><a class="tocitem" href="../../explanation/generators/dice/">DiCE</a></li><li><a class="tocitem" href="../../explanation/generators/feature_tweak/">FeatureTweak</a></li><li><a class="tocitem" href="../../explanation/generators/gravitational/">Gravitational</a></li><li><a class="tocitem" href="../../explanation/generators/greedy/">Greedy</a></li><li><a class="tocitem" href="../../explanation/generators/growing_spheres/">GrowingSpheres</a></li><li><a class="tocitem" href="../../explanation/generators/probe/">PROBE</a></li><li><a class="tocitem" href="../../explanation/generators/revise/">REVISE</a></li><li><a class="tocitem" href="../../explanation/generators/mint/">MINT</a></li><li><a class="tocitem" href="../../explanation/generators/tcrex/">T-CREx</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-3-4" type="checkbox"/><label class="tocitem" for="menuitem-3-4"><span class="docs-label">Evaluation</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../explanation/evaluation/overview/">Overview</a></li><li><a class="tocitem" href="../../explanation/evaluation/faithfulness/">Plausibility and Faithfulness</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-3-5" type="checkbox"/><label class="tocitem" for="menuitem-3-5"><span class="docs-label">Optimisers</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../explanation/optimisers/overview/">Overview</a></li><li><a class="tocitem" href="../../explanation/optimisers/jsma/">JSMA</a></li></ul></li><li><a class="tocitem" href="../../explanation/categorical/">Categorical Features</a></li></ul></li><li><span class="tocitem">🫡 How-To ...</span><ul><li><a class="tocitem" href="../../how_to_guides/">Overview</a></li><li><a class="tocitem" href="../../how_to_guides/custom_generators/">... add custom generators</a></li><li><a class="tocitem" href="../../how_to_guides/custom_models/">... add custom models</a></li></ul></li><li><span class="tocitem">⛓️ Extensions</span><ul><li><a class="tocitem" href="../../extensions/">Overview</a></li><li><a class="tocitem" href="../../extensions/neurotree/">NeuroTrees</a></li><li><a class="tocitem" href="../../extensions/laplace_redux/">LaplaceRedux</a></li></ul></li><li><a class="tocitem" href="../../reference/">🧐 Reference</a></li><li><a class="tocitem" href="../../contribute/">🛠 Contribute</a></li><li><a class="tocitem" href="../../assets/resources/">📚 Additional Resources</a></li><li><a class="tocitem" href="../../release-notes/">Release Notes</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">🫣 Tutorials</a></li><li class="is-active"><a href>Benchmarking Explanations</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Benchmarking Explanations</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/juliatrustworthyai/CounterfactualExplanations.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/juliatrustworthyai/CounterfactualExplanations.jl/blob/main/docs/src/tutorials/benchmarking.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Performance-Benchmarks"><a class="docs-heading-anchor" href="#Performance-Benchmarks">Performance Benchmarks</a><a id="Performance-Benchmarks-1"></a><a class="docs-heading-anchor-permalink" href="#Performance-Benchmarks" title="Permalink"></a></h1><p>In the previous tutorial, we have seen how counterfactual explanations can be evaluated. An important follow-up task is to compare the performance of different counterfactual generators is an important task. Researchers can use benchmarks to test new ideas they want to implement. Practitioners can find the right counterfactual generator for their specific use case through benchmarks. In this tutorial, we will see how to run benchmarks for counterfactual generators.</p><h2 id="Post-Hoc-Benchmarking"><a class="docs-heading-anchor" href="#Post-Hoc-Benchmarking">Post Hoc Benchmarking</a><a id="Post-Hoc-Benchmarking-1"></a><a class="docs-heading-anchor-permalink" href="#Post-Hoc-Benchmarking" title="Permalink"></a></h2><p>We begin by continuing the discussion from the previous tutorial: suppose you have generated multiple counterfactual explanations for multiple individuals, like below:</p><pre><code class="language-julia hljs"># Factual and target:
n_individuals = 5
ids = rand(findall(predict_label(M, counterfactual_data) .== factual), n_individuals)
xs = select_factual(counterfactual_data, ids)
ces = generate_counterfactual(xs, target, counterfactual_data, M, generator; num_counterfactuals=5)</code></pre><p>You may be interested in comparing the outcomes across individuals. To benchmark the various counterfactual explanations using default evaluation measures, you can simply proceed as follows:</p><pre><code class="language-julia hljs">bmk = benchmark(ces)</code></pre><p>Under the hood, the <a href="../../reference/#CounterfactualExplanations.Evaluation.benchmark-Tuple{Vector{CounterfactualExplanation}}"><code>benchmark(counterfactual_explanations::Vector{CounterfactualExplanation})</code></a> uses <a href="../../reference/#CounterfactualExplanations.Evaluation.evaluate"><code>CounterfactualExplanations.Evaluation.evaluate(ce::CounterfactualExplanation)</code></a> to generate a <a href="../../reference/#CounterfactualExplanations.Evaluation.Benchmark"><code>Benchmark</code></a> object, which contains the evaluation in its most granular form as a <code>DataFrame</code>.</p><h3 id="Working-with-Benchmarks"><a class="docs-heading-anchor" href="#Working-with-Benchmarks">Working with <code>Benchmark</code>s</a><a id="Working-with-Benchmarks-1"></a><a class="docs-heading-anchor-permalink" href="#Working-with-Benchmarks" title="Permalink"></a></h3><p>For convenience, the <code>DataFrame</code> containing the evaluation can be returned by simply calling the <code>Benchmark</code> object. By default, the aggregated evaluation measures across <code>id</code> (in line with the default behaviour of <code>evaluate</code>).</p><pre><code class="language-julia hljs">bmk()</code></pre><pre><code class="nohighlight hljs">15×7 DataFrame
 Row │ sample                                variable    value    generator    ⋯
     │ Base.UUID                             String      Float64  Symbol       ⋯
─────┼──────────────────────────────────────────────────────────────────────────
   1 │ 239104d0-f59f-11ee-3d0c-d1db071927ff  distance    3.17243  GradientBase ⋯
   2 │ 239104d0-f59f-11ee-3d0c-d1db071927ff  redundancy  0.0      GradientBase
   3 │ 239104d0-f59f-11ee-3d0c-d1db071927ff  validity    1.0      GradientBase
   4 │ 2398b3e2-f59f-11ee-3323-13d53fb7e75b  distance    3.07148  GradientBase
   5 │ 2398b3e2-f59f-11ee-3323-13d53fb7e75b  redundancy  0.0      GradientBase ⋯
   6 │ 2398b3e2-f59f-11ee-3323-13d53fb7e75b  validity    1.0      GradientBase
   7 │ 2398b916-f59f-11ee-3f13-bd00858a39af  distance    3.62159  GradientBase
   8 │ 2398b916-f59f-11ee-3f13-bd00858a39af  redundancy  0.0      GradientBase
   9 │ 2398b916-f59f-11ee-3f13-bd00858a39af  validity    1.0      GradientBase ⋯
  10 │ 2398bce8-f59f-11ee-37c1-ef7c6de27b6b  distance    2.62783  GradientBase
  11 │ 2398bce8-f59f-11ee-37c1-ef7c6de27b6b  redundancy  0.0      GradientBase
  12 │ 2398bce8-f59f-11ee-37c1-ef7c6de27b6b  validity    1.0      GradientBase
  13 │ 2398c08a-f59f-11ee-175b-81c155750752  distance    2.91985  GradientBase ⋯
  14 │ 2398c08a-f59f-11ee-175b-81c155750752  redundancy  0.0      GradientBase
  15 │ 2398c08a-f59f-11ee-175b-81c155750752  validity    1.0      GradientBase
                                                               4 columns omitted</code></pre><p>To retrieve the granular dataset, simply do:</p><pre><code class="language-julia hljs">bmk(agg=nothing)</code></pre><pre><code class="nohighlight hljs">75×8 DataFrame
 Row │ sample                                num_counterfactual  variable    v ⋯
     │ Base.UUID                             Int64               String      F ⋯
─────┼──────────────────────────────────────────────────────────────────────────
   1 │ 239104d0-f59f-11ee-3d0c-d1db071927ff                   1  distance    3 ⋯
   2 │ 239104d0-f59f-11ee-3d0c-d1db071927ff                   2  distance    3
   3 │ 239104d0-f59f-11ee-3d0c-d1db071927ff                   3  distance    3
   4 │ 239104d0-f59f-11ee-3d0c-d1db071927ff                   4  distance    3
   5 │ 239104d0-f59f-11ee-3d0c-d1db071927ff                   5  distance    3 ⋯
   6 │ 239104d0-f59f-11ee-3d0c-d1db071927ff                   1  redundancy  0
   7 │ 239104d0-f59f-11ee-3d0c-d1db071927ff                   2  redundancy  0
   8 │ 239104d0-f59f-11ee-3d0c-d1db071927ff                   3  redundancy  0
   9 │ 239104d0-f59f-11ee-3d0c-d1db071927ff                   4  redundancy  0 ⋯
  10 │ 239104d0-f59f-11ee-3d0c-d1db071927ff                   5  redundancy  0
  11 │ 239104d0-f59f-11ee-3d0c-d1db071927ff                   1  validity    1
  ⋮  │                  ⋮                            ⋮               ⋮         ⋱
  66 │ 2398c08a-f59f-11ee-175b-81c155750752                   1  redundancy  0
  67 │ 2398c08a-f59f-11ee-175b-81c155750752                   2  redundancy  0 ⋯
  68 │ 2398c08a-f59f-11ee-175b-81c155750752                   3  redundancy  0
  69 │ 2398c08a-f59f-11ee-175b-81c155750752                   4  redundancy  0
  70 │ 2398c08a-f59f-11ee-175b-81c155750752                   5  redundancy  0
  71 │ 2398c08a-f59f-11ee-175b-81c155750752                   1  validity    1 ⋯
  72 │ 2398c08a-f59f-11ee-175b-81c155750752                   2  validity    1
  73 │ 2398c08a-f59f-11ee-175b-81c155750752                   3  validity    1
  74 │ 2398c08a-f59f-11ee-175b-81c155750752                   4  validity    1
  75 │ 2398c08a-f59f-11ee-175b-81c155750752                   5  validity    1 ⋯
                                                   5 columns and 54 rows omitted</code></pre><p>Since benchmarks return a <code>DataFrame</code> object on call, post-processing is straightforward. For example, we could use <a href="https://kdpsingh.github.io/Tidier.jl/dev/"><code>Tidier.jl</code></a>:</p><pre><code class="language-julia hljs">using Tidier
@chain bmk() begin
    @filter(variable == &quot;distance&quot;)
    @select(sample, variable, value)
end</code></pre><pre><code class="nohighlight hljs">5×3 DataFrame
 Row │ sample                                variable  value   
     │ Base.UUID                             String    Float64 
─────┼─────────────────────────────────────────────────────────
   1 │ 239104d0-f59f-11ee-3d0c-d1db071927ff  distance  3.17243
   2 │ 2398b3e2-f59f-11ee-3323-13d53fb7e75b  distance  3.07148
   3 │ 2398b916-f59f-11ee-3f13-bd00858a39af  distance  3.62159
   4 │ 2398bce8-f59f-11ee-37c1-ef7c6de27b6b  distance  2.62783
   5 │ 2398c08a-f59f-11ee-175b-81c155750752  distance  2.91985</code></pre><h3 id="Metadata-for-Counterfactual-Explanations"><a class="docs-heading-anchor" href="#Metadata-for-Counterfactual-Explanations">Metadata for Counterfactual Explanations</a><a id="Metadata-for-Counterfactual-Explanations-1"></a><a class="docs-heading-anchor-permalink" href="#Metadata-for-Counterfactual-Explanations" title="Permalink"></a></h3><p>Benchmarks always report metadata for each counterfactual explanation, which is automatically inferred by default. The default metadata concerns the explained <code>model</code> and the employed <code>generator</code>. In the current example, we used the same model and generator for each individual:</p><pre><code class="language-julia hljs">@chain bmk() begin
    @group_by(sample)
    @select(sample, model, generator)
    @summarize(model=first(model),generator=first(generator))
    @ungroup
end</code></pre><pre><code class="nohighlight hljs">5×3 DataFrame
 Row │ sample                                model                             ⋯
     │ Base.UUID                             Symbol                            ⋯
─────┼──────────────────────────────────────────────────────────────────────────
   1 │ 239104d0-f59f-11ee-3d0c-d1db071927ff  FluxModel(Chain(Dense(2 =&gt; 2)), … ⋯
   2 │ 2398b3e2-f59f-11ee-3323-13d53fb7e75b  FluxModel(Chain(Dense(2 =&gt; 2)), …
   3 │ 2398b916-f59f-11ee-3f13-bd00858a39af  FluxModel(Chain(Dense(2 =&gt; 2)), …
   4 │ 2398bce8-f59f-11ee-37c1-ef7c6de27b6b  FluxModel(Chain(Dense(2 =&gt; 2)), …
   5 │ 2398c08a-f59f-11ee-175b-81c155750752  FluxModel(Chain(Dense(2 =&gt; 2)), … ⋯
                                                                1 column omitted</code></pre><p>Metadata can also be provided as an optional key argument.</p><pre><code class="language-julia hljs">meta_data = Dict(
    :generator =&gt; &quot;Generic&quot;,
    :model =&gt; &quot;MLP&quot;,
)
meta_data = [meta_data for i in 1:length(ces)]
bmk = benchmark(ces; meta_data=meta_data)
@chain bmk() begin
    @group_by(sample)
    @select(sample, model, generator)
    @summarize(model=first(model),generator=first(generator))
    @ungroup
end</code></pre><pre><code class="nohighlight hljs">5×3 DataFrame
 Row │ sample                                model   generator 
     │ Base.UUID                             String  String    
─────┼─────────────────────────────────────────────────────────
   1 │ 27fae496-f59f-11ee-2c30-f35d1025a6d4  MLP     Generic
   2 │ 27fdcc6a-f59f-11ee-030b-152c9794c5f1  MLP     Generic
   3 │ 27fdd04a-f59f-11ee-2010-e1732ff5d8d2  MLP     Generic
   4 │ 27fdd340-f59f-11ee-1d20-050a69dcacef  MLP     Generic
   5 │ 27fdd5fc-f59f-11ee-02e8-d198e436abb3  MLP     Generic</code></pre><h2 id="Ad-Hoc-Benchmarking"><a class="docs-heading-anchor" href="#Ad-Hoc-Benchmarking">Ad Hoc Benchmarking</a><a id="Ad-Hoc-Benchmarking-1"></a><a class="docs-heading-anchor-permalink" href="#Ad-Hoc-Benchmarking" title="Permalink"></a></h2><p>So far we have assumed the following workflow:</p><ol><li>Fit some machine learning model.</li><li>Generate counterfactual explanations for some individual(s) (<code>generate_counterfactual</code>).</li><li>Evaluate and benchmark them (<code>benchmark(ces::Vector{CounterfactualExplanation})</code>).</li></ol><p>In many cases, it may be preferable to combine these steps. To this end, we have added support for two scenarios of Ad Hoc Benchmarking.</p><h3 id="Pre-trained-Models"><a class="docs-heading-anchor" href="#Pre-trained-Models">Pre-trained Models</a><a id="Pre-trained-Models-1"></a><a class="docs-heading-anchor-permalink" href="#Pre-trained-Models" title="Permalink"></a></h3><p>In the first scenario, it is assumed that the machine learning models have been pre-trained and so the workflow can be summarized as follows:</p><ol><li>Fit some machine learning model(s).</li><li>Generate counterfactual explanations and benchmark them.</li></ol><p>We suspect that this is the most common workflow for practitioners who are interested in benchmarking counterfactual explanations for the pre-trained machine learning models. Let’s go through this workflow using a simple example. We first train some models and store them in a dictionary:</p><pre><code class="language-julia hljs">models = Dict(
    :MLP =&gt; fit_model(counterfactual_data, :MLP),
    :Linear =&gt; fit_model(counterfactual_data, :Linear),
)</code></pre><p>Next, we store the counterfactual generators of interest in a dictionary as well:</p><pre><code class="language-julia hljs">generators = Dict(
    :Generic =&gt; GenericGenerator(),
    :Gravitational =&gt; GravitationalGenerator(),
    :Wachter =&gt; WachterGenerator(),
    :ClaPROAR =&gt; ClaPROARGenerator(),
)</code></pre><p>Then we can run a benchmark for individual(s) <code>x</code>, a pre-specified <code>target</code> and <code>counterfactual_data</code> as follows:</p><pre><code class="language-julia hljs">bmk = benchmark(x, target, counterfactual_data; models=models, generators=generators)</code></pre><p>In this case, metadata is automatically inferred from the dictionaries:</p><pre><code class="language-julia hljs">@chain bmk() begin
    @filter(variable == &quot;distance&quot;)
    @select(sample, variable, value, model, generator)
end</code></pre><pre><code class="nohighlight hljs">8×5 DataFrame
 Row │ sample                                variable  value    model          ⋯
     │ Base.UUID                             String    Float64  Tuple…         ⋯
─────┼──────────────────────────────────────────────────────────────────────────
   1 │ 2cba5eee-f59f-11ee-1844-cbc7a8372a38  distance  4.38877  (:Linear, Flux ⋯
   2 │ 2cd740fe-f59f-11ee-35c3-1157eb1b7583  distance  4.17021  (:Linear, Flux
   3 │ 2cd741e2-f59f-11ee-2b09-0d55ef9892b9  distance  4.31145  (:Linear, Flux
   4 │ 2cd7420c-f59f-11ee-1996-6fa75e23bb57  distance  4.17035  (:Linear, Flux
   5 │ 2cd74234-f59f-11ee-0ad0-9f21949f5932  distance  5.73182  (:MLP, FluxMod ⋯
   6 │ 2cd7425c-f59f-11ee-3eb4-af34f85ffd3d  distance  5.50606  (:MLP, FluxMod
   7 │ 2cd7427a-f59f-11ee-10d3-a1df6c8dc125  distance  5.2114   (:MLP, FluxMod
   8 │ 2cd74298-f59f-11ee-32d1-f501c104fea8  distance  5.3623   (:MLP, FluxMod
                                                               2 columns omitted</code></pre><h3 id="Everything-at-once"><a class="docs-heading-anchor" href="#Everything-at-once">Everything at once</a><a id="Everything-at-once-1"></a><a class="docs-heading-anchor-permalink" href="#Everything-at-once" title="Permalink"></a></h3><p>Researchers, in particular, may be interested in combining all steps into one. This is the second scenario of Ad Hoc Benchmarking:</p><ol><li>Fit some machine learning model(s), generate counterfactual explanations and benchmark them.</li></ol><p>It involves calling <code>benchmark</code> directly on counterfactual data (the only positional argument):</p><pre><code class="language-julia hljs">bmk = benchmark(counterfactual_data)</code></pre><p>This will use the default models from <a href="../../reference/#CounterfactualExplanations.Models.standard_models_catalogue"><code>standard_models_catalogue</code></a> and train them on the data. All available generators from <a href="../../reference/#CounterfactualExplanations.Generators.generator_catalogue"><code>generator_catalogue</code></a> will also be used:</p><pre><code class="language-julia hljs">@chain bmk() begin
    @filter(variable == &quot;validity&quot;)
    @select(sample, variable, value, model, generator)
end</code></pre><pre><code class="nohighlight hljs">200×5 DataFrame
 Row │ sample                                variable  value    model   genera ⋯
     │ Base.UUID                             String    Float64  Symbol  Symbol ⋯
─────┼──────────────────────────────────────────────────────────────────────────
   1 │ 32d1817e-f59f-11ee-152f-a30b18c2e6f7  validity      1.0  Linear  gravit ⋯
   2 │ 32d1817e-f59f-11ee-152f-a30b18c2e6f7  validity      1.0  Linear  growin
   3 │ 32d1817e-f59f-11ee-152f-a30b18c2e6f7  validity      1.0  Linear  revise
   4 │ 32d1817e-f59f-11ee-152f-a30b18c2e6f7  validity      1.0  Linear  clue
   5 │ 32d1817e-f59f-11ee-152f-a30b18c2e6f7  validity      1.0  Linear  probe  ⋯
   6 │ 32d1817e-f59f-11ee-152f-a30b18c2e6f7  validity      1.0  Linear  dice
   7 │ 32d1817e-f59f-11ee-152f-a30b18c2e6f7  validity      1.0  Linear  clapro
   8 │ 32d1817e-f59f-11ee-152f-a30b18c2e6f7  validity      1.0  Linear  wachte
   9 │ 32d1817e-f59f-11ee-152f-a30b18c2e6f7  validity      1.0  Linear  generi ⋯
  10 │ 32d1817e-f59f-11ee-152f-a30b18c2e6f7  validity      1.0  Linear  greedy
  11 │ 32d255e8-f59f-11ee-3e8d-a9e9f6e23ea8  validity      1.0  Linear  gravit
  ⋮  │                  ⋮                       ⋮         ⋮       ⋮            ⋱
 191 │ 3382d08a-f59f-11ee-10b3-f7d18cf7d3b5  validity      1.0  MLP     gravit
 192 │ 3382d08a-f59f-11ee-10b3-f7d18cf7d3b5  validity      1.0  MLP     growin ⋯
 193 │ 3382d08a-f59f-11ee-10b3-f7d18cf7d3b5  validity      1.0  MLP     revise
 194 │ 3382d08a-f59f-11ee-10b3-f7d18cf7d3b5  validity      1.0  MLP     clue
 195 │ 3382d08a-f59f-11ee-10b3-f7d18cf7d3b5  validity      1.0  MLP     probe
 196 │ 3382d08a-f59f-11ee-10b3-f7d18cf7d3b5  validity      1.0  MLP     dice   ⋯
 197 │ 3382d08a-f59f-11ee-10b3-f7d18cf7d3b5  validity      1.0  MLP     clapro
 198 │ 3382d08a-f59f-11ee-10b3-f7d18cf7d3b5  validity      1.0  MLP     wachte
 199 │ 3382d08a-f59f-11ee-10b3-f7d18cf7d3b5  validity      1.0  MLP     generi
 200 │ 3382d08a-f59f-11ee-10b3-f7d18cf7d3b5  validity      1.0  MLP     greedy ⋯
                                                   1 column and 179 rows omitted</code></pre><p>Optionally, you can instead provide a dictionary of <code>models</code> and <code>generators</code> as before. Each value in the <code>models</code> dictionary should be one of two things:</p><ol><li>Either be an object <code>M</code> of type <a href="../../reference/#CounterfactualExplanations.AbstractModel"><code>AbstractModel</code></a> that implements the <a href="../../reference/#CounterfactualExplanations.Models.train-Tuple{CounterfactualExplanations.Models.Model, CounterfactualData}"><code>Models.train</code></a> method.</li><li>Or a <code>DataType</code> that can be called on <a href="../../reference/#CounterfactualExplanations.DataPreprocessing.CounterfactualData-Tuple{AbstractMatrix, Union{AbstractMatrix, AbstractVector}}"><code>CounterfactualData</code></a> to create an object <code>M</code> as in (a).</li></ol><h2 id="Multiple-Datasets"><a class="docs-heading-anchor" href="#Multiple-Datasets">Multiple Datasets</a><a id="Multiple-Datasets-1"></a><a class="docs-heading-anchor-permalink" href="#Multiple-Datasets" title="Permalink"></a></h2><p>Benchmarks are run on single instances of type <a href="../../reference/#CounterfactualExplanations.DataPreprocessing.CounterfactualData-Tuple{AbstractMatrix, Union{AbstractMatrix, AbstractVector}}"><code>CounterfactualData</code></a>. This is our design choice for two reasons:</p><ol><li>We want to avoid the loops inside the <code>benchmark</code> method(s) from getting too nested and convoluted.</li><li>While it is straightforward to infer metadata for models and generators, this is not the case for datasets.</li></ol><p>Fortunately, it is very easy to run benchmarks for multiple datasets anyway, since <code>Benchmark</code> instances can be concatenated. To see how, let’s consider an example involving multiple datasets, models and generators:</p><pre><code class="language-julia hljs"># Data:
datasets = Dict(
    :moons =&gt; CounterfactualData(load_moons()...),
    :circles =&gt; CounterfactualData(load_circles()...),
)

# Models:
models = Dict(
    :MLP =&gt; FluxModel,
    :Linear =&gt; Linear,
)

# Generators:
generators = Dict(
    :Generic =&gt; GenericGenerator(),
    :Greedy =&gt; GreedyGenerator(),
)</code></pre><p>Then we can simply loop over the datasets and eventually concatenate the results like so:</p><pre><code class="language-julia hljs">using CounterfactualExplanations.Evaluation: distance_measures
bmks = []
for (dataname, dataset) in datasets
    bmk = benchmark(dataset; models=models, generators=generators, measure=distance_measures)
    push!(bmks, bmk)
end
bmk = vcat(bmks[1], bmks[2]; ids=collect(keys(datasets)))</code></pre><p>When <code>ids</code> are supplied, then a new id column is added to the evaluation data frame that contains unique identifiers for the different benchmarks. The optional <code>idcol_name</code> argument can be used to specify the name for that indicator column (defaults to <code>&quot;dataset&quot;</code>):</p><pre><code class="language-julia hljs">@chain bmk() begin
    @group_by(dataset, generator)
    @filter(model == :MLP)
    @filter(variable == &quot;distance_l1&quot;)
    @summarize(L1_norm=mean(value))
    @ungroup
end</code></pre><pre><code class="nohighlight hljs">4×3 DataFrame
 Row │ dataset  generator  L1_norm  
     │ Symbol   Symbol     Float32  
─────┼──────────────────────────────
   1 │ moons    Generic    1.56555
   2 │ moons    Greedy     0.819269
   3 │ circles  Generic    1.83524
   4 │ circles  Greedy     0.498953</code></pre></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../evaluation/">« Evaluating Explanations</a><a class="docs-footer-nextpage" href="../parallelization/">Parallelization »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.7.0 on <span class="colophon-date" title="Tuesday 24 September 2024 17:14">Tuesday 24 September 2024</span>. Using Julia version 1.10.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
