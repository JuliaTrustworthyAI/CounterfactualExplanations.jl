{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```@meta\n",
    "CurrentModule = AlgorithmicRecourse \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recourse for multi-class targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogLevel(1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using Flux, Random, Plots, PlotThemes, AlgorithmicRecourse\n",
    "theme(:wong)\n",
    "using Logging\n",
    "disable_logging(Logging.Info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = toy_data_multi()\n",
    "X = hcat(x...)\n",
    "y_train = Flux.onehotbatch(y, unique(y))\n",
    "y_train = Flux.unstack(y_train',1)\n",
    "plt = plot()\n",
    "plt = plot_data!(plt,X',y);\n",
    "savefig(plt, \"www/multi_samples.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](www/multi_samples.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden = 32\n",
    "out_dim = length(unique(y))\n",
    "nn = build_model(output_dim=out_dim)\n",
    "loss(x, y) = Flux.Losses.logitcrossentropy(nn(x), y)\n",
    "ps = Flux.params(nn)\n",
    "data = zip(x,y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux.Optimise: update!, ADAM\n",
    "using Statistics\n",
    "opt = ADAM()\n",
    "epochs = 10\n",
    "avg_loss(data) = mean(map(d -> loss(d[1],d[2]), data))\n",
    "\n",
    "using Plots\n",
    "anim = Animation()\n",
    "plt = plot(ylim=(0,avg_loss(data)), xlim=(0,epochs), legend=false, xlab=\"Epoch\")\n",
    "avg_l = []\n",
    "\n",
    "for epoch = 1:epochs\n",
    "  for d in data\n",
    "    gs = gradient(params(nn)) do\n",
    "      l = loss(d...)\n",
    "    end\n",
    "    update!(opt, params(nn), gs)\n",
    "  end\n",
    "  avg_l = vcat(avg_l,avg_loss(data))\n",
    "  plot!(plt, avg_l, color=1, title=\"Average (training) loss\")\n",
    "  frame(anim, plt)\n",
    "end\n",
    "\n",
    "gif(anim, \"www/multi_loss.gif\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](www/multi_loss.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(Chain(Dense(2, 32, relu), Dense(32, 4)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using AlgorithmicRecourse, AlgorithmicRecourse.Models\n",
    "import AlgorithmicRecourse.Models: logits, probs # import functions in order to extend\n",
    "\n",
    "# Step 1)\n",
    "struct NeuralNetwork <: Models.FittedModel\n",
    "    nn::Any\n",
    "end\n",
    "\n",
    "# Step 2)\n",
    "logits(𝑴::NeuralNetwork, X::AbstractArray) = 𝑴.nn(X)\n",
    "probs(𝑴::NeuralNetwork, X::AbstractArray)= softmax(logits(𝑴, X))\n",
    "𝑴 = NeuralNetwork(nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt = plot_contour_multi(X',y,𝑴);\n",
    "savefig(plt, \"www/multi_contour.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](www/multi_contour.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly selected factual:\n",
    "Random.seed!(42);\n",
    "x̅ = X[:,rand(1:size(X)[2])]\n",
    "y̅ = Flux.onecold(probs(𝑴, x̅),unique(y))\n",
    "target = rand(unique(y)[1:end .!= y̅]) # opposite label as target\n",
    "γ = 0.75\n",
    "# Define Generator:\n",
    "generator = GenericGenerator(0.1,0.1,1e-5,:logitcrossentropy,nothing)\n",
    "# Generate recourse:\n",
    "recourse = generate_recourse(generator, x̅, 𝑴, target, γ); # generate recourse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = size(recourse.path)[1]\n",
    "ŷ = AlgorithmicRecourse.target_probs(probs(recourse.𝑴, recourse.path'),target)\n",
    "p1 = plot_contour_multi(X',y,𝑴;title=\"Neural network\")\n",
    "anim = @animate for t in 1:T\n",
    "    scatter!(p1, [recourse.path[t,1]], [recourse.path[t,2]], ms=5, color=Int(y̅), label=\"\")\n",
    "    p2 = plot(1:t, ŷ[1:t], xlim=(0,T), ylim=(0, 1), label=\"p(y̲=\" * string(target) * \")\", title=\"Validity\", lc=:black)\n",
    "    Plots.abline!(p2,0,γ,label=\"threshold γ\", ls=:dash) # decision boundary\n",
    "    plot(p1,p2,size=(800,400))\n",
    "end\n",
    "gif(anim, \"www/multi_generic_recourse.gif\", fps=5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](www/multi_generic_recourse.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "𝓜 = build_ensemble(5;kw=(output_dim=out_dim,));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "𝓜, anim = forward(𝓜, data, opt, n_epochs=epochs, plot_every=1); # fit the ensemble\n",
    "gif(anim, \"www/multi_ensemble_loss.gif\", fps=10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](www/multi_ensemble_loss.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1)\n",
    "struct FittedEnsemble <: Models.FittedModel\n",
    "    𝓜::AbstractArray\n",
    "end\n",
    "\n",
    "# Step 2)\n",
    "using Statistics\n",
    "logits(𝑴::FittedEnsemble, X::AbstractArray) = mean(Flux.stack([nn(X) for nn in 𝑴.𝓜],3), dims=3)\n",
    "probs(𝑴::FittedEnsemble, X::AbstractArray) = mean(Flux.stack([softmax(nn(X)) for nn in 𝑴.𝓜],3),dims=3)\n",
    "\n",
    "𝑴=FittedEnsemble(𝓜);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt = plot_contour_multi(X',y,𝑴);\n",
    "savefig(plt, \"www/multi_ensemble_contour.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](www/multi_ensemble_contour.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = GreedyGenerator(0.25,20,:logitcrossentropy,nothing)\n",
    "recourse = generate_recourse(generator, x̅, 𝑴, target, γ); # generate recourse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = size(recourse.path)[1]\n",
    "ŷ = AlgorithmicRecourse.target_probs(probs(recourse.𝑴, recourse.path'),target)\n",
    "p1 = plot_contour_multi(X',y,𝑴;title=\"Deep ensemble\")\n",
    "anim = @animate for t in 1:T\n",
    "    scatter!(p1, [recourse.path[t,1]], [recourse.path[t,2]], ms=5, color=Int(y̅), label=\"\")\n",
    "    p2 = plot(1:t, ŷ[1:t], xlim=(0,T), ylim=(0, 1), label=\"p(y̲=\" * string(target) * \")\", title=\"Validity\", lc=:black)\n",
    "    Plots.abline!(p2,0,γ,label=\"threshold γ\", ls=:dash) # decision boundary\n",
    "    plot(p1,p2,size=(800,400))\n",
    "end\n",
    "gif(anim, \"www/multi_greedy_recourse.gif\", fps=5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](www/multi_greedy_recourse.gif)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.4",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
