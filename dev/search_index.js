var documenterSearchIndex = {"docs":
[{"location":"tutorials/generators/","page":"Custom generators","title":"Custom generators","text":"CurrentModule = CounterfactualExplanations ","category":"page"},{"location":"tutorials/generators/#Custom-generators","page":"Custom generators","title":"Custom generators","text":"","category":"section"},{"location":"tutorials/generators/","page":"Custom generators","title":"Custom generators","text":"As we will see in this short tutorial, building custom counterfactual generators is straight-forward. We hope that this will facilitate contributions through the community.","category":"page"},{"location":"tutorials/generators/#Generic-generator-with-dropout","page":"Custom generators","title":"Generic generator with dropout","text":"","category":"section"},{"location":"tutorials/generators/","page":"Custom generators","title":"Custom generators","text":"To illustrate how custom generators can be implemented we will consider a simple example of a generator that extends the functionality of our GenericGenerator. We have noted elsewhere that the effectiveness of ounterfactual explanations depends to some degree on the quality of the fitted model. Another, perhaps trivial, thing to note is that counterfactual explanations are not unique: there are potentially many valid counterfactual paths. One interesting (or silly) idea following these two observations might be to introduce some form of regularization in the counterfactual search. For example, we could use dropout to randomly switch features on and off in each iteration. Without dwelling further on the usefulness of this idea, let us see how it can be implemented.","category":"page"},{"location":"tutorials/generators/","page":"Custom generators","title":"Custom generators","text":"The first code chunk below implements two important steps: 1) create an abstract subtype of the AbstractGradientBasedGenerator and 2) create a constructor similar to the GenericConstructor, but with one additional field for the probability of dropout.","category":"page"},{"location":"tutorials/generators/","page":"Custom generators","title":"Custom generators","text":"# Abstract suptype:\nabstract type AbstractDropoutGenerator <: AbstractGradientBasedGenerator end\n\n# Constructor:\nstruct DropoutGenerator <: AbstractDropoutGenerator\n    loss::Symbol # loss function\n    complexity::Function # complexity function\n    mutability::Union{Nothing,Vector{Symbol}} # mutibility constraints \n    Œª::AbstractFloat # strength of penalty\n    œµ::AbstractFloat # step size\n    œÑ::AbstractFloat # tolerance for convergence\n    p_dropout::AbstractFloat # dropout rate\nend\n\n# Instantiate:\nusing LinearAlgebra\ngenerator = DropoutGenerator(\n    :logitbinarycrossentropy,\n    norm,\n    nothing,\n    0.1,\n    0.1,\n    1e-5,\n    0.5\n)","category":"page"},{"location":"tutorials/generators/","page":"Custom generators","title":"Custom generators","text":"Next, we define how feature perturbations are generated for our dropout generator: in particular, we extend the relevant function through a method that implemented the dropout logic.","category":"page"},{"location":"tutorials/generators/","page":"Custom generators","title":"Custom generators","text":"import CounterfactualExplanations.Generators: generate_perturbations, ‚àá\nusing StatsBase\nfunction generate_perturbations(generator::AbstractDropoutGenerator, counterfactual_state::CounterfactualState)\n    ùê†‚Çú = ‚àá(generator, counterfactual_state) # gradient\n    # Dropout:\n    set_to_zero = sample(1:length(ùê†‚Çú),Int(round(generator.p_dropout*length(ùê†‚Çú))),replace=false)\n    ùê†‚Çú[set_to_zero] .= 0\n    Œîx‚Ä≤ = - (generator.œµ .* ùê†‚Çú) # gradient step\n    return Œîx‚Ä≤\nend","category":"page"},{"location":"tutorials/generators/","page":"Custom generators","title":"Custom generators","text":"Finally, we proceed to generate counterfactuals in the same way we always do. The code below simply generates some toy data, randomly selects a sample and runs the counterfactual search. The resulting counterfactual path is shown in Figure¬†1.","category":"page"},{"location":"tutorials/generators/","page":"Custom generators","title":"Custom generators","text":"# Data:\nusing CounterfactualExplanations.Data\nRandom.seed!(1234)\nN = 25\nw = [1.0 1.0]# true coefficients\nb = 0\nxs, ys = Data.toy_data_linear(N)\nX = hcat(xs...)\ncounterfactual_data = CounterfactualData(X,ys')\n\n# Model:\nusing CounterfactualExplanations.Models: LogisticModel, probs \n# Logit model:\nM = LogisticModel(w, [b])\n# Randomly selected factual:\nRandom.seed!(123)\nx = select_factual(counterfactual_data,rand(1:size(X)[2]))\ny = round(probs(M, x)[1])\ntarget = ifelse(y==1.0,0.0,1.0) # opposite label as target\n\n# Generate recourse:\ncounterfactual = generate_counterfactual(x, target, counterfactual_data, M, generator)","category":"page"},{"location":"tutorials/generators/","page":"Custom generators","title":"Custom generators","text":"(Image: Figure 1: Counterfactual path for a generic generator with dropout.)","category":"page"},{"location":"contributing/","page":"Overview","title":"Overview","text":"CurrentModule = CounterfactualExplanations ","category":"page"},{"location":"contributing/#Contributing","page":"Overview","title":"Contributing","text":"","category":"section"},{"location":"contributing/","page":"Overview","title":"Overview","text":"CounterfactualExplanations.jl is designed to be scalable: through multiple dispatch and modularization we hope to make it as straight-forward as possible for members of the community to contribute to its functionality. At the moment we are primarily looking for the following contributions:","category":"page"},{"location":"contributing/","page":"Overview","title":"Overview","text":"Additional counterfactual generators.\nAdditional predictive models.\nMore examples to be added to the documentation.\nNative support for categorical features.\nSupport for regression models.","category":"page"},{"location":"contributing/","page":"Overview","title":"Overview","text":"We are also interested in suggestions on how to adjust and improve the inner workings of our package. To facilitate this process the following page explain and justify the package architecture and the design choices we have made. ","category":"page"},{"location":"contributing/#How-to-contribute?","page":"Overview","title":"How to contribute?","text":"","category":"section"},{"location":"contributing/","page":"Overview","title":"Overview","text":"All of the following contributions are welcome:","category":"page"},{"location":"contributing/","page":"Overview","title":"Overview","text":"Should you spot any errors or something is not working, please just open an issue.\nIf you want to contribute your own code, please proceed as follows:\nFork this repo and clone your fork: git clone https://github.com/your_username/CounterfactualExplanations.jl.\nAdd a remote corresponding to this repository: git remote add upstream https://github.com/pat-alt/CounterfactualExplanations.jl.git\nImplement your modifications and submit a pull request.\nFor any other questions or comments you can also start a discussion.","category":"page"},{"location":"tutorials/binary/","page":"Binary target","title":"Binary target","text":"CurrentModule = CounterfactualExplanations ","category":"page"},{"location":"tutorials/binary/#Counterfactual-explanations-for-binary-classification","page":"Binary target","title":"Counterfactual explanations for binary classification","text":"","category":"section"},{"location":"tutorials/binary/","page":"Binary target","title":"Binary target","text":"To understand the core functionality of CounterfactualExplanations.jl we will look at two example use cases of the generate_counterfactual function. This function takes a structure of type AbstractGenerator as its main argument. Users can utilize one of the default generators: GenericGenerator <: AbstractGenerator, GreedyGenerator <: AbstractGenerator. Alternatively, users can also create their own custom generator.","category":"page"},{"location":"tutorials/binary/#Default-generators","page":"Binary target","title":"Default generators","text":"","category":"section"},{"location":"tutorials/binary/#GenericGenerator","page":"Binary target","title":"GenericGenerator","text":"","category":"section"},{"location":"tutorials/binary/","page":"Binary target","title":"Binary target","text":"Let t‚ÄÑ‚àà‚ÄÑ{0,‚ÄÜ1} denote the target label, M the model (classifier) and x‚Ä≤ ‚àà ‚Ñù·¥∞ the vector of counterfactual features. In order to generate recourse the GenericGenerator optimizes the following objective function through steepest descent","category":"page"},{"location":"tutorials/binary/","page":"Binary target","title":"Binary target","text":"xprime = arg min_xprime  ell(M(xprime)t) + lambda h(xprime)","category":"page"},{"location":"tutorials/binary/","page":"Binary target","title":"Binary target","text":"where ‚Ñì denotes some loss function targeting the deviation between the target label and the predicted label and h(‚ãÖ) as a complexity penalty generally addressing the realism or cost of the proposed counterfactual.","category":"page"},{"location":"tutorials/binary/","page":"Binary target","title":"Binary target","text":"Let‚Äôs generate some toy data:","category":"page"},{"location":"tutorials/binary/","page":"Binary target","title":"Binary target","text":"# Some random data:\nusing CounterfactualExplanations.Data\nRandom.seed!(1234);\nN = 25\nw = [1.0 1.0]# true coefficients\nb = 0\nxs, ys = Data.toy_data_linear(N)\nX = hcat(xs...)\ncounterfactual_data = CounterfactualData(X,ys')\nplt = plot()\nplt = plot_data!(plt,X',ys);\nsavefig(plt, joinpath(www_path, \"binary_samples.png\"))","category":"page"},{"location":"tutorials/binary/","page":"Binary target","title":"Binary target","text":"(Image: )","category":"page"},{"location":"tutorials/binary/","page":"Binary target","title":"Binary target","text":"For this toy data we will now implement algorithmic recourse as follows:","category":"page"},{"location":"tutorials/binary/","page":"Binary target","title":"Binary target","text":"Use the coefficients w and b to define our model using CounterfactualExplanations.Models.LogisticModel(w, b).\nDefine our GenericGenerator.\nGenerate counterfactual.","category":"page"},{"location":"tutorials/binary/","page":"Binary target","title":"Binary target","text":"using CounterfactualExplanations.Models: LogisticModel, probs \n# Logit model:\nM = LogisticModel(w, [b])\n# Randomly selected factual:\nRandom.seed!(123);\nx = select_factual(counterfactual_data,rand(1:size(X)[2]))\ny = round(probs(M, x)[1])\ntarget = ifelse(y==1.0,0.0,1.0) # opposite label as target","category":"page"},{"location":"tutorials/binary/","page":"Binary target","title":"Binary target","text":"plt = plot_contour(X',ys,M;title=\"Posterior predictive - Plugin\")\nsavefig(plt, joinpath(www_path, \"binary_contour.png\"))","category":"page"},{"location":"tutorials/binary/","page":"Binary target","title":"Binary target","text":"(Image: )","category":"page"},{"location":"tutorials/binary/","page":"Binary target","title":"Binary target","text":"# Define generator:\ngenerator = GenericGenerator()\n# Generate recourse:\ncounterfactual = generate_counterfactual(x, target, counterfactual_data, M, generator)","category":"page"},{"location":"tutorials/binary/","page":"Binary target","title":"Binary target","text":"Now let‚Äôs plot the resulting counterfactual path in the 2-D feature space (left) and the predicted probability (right):","category":"page"},{"location":"tutorials/binary/","page":"Binary target","title":"Binary target","text":"import CounterfactualExplanations.Counterfactuals: target_probs\nT = total_steps(counterfactual)\nX_path = reduce(hcat,path(counterfactual))\nyÃÇ = target_probs(counterfactual,X_path)\np1 = plot_contour(X',ys,M;colorbar=false, title=\"Posterior predictive - Plugin\")\nanim = @animate for t in 1:T\n    scatter!(p1, [path(counterfactual)[t][1]], [path(counterfactual)[t][2]], ms=5, color=Int(y), label=\"\")\n    p2 = plot(1:t, yÃÇ[1:t], xlim=(0,T), ylim=(0, 1), label=\"p(y‚Ä≤=\" * string(target) * \")\", title=\"Validity\", lc=:black)\n    Plots.abline!(p2,0,counterfactual.params[:Œ≥],label=\"threshold Œ≥\", ls=:dash) # decision boundary\n    plot(p1,p2,size=(800,400))\nend\ngif(anim, joinpath(www_path, \"binary_generic_recourse.gif\"), fps=25)","category":"page"},{"location":"tutorials/binary/","page":"Binary target","title":"Binary target","text":"(Image: )","category":"page"},{"location":"tutorials/binary/#GreedyGenerator","page":"Binary target","title":"GreedyGenerator","text":"","category":"section"},{"location":"tutorials/binary/","page":"Binary target","title":"Binary target","text":"Next we will repeat the exercise above, but instead use the GreedyGenerator in the context of a Bayesian classifier. This generator is greedy in the sense that it simply chooses the most salient feature {x‚Ä≤}·µà where","category":"page"},{"location":"tutorials/binary/","page":"Binary target","title":"Binary target","text":"d=argmax_d in 1D nabla_xprime ell(M(xprime)t)","category":"page"},{"location":"tutorials/binary/","page":"Binary target","title":"Binary target","text":"and perturbs it by a fixed amount Œ¥. In other words, optimization is penalty-free. This is possible in the Bayesian context, because maximizing the predictive probability Œ≥ corresponds to minimizing the predictive uncertainty: by construction the generated counterfactual will therefore be realistic (low epistemic uncertainty) and unambiguous (low aleotoric uncertainty).","category":"page"},{"location":"tutorials/binary/","page":"Binary target","title":"Binary target","text":"using LinearAlgebra\nŒ£ = Symmetric(reshape(randn(9),3,3).*0.01 + UniformScaling(1)) # MAP covariance matrix\nŒº = hcat(b, w)\nM = CounterfactualExplanations.Models.BayesianLogisticModel(Œº, Œ£);\ngenerator = GreedyGenerator(Dict(:Œ¥=>0.1,:n=>25))\ncounterfactual = generate_counterfactual(x, target, counterfactual_data, M, generator)","category":"page"},{"location":"tutorials/binary/","page":"Binary target","title":"Binary target","text":"Once again we plot the resulting counterfactual path (left) and changes in the predicted probability (right). For the Bayesian classifier predicted probabilities splash out: uncertainty increases in regions with few samples. Note how the greedy approach selects the same most salient feature over and over again until its exhausted (i.e.¬†it has been chosen GreedyGenerator.n times).","category":"page"},{"location":"tutorials/binary/","page":"Binary target","title":"Binary target","text":"import CounterfactualExplanations.Counterfactuals: target_probs\nT = total_steps(counterfactual)\nX_path = reduce(hcat,path(counterfactual))\nyÃÇ = target_probs(counterfactual,X_path)\np1 = plot_contour(X',ys,M;colorbar=false, title=\"Posterior predictive - Plugin\")\nanim = @animate for t in 1:T\n    scatter!(p1, [path(counterfactual)[t][1]], [path(counterfactual)[t][2]], ms=5, color=Int(y), label=\"\")\n    p2 = plot(1:t, yÃÇ[1:t], xlim=(0,T), ylim=(0, 1), label=\"p(y‚Ä≤=\" * string(target) * \")\", title=\"Validity\", lc=:black)\n    Plots.abline!(p2,0,counterfactual.params[:Œ≥],label=\"threshold Œ≥\", ls=:dash) # decision boundary\n    plot(p1,p2,size=(800,400))\nend\ngif(anim, joinpath(www_path, \"binary_greedy_recourse.gif\"), fps=25);","category":"page"},{"location":"tutorials/binary/","page":"Binary target","title":"Binary target","text":"(Image: )","category":"page"},{"location":"tutorials/mutability/","page":"Mutability constraints","title":"Mutability constraints","text":"CurrentModule = CounterfactualExplanations ","category":"page"},{"location":"tutorials/mutability/#Mutability-and-domain-constraints","page":"Mutability constraints","title":"Mutability and domain constraints","text":"","category":"section"},{"location":"tutorials/mutability/","page":"Mutability constraints","title":"Mutability constraints","text":"In practice, features usually cannot be perturbed arbitrarily. Suppose, for example, that one of the features used by a bank to predict the credit worthiness of its clients is gender. If a counterfactual explanation for the prediction model indicates that female clients should change their gender to improve their credit worthiness, then this is an interesting insight (it reveals gender bias), but it is not usually an actionable transformation in practice. In such cases we may want to constrain the mutability of features to ensure actionable and realistic recourse. To illustrate how this can be implemented in CounterfactualExplanations.jl we will look at the linearly separable toy dataset again.","category":"page"},{"location":"tutorials/mutability/","page":"Mutability constraints","title":"Mutability constraints","text":"# Data:\nusing CounterfactualExplanations.Data\nxs, ys = Data.toy_data_linear()\nX = hcat(xs...)\n\n# Model\nw = [1.0 1.0]# true coefficients\nb = 0\nusing CounterfactualExplanations.Models: LogisticModel, probs \n# Logit model:\nM = LogisticModel(w, [b])","category":"page"},{"location":"tutorials/mutability/#Mutability","page":"Mutability constraints","title":"Mutability","text":"","category":"section"},{"location":"tutorials/mutability/","page":"Mutability constraints","title":"Mutability constraints","text":"Mutability of features can be defined in terms of four different options: 1) the feature is mutable in both directions, 2) the feature can only increase (e.g.¬†age), 3) the feature can only decrease (e.g.¬†time left until your next deadline) and 4) the feature is not mutable (e.g.¬†skin colour, ethnicity, ‚Ä¶). To specify which category a feature belongs to, you can pass a vector of symbols containing the mutability constraints at the pre-processing stage. For each feature you can choose from these four options: :both (mutable in both directions), :increase (only up), :decrease (only down) and :none (immutable). By default, nothing is passed to that keyword argument and it is assumed that all features are mutable in both directions.","category":"page"},{"location":"tutorials/mutability/","page":"Mutability constraints","title":"Mutability constraints","text":"Below we impose that the second feature is immutable. The resulting counterfactual path is shown in Figure¬†1 below. Since only the first feature can be perturbed, the sample can only move along the horizontal axis.","category":"page"},{"location":"tutorials/mutability/","page":"Mutability constraints","title":"Mutability constraints","text":"counterfactual_data = CounterfactualData(X,ys';mutability=[:both, :none])","category":"page"},{"location":"tutorials/mutability/","page":"Mutability constraints","title":"Mutability constraints","text":"(Image: Figure 1: Counterfactual path with immutable feature.)","category":"page"},{"location":"tutorials/mutability/#Domain-constraints","page":"Mutability constraints","title":"Domain constraints","text":"","category":"section"},{"location":"tutorials/mutability/","page":"Mutability constraints","title":"Mutability constraints","text":"In some cases we may also want to constrain the domain of some feature. For example, age as a feature is constrained to a range from 0 to some upper bound corresponding perhaps to the average life expectancy of humans. Below, for example, we impose an upper bound of 0.5 for our two features. This results in the counterfactual path shown in Figure¬†2: since features are not allowed to be perturbed beyond the upper bound, the resulting counterfactual falls just short of the threshold probability Œ≥.","category":"page"},{"location":"tutorials/mutability/","page":"Mutability constraints","title":"Mutability constraints","text":"counterfactual_data = CounterfactualData(X,ys';domain=(-Inf,0.5))","category":"page"},{"location":"tutorials/mutability/","page":"Mutability constraints","title":"Mutability constraints","text":"(Image: Figure 2: Counterfactual path with domain constraints.)","category":"page"},{"location":"tutorials/mutability/","page":"Mutability constraints","title":"Mutability constraints","text":"If we only want to constrain one particular feature to a certain domain we can pass a vector of tuples as below. In this case the resulting counterfactual path shown in Figure¬†3 does converge to the desired threshold Œ≥.","category":"page"},{"location":"tutorials/mutability/","page":"Mutability constraints","title":"Mutability constraints","text":"counterfactual_data = CounterfactualData(X,ys';domain=[(-Inf,Inf),(-Inf,-0.5)])","category":"page"},{"location":"tutorials/mutability/","page":"Mutability constraints","title":"Mutability constraints","text":"(Image: Figure 3: Counterfactual path with only one feature constrained to a certain domain.)","category":"page"},{"location":"tutorials/","page":"Overview","title":"Overview","text":"CurrentModule = CounterfactualExplanations ","category":"page"},{"location":"tutorials/#Using-CounterfactualExplanations.jl","page":"Overview","title":"Using CounterfactualExplanations.jl","text":"","category":"section"},{"location":"tutorials/","page":"Overview","title":"Overview","text":"The following pages introduce the main package functionality through various illustrative examples involving synthetic data. Among other things, the tutorials cover binary classification, multi-class problem and language interoperability with Python and R. For anyone primarily interested in using and understanding the existing package functionality, these tutorials should provide sufficient detail. If you are interested in contributing your own custom generators and models or have ideas for how to improve this package, we encourage you to also take a look at the Contributor's Guide. ","category":"page"},{"location":"intro/","page":"-","title":"-","text":"Installation\nBackground and motivation\nUsage example\nGoals and limitations\nCitation","category":"page"},{"location":"intro/","page":"-","title":"-","text":"CounterfactualExplanations.jl is a Julia package for generating Counterfactual Explanations (CE) and Algorithmic Recourse (AR) for black-box algorithms. Both CE and AR are related tools for interpretable machine learning. See below for short introduction and other resources or dive straight into the docs.","category":"page"},{"location":"intro/#Installation","page":"-","title":"Installation","text":"","category":"section"},{"location":"intro/","page":"-","title":"-","text":"The package is in its early stages of development and currently awaiting registry on Julia‚Äôs General Registry. In the meantime it can be installed as follows:","category":"page"},{"location":"intro/","page":"-","title":"-","text":"using Pkg\nPkg.add(\"https://github.com/pat-alt/CounterfactualExplanations.jl\")","category":"page"},{"location":"intro/","page":"-","title":"-","text":"To instead install the development version of the package you can run the following command:","category":"page"},{"location":"intro/","page":"-","title":"-","text":"using Pkg\nPkg.add(url=\"https://github.com/pat-alt/CounterfactualExplanations.jl\", rev=\"dev\")","category":"page"},{"location":"intro/#Background-and-motivation","page":"-","title":"Background and motivation","text":"","category":"section"},{"location":"intro/","page":"-","title":"-","text":"Algorithms used for automated decision-making such as deep neural networks have become so complex and opaque over recent years that they are generally considered as black boxes. This creates the following undesirable scenario: the human operators in charge of the black-box decision-making system do not understand how it works and essentially rely on it blindly. Conversely, those individuals who are subject to the decisions produced by such systems typically have no way of challenging them.","category":"page"},{"location":"intro/","page":"-","title":"-","text":"‚ÄúYou cannot appeal to (algorithms). They do not listen. Nor do they bend.‚Äù‚Äî Cathy O‚ÄôNeil in Weapons of Math Destruction, 2016","category":"page"},{"location":"intro/","page":"-","title":"-","text":"Counterfactual Explanations can help programmers make sense of the systems they build: they explain how inputs into a system need to change for it to produce a different output. Figure¬†1, for example, shows various counterfactuals generated through different approaches that all turn the predicted label of some classifier from a 9 into a 4. CEs that involve realistic and actionable changes such as the one on the far right can be used for the purpose of individual counterfactual.","category":"page"},{"location":"intro/","page":"-","title":"-","text":"<figure> <img src=\"examples/image/www/MNIST_9to4.png\" id=\"fig-mnist\" alt=\"Figure 1: Realistic counterfactual explanations for MNIST data: turning a 4 into a 9.\" /> <figcaption aria-hidden=\"true\">Figure 1: Realistic counterfactual explanations for MNIST data: turning a 4 into a 9.</figcaption> </figure>","category":"page"},{"location":"intro/","page":"-","title":"-","text":"Algorithmic Recourse (AR) offers individuals subject to algorithms a way to turn a negative decision into positive one. Figure¬†2 illustrates the point of AR through a toy example: it shows the counterfactual path of one sad cat üê± that would like to be grouped with her cool dog friends. Unfortunately, based on her tail length and height she was classified as a cat by a black-box classifier. The recourse algorithm perturbs her features in such a way that she ends up crossing the decision boundary into a dense region inside the target class.","category":"page"},{"location":"intro/","page":"-","title":"-","text":"<figure> <img src=\"examples/www/recourse_laplace.gif\" id=\"fig-cat\" alt=\"Figure 2: A sad üê± on its counterfactual path to its cool dog friends.\" /> <figcaption aria-hidden=\"true\">Figure 2: A sad üê± on its counterfactual path to its cool dog friends.</figcaption> </figure>","category":"page"},{"location":"intro/#Usage-example","page":"-","title":"Usage example","text":"","category":"section"},{"location":"intro/#Goals-and-limitations","page":"-","title":"Goals and limitations","text":"","category":"section"},{"location":"intro/","page":"-","title":"-","text":"The goal for this library is to contribute to efforts towards trustworthy machine learning in Julia. The Julia language has an edge when it comes to trustworthiness: it is very transparent. Packages like this one are generally written in 100% Julia, which makes it easy for users and developers to understand and contribute to open source code.","category":"page"},{"location":"intro/","page":"-","title":"-","text":"Eventually the aim for this project is to be at least at par with the amazing CARLA Python library which was presented at NeurIPS 2021. Currently CounterfactualExplanations.jl falls short of this goal in a number of ways: 1) the number of counterfactual generators is limited, 2) it lacks a framework for evaluating and benchmarking different generators, 3) it has so far been a one-person effort and not yet gone through a formal review.","category":"page"},{"location":"intro/#Citation","page":"-","title":"Citation","text":"","category":"section"},{"location":"intro/","page":"-","title":"-","text":"If you want to use this codebase, please cite:","category":"page"},{"location":"intro/","page":"-","title":"-","text":"@software{altmeyer2022CounterfactualExplanations,\n  author = {Patrick Altmeyer},\n  title = {{CounterfactualExplanations.jl - a julia package for Counterfactual Explanations and Algorithmic Recourse}},\n  url = {https://github.com/pat-alt/CounterfactualExplanations.jl},\n  version = {0.1.0},\n  year = {2022}\n}","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"CurrentModule = CounterfactualExplanations ","category":"page"},{"location":"contributing/loss/#Loss-functions","page":"Loss functions","title":"Loss functions","text":"","category":"section"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"For the computation of loss functions and their gradients we leverage the functionality already implmented in Flux. All of the loss functions from Flux have been imported:","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"julia> names(CounterfactualExplanations.Losses)\n19-element Vector{Symbol}:\n :Losses\n :binary_focal_loss\n :binarycrossentropy\n :crossentropy\n :ctc_loss\n :dice_coeff_loss\n :focal_loss\n :hinge_loss\n ‚ãÆ\n :logitbinarycrossentropy\n :logitcrossentropy\n :mae\n :mse\n :msle\n :poisson_loss\n :squared_hinge_loss\n :tversky_loss","category":"page"},{"location":"contributing/loss/#Classification","page":"Loss functions","title":"Classification","text":"","category":"section"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"For most classification tasks the default :logitbinarycrossentropy (binary) and :logitcrossentropy should be sufficient. For both choices the package has been tested and works natively. When using other loss functions, some caution is recommended though:","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"warning: External loss functions\nSome margin-based loss functions like hinge loss do not expect inputs in the domain mathcalY=01, but rather mathcalY=-11. In those case one needs to ensure that the training labels y are encoded accordingly. In order to use distance-based loss functions like mean squared error (MSE) loss needs to be computed with respect to probibilities rather than logits. This is currently not supported and we genenerally recommend not to use distance-based loss functions in the classification setting (more on this below).","category":"page"},{"location":"contributing/loss/#Regression","page":"Loss functions","title":"Regression","text":"","category":"section"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"At this point CounterfactualExplanations.jl is designed to be used with classification models, since the overwhelming majority of the existing literature on counterfactual explanations is set in this context. By default margin-based loss functions are used and computed with respect to logits (more on this below). To produce counterfactual explanations for regression problems users currently need to binarize the problem: let t denote some target value for the continuous dependent variable y in the regression context, then we could respecify the dependent variable as tÃÉ‚ÄÑ=‚ÄÑ0 for all y‚ÄÑ\\<‚ÄÑt and tÃÉ‚ÄÑ=‚ÄÑ1 otherwise. In future work we want to add full support for regression problems.","category":"page"},{"location":"contributing/loss/#Methodological-background","page":"Loss functions","title":"Methodological background","text":"","category":"section"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"This is a short tutorial on loss functions and gradients typically involved in counterfactual search. It involves more maths than perhaps some of the other tutorials.","category":"page"},{"location":"contributing/loss/#General-setup","page":"Loss functions","title":"General setup","text":"","category":"section"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"We begin by restating the general setup for generic counterfactual search. Let t‚ÄÑ‚àà‚ÄÑ{0,‚ÄÜ1} denote the target label, M the model (classifier) and x‚Ä≤‚ÄÑ‚àà‚ÄÑ‚Ñù^(D) the vector of counterfactual features (we will assume all features are continuous). Then the differentiable optimization problem in algorithmic recourse is generally of the following form","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"xprime = arg min_xprime  ell(M(xprime)t) + lambda h(xprime)","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"where ‚Ñì denotes some loss function targeting the deviation between the target label and the predicted label and h(‚ãÖ) acts as a complexity penality generally addressing the realism or cost of the proposed counterfactual.","category":"page"},{"location":"contributing/loss/#Loss-function-‚Ñì","page":"Loss functions","title":"Loss function ‚Ñì","text":"","category":"section"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"Different choices for ‚Ñì come to mind, each potentially leading to very different counterfactual outcomes. In practice, ‚Ñì is often implemented with respect to the logits a‚ÄÑ=‚ÄÑw^(T)x rather than the probabilities p(y‚Ä≤=1|x‚Ä≤)‚ÄÑ=‚ÄÑœÉ(a) predicted by the classifier. We follow this convention here, but as we shall see depeding on the label domain this convention does not work well for every type of loss function. Common choices for ‚Ñì in the literature include margin-based loss function like hinge loss and logit binary crossentropy (or log) loss. Some use distance-based loss such as mean squared error loss (MSE).","category":"page"},{"location":"contributing/loss/#Hinge-loss","page":"Loss functions","title":"Hinge loss","text":"","category":"section"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"With respect to the logits a‚ÄÑ=‚ÄÑw‚Ä≤x hinge loss can be defined as follows","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"ell(at^*)=(1-acdot t^*)_+=max01-acdot t^*","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"where t^(*) is the target label in {‚ÄÖ‚àí‚ÄÖ1,‚ÄÜ1}. Since above we defined t‚ÄÑ‚àà‚ÄÑ{0,‚ÄÜ1} we need a mapping h‚ÄÑ:‚ÄÑ{0,‚ÄÜ1}‚ÄÑ‚Ü¶‚ÄÑ{‚ÄÖ‚àí‚ÄÖ1,‚ÄÜ1}. Specifically, we want to plug in h(t)‚ÄÑ=‚ÄÑt^(*) where h(‚ãÖ) is just the following conditional:","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"beginaligned\nh(t)=begincases\n-1  textif  t=0  1  textif  t=1\nendcases\nendaligned","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"Then our loss function as function of t can restated as follows:","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"ell(at^*)=ell(at)=(1-acdot h(t))_+=max01-acdot h(t)","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"The first-order derivative of hinge loss with respect to the logits a is simply","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"beginaligned\nell(at)=begincases\n-h(t)  textif  a cdot h(t)=1  0  textotherwise \nendcases\nendaligned","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"In the context of counterfactual search the gradient with respect to the feature vector is then:","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"beginaligned\n nabla_xprime ell(at)= begincases\n-h(t)mathbfw  textif  h(t)mathbfw^Txprime=1  0  textotherwise \nendcases\nendaligned","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"In practice gradients are commonly computed through autodifferentiation. In this tutorial we use the Zygote.jl package which is at the core of Flux.jl, the main deep learning library for Julia.","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"The side-by-side plot below visualises the loss function and its derivative. The plot further below serves as a simple sanity check to verify that autodifferentiation indeed yields the same result as the closed-form solution for the gradient.","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"h(t) = ifelse(t==1,1,-1)\nhinge(a,t) = max(0,1-a*h(t))","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"default(size=(500,500))\na = -2:0.05:2\np1 = plot(a, [hinge(a,1) for a=a], title=\"Loss, t=1\", xlab=\"logits\")\np2 = plot(a, [gradient(hinge,a,1)[1] for a=a], title=\"Gradient, t=1\", xlab=\"logits\")\np3 = plot(a, [hinge(a,0) for a=a], title=\"Loss, t=0\", xlab=\"logits\")\np4 = plot(a, [gradient(hinge,a,0)[1] for a=a], title=\"Gradient, t=0\", xlab=\"logits\")\nplot(p1, p2, p3, p4, layout = (2, 2), legend = false)\nsavefig(joinpath(www_path, \"loss_grad_hinge.png\"))","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"(Image: )","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"# Just verifying that the formula for the gradient above indeed yields the same result.\nfunction gradient_man(x,w,t)\n    ùê† = ifelse(h(t)*w'x<=1, -h(t)*w, 0)\n    return ùê†\nend;\nplot(a, [gradient_man(a,1,1) for a=a], legend=:bottomright, label=\"Manual\", title=\"Gradient\", xlab=\"logits\")\nscatter!(a, [gradient(hinge,a,1)[1] for a=a], label=\"Autodiff\")\nsavefig(joinpath(www_path, \"loss_grad_hinge_test.png\"))","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"(Image: )","category":"page"},{"location":"contributing/loss/#Logit-binary-crossentropy-loss","page":"Loss functions","title":"Logit binary crossentropy loss","text":"","category":"section"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"Logit binary crossentropy loss loss (sometimes referred to as log loss) is defined as follows:","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"beginaligned\n ell(at)=- left( t cdot log(sigma(a)) + (1-t) cdot log (1-sigma(a)) right) \nendaligned","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"where œÉ(a) is the logit/sigmoid link function.","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"Once again for the purpose of counter factual search we are interested in the first-order derivative with respect to our feature vector x‚Ä≤. You can verify that the partial derivative with respect to feature x‚Ä≤_(d) is as follows:","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"beginaligned\n fracpartial ell(at)partial xprime_d= (sigma(a) - t) w_d \nendaligned","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"The gradient just corresponds to the stacked vector of partial derivatives:","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"beginaligned\n nabla_xprime ell(at)= (sigma(a) - t) mathbfw \nendaligned","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"As before implementation below is done through autodifferentiation. As before the side-by-side plot shows the resulting loss function and its gradient and the plot further below is a simple sanity check.","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"# sigmoid function:\nfunction ùõî(a)\n    trunc = 8.0 # truncation to avoid numerical over/underflow\n    a = clamp.(a,-trunc,trunc)\n    p = exp.(a)\n    p = p ./ (1 .+ p)\n    return p\nend\n\n# Logit binary crossentropy:\nlogitbinarycrossentropy(a, t) = - (t * log(ùõî(a)) + (1-t) * log(1-ùõî(a)))","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"(Image: )","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"p1 = plot(a, [logitbinarycrossentropy(a,1) for a=a], title=\"Loss, t=1\", xlab=\"logits\")\np2 = plot(a, [gradient(logitbinarycrossentropy,a,1)[1] for a=a], title=\"Gradient, t=1\", xlab=\"logits\")\np3 = plot(a, [logitbinarycrossentropy(a,0) for a=a], title=\"Loss, t=0\", xlab=\"logits\")\np4 = plot(a, [gradient(logitbinarycrossentropy,a,0)[1] for a=a], title=\"Gradient, t=0\", xlab=\"logits\")\nplot(p1, p2, p3, p4, layout = (2, 2), legend = false)\nsavefig(joinpath(www_path, \"loss_grad_log.png\"))","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"(Image: )","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"# Just verifying that the formula for the gradient above indeed yields the same result.\nfunction gradient_man(x,w,y)\n    ùê† = (ùõî(w'x) - y) .* w\n    return ùê†\nend;\nplot(a, [gradient_man(a,1,1) for a=a], legend=:bottomright, label=\"Manual\", title=\"Gradient\", xlab=\"logits\")\nscatter!(a, [gradient(logitbinarycrossentropy,a,1)[1] for a=a], label=\"Autodiff\")\nsavefig(joinpath(www_path, \"loss_grad_log_test.png\"))","category":"page"},{"location":"contributing/loss/#Mean-squared-error","page":"Loss functions","title":"Mean squared error","text":"","category":"section"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"Some authors work with distance-based loss functions instead. Since in general we are interested in providing valid recourse, that is counterfactual explanations that indeed lead to the desired label switch, using one of the margin-based loss functions introduced above seems like a more natural choice. Nonetheless, we shall briefly introduce one of the common distance-based loss functions as well.","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"The mean squared error for counterfactual search implemented with respect to the logits is simply the squared ‚Ñì¬≤ norm between the target label and a‚ÄÑ=‚ÄÑw^(T)x:","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"beginaligned\n ell(at)= t-a^2\nendaligned","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"The gradient with respect to the vector of features is then:","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"beginaligned\n nabla_xprime ell(at)= 2(a - t) mathbfw \nendaligned","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"As before implementation and visualizations follow below.","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"mse(a,t) = norm(t - a)^2","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"NOTE: I hinted above that the convention of taking derivatives with respect to logits can go wrong depending on the loss function we choose. The plot below demonstrates this point: for t‚ÄÑ=‚ÄÑ0 the global minimum of the MSE is of course also at 0. The implication for counterfactual search is that for t‚ÄÑ=‚ÄÑ0 the search stops when w^(T)x‚Ä≤‚ÄÑ=‚ÄÑ0. But at this point œÉ(w^(T)x‚Ä≤)‚ÄÑ=‚ÄÑ0.5, in other words we stop right at the decision boundary, but never cross it. We will see an example of this below. Key takeaway: carefully think about the choice of your loss function and DON‚ÄôT use distance-based loss functions when optimizing with respect to logits.","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"p1 = plot(a, [mse(a,1) for a=a], title=\"Loss, t=1\", xlab=\"logits\")\np2 = plot(a, [gradient(mse,a,1)[1] for a=a], title=\"Gradient, t=1\", xlab=\"logits\")\np3 = plot(a, [mse(a,0) for a=a], title=\"Loss, t=0\", xlab=\"logits\")\np4 = plot(a, [gradient(mse,a,0)[1] for a=a], title=\"Gradient, t=0\", xlab=\"logits\")\nplot(p1, p2, p3, p4, layout = (2, 2), legend = false)\nsavefig(joinpath(www_path, \"loss_grad_mse.png\"))","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"(Image: )","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"# Just verifying that the formula for the gradient above indeed yields the same result.\nfunction gradient_man(x,w,y)\n    ùê† = 2*(w'x - y) .* w\n    return ùê†\nend;\nplot(a, [gradient_man(a,1,1) for a=a], legend=:bottomright, label=\"Manual\", title=\"Gradient\", xlab=\"logits\")\nscatter!(a, [gradient(mse,a,1)[1] for a=a], label=\"Autodiff\")\nsavefig(joinpath(www_path, \"loss_grad_mse_test.png\"))","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"(Image: )","category":"page"},{"location":"contributing/loss/#Example-in-2D","page":"Loss functions","title":"Example in 2D","text":"","category":"section"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"To understand the properties of the different loss functions we will now look at a toy example in 2D. The code below generates some random features and assigns labels based on a fixed vector of coefficients using the sigmoid function.","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"# Some random data:\nusing Flux, Random, CounterfactualExplanations.Data\nRandom.seed!(1234)\nN = 25\nw = [1.0 1.0]# true coefficients\nb = 0\nxs, ys = Data.toy_data_linear(N)\nX = hcat(xs...)\ncounterfactual_data = CounterfactualData(X,ys')","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"The plot below shows the samples coloured by label along with the decision boundary. You can think of this as representing the outcome of some automated decision making system. The highlighted sample was chosen to receive algorithmic recourse in the following: we will search for a counterfactual that leads to a label switch.","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"using CounterfactualExplanations\nusing CounterfactualExplanations.Models: LogisticModel\nM = LogisticModel(w, [b])\n\nRandom.seed!(1234)\nx = select_factual(counterfactual_data,rand(1:size(X)[2]))\ny = round(probs(M, x)[1])\ntarget = ifelse(y==1.0,0.0,1.0)\nŒ≥ = 0.75\n\n# Plot with random sample chose for recourse\nplt = plot_contour(X',ys,M)\nscatter!(plt,[x[1]],[x[2]],ms=10,label=\"\", color=Int(y))\nPlots.abline!(plt,-w[2]/w[1],b,color=\"black\",label=\"\",lw=2)\nsavefig(joinpath(www_path, \"loss_example.png\"))","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"(Image: )","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"Now we instantiate different generators for our different loss functions and different choices of Œª. Finally we generate recourse for each of them:","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"# Generating recourse\nŒõ = [0.0, 1.0, 5.0] # varying complexity penalties\nlosses = [:hinge_loss, :logitbinarycrossentropy, :mse]\ncounterfactuals = []\nfor loss in losses\n    for Œª in Œõ\n        generator = GenericGenerator(;loss=loss,Œª=Œª) \n        t = loss == :hinge_loss ? h(target) : target # mapping for hinge loss\n        counterfactual = generate_counterfactual(x, t, counterfactual_data, M, generator; Œ≥=Œ≥, T=50)\n        counterfactuals = vcat(counterfactuals, counterfactual)\n    end\nend","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"The code below plots the resulting counterfactual paths.","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"**Complexity penalty Œª***: has the expected effect of penalizing *long counterfactual paths: as the distance between x and x‚Ä≤ the penalty exerts more and more pressure on the gradient in the opposite direction ‚àá‚Ñì. For large choices of Œª valid recourse is not attainable.\n**Confidence threshold Œ≥***: note how for both log loss and hinge loss we overshoot a bit, that is we end up well beyond the decision boundary. This is because above we chose a confidence threshold of *Œ≥‚ÄÑ=‚ÄÑ0.75. In the context of recourse this choice matters a lot: we have a longer distance to travel (=higher costs for the individual), but we can be more confident that recourse will remain valid. There is of course an interplay between Œª and Œ≥.\nThe choice of the loss function matters: the distance-based MSE does NOT work without further ajustments when optimizing with respect to logits, as discussed above.","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"Overall, in the context of this toy example log loss arguably generates the most reasonable outcome: firstly, we can observe that the step size decreases at an increasing rate as the search approaches convergence (which may be desirable); secondly, it appears that increasing Œª leads to a roughly proportional decrease in the distance of the final counterfactual. This stands in contrast to the outcome for hinge loss, where increasing Œª from 0 to 1 barely has any effect at all.","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"# Plotting\nk = length(counterfactuals)\nfunction plot_recourse(counterfactual, t)\n    l = string(counterfactual.generator.loss)\n    l = l[1:minimum([5,length(l)])]\n    Œª = string(counterfactual.generator.Œª)\n    plt = plot_contour(X',ys,M;colorbar=false,title=\"Loss: $(l), Œª: $(Œª)\")\n    plt = plot(plt, size=(floor(‚àö(k)) * 350, ceil(‚àö(k)) * 350))\n    Plots.abline!(plt,-w[2]/w[1],b,color=\"black\",label=\"\",lw=2)\n    t = minimum([t, total_steps(counterfactual)])\n    scatter!(plt, hcat(path(counterfactual)[1:t]...)[1,:], hcat(path(counterfactual)[1:t]...)[2,:], ms=10, color=Int(y), label=\"\")\n    return plt\nend\nmax_path_length = maximum(map(counterfactual -> total_steps(counterfactual), counterfactuals))\nanim = @animate for i in 1:max_path_length\n    plots = map(counterfactual -> plot_recourse(counterfactual, i), counterfactuals)\n    plot(plots..., layout = (Int(floor(‚àö(k))), Int(ceil(‚àö(k)))), legend = false, plot_title=\"Iteration: \" * string(i))\nend\ngif(anim, joinpath(www_path, \"loss_paths.gif\"), fps=5)","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"(Image: )","category":"page"},{"location":"tutorials/interop/","page":"Interoperability","title":"Interoperability","text":"CurrentModule = CounterfactualExplanations ","category":"page"},{"location":"tutorials/interop/#Interoperability","page":"Interoperability","title":"Interoperability","text":"","category":"section"},{"location":"tutorials/interop/","page":"Interoperability","title":"Interoperability","text":"warning: Experimental feature\nOur work on language interoperability is still in its early stages. What follows is a proof-of-concept.","category":"page"},{"location":"tutorials/interop/","page":"Interoperability","title":"Interoperability","text":"The Julia language offers unique support for programming language interoperability. For example, calling Python and R is made remarkably easy through PyCall.jl and RCall.jl. In this tutorial we will see how CounterfactualExplanations.jl leverages this functionality. In particular, we will see that through minimal extra effort the package can be used to explain models that were developed in train in Python or R.","category":"page"},{"location":"tutorials/interop/","page":"Interoperability","title":"Interoperability","text":"To get started we will first load some two-dimensional toy data:","category":"page"},{"location":"tutorials/interop/","page":"Interoperability","title":"Interoperability","text":"using Random\n# Some random data:\nRandom.seed!(1234);\nN = 100\nusing CounterfactualExplanations\nusing CounterfactualExplanations.Data\nxs, ys = Data.toy_data_non_linear(N)\nX = hcat(xs...)\ncounterfactual_data = CounterfactualData(X,ys')","category":"page"},{"location":"tutorials/interop/#torch-model-trained-in-R","page":"Interoperability","title":"torch model trained in R","text":"","category":"section"},{"location":"tutorials/interop/","page":"Interoperability","title":"Interoperability","text":"The code below builds a simple MLP in R:","category":"page"},{"location":"tutorials/interop/","page":"Interoperability","title":"Interoperability","text":"using RCall\nR\"\"\"\n# Data\nlibrary(torch)\nX <- torch_tensor(t($X))\nys <- torch_tensor($ys)\n\n# Model:\nmlp <- nn_module(\n  initialize = function() {\n    self$layer1 <- nn_linear(2, 32)\n    self$layer2 <- nn_linear(32, 1)\n  },\n  forward = function(input) {\n    input <- self$layer1(input)\n    input <- nnf_sigmoid(input)\n    input <- self$layer2(input)\n    input\n  }\n)\nmodel <- mlp()\noptimizer <- optim_adam(model$parameters, lr = 0.1)\nloss_fun <- nnf_binary_cross_entropy_with_logits\n\"\"\"","category":"page"},{"location":"tutorials/interop/","page":"Interoperability","title":"Interoperability","text":"The following code trains the MLP for the binary prediction task at hand:","category":"page"},{"location":"tutorials/interop/","page":"Interoperability","title":"Interoperability","text":"R\"\"\"\nfor (epoch in 1:100) {\n\n  model$train()  \n\n  # Compute prediction and loss:\n  output <- model(X)[,1]\n  loss <- loss_fun(output, ys)\n\n  # Backpropagation:\n  optimizer$zero_grad()\n  loss$backward()\n  optimizer$step()\n  \n  cat(sprintf(\"Loss at epoch %d: %7f\\n\", epoch, loss$item()))\n}\n\"\"\"","category":"page"},{"location":"tutorials/interop/#Making-the-model-compatible","page":"Interoperability","title":"Making the model compatible","text":"","category":"section"},{"location":"tutorials/interop/","page":"Interoperability","title":"Interoperability","text":"As always we need to extend the logits and probs functions to make the model compatible with CounterfactualExplanations.jl. As evident from the code below, this is actually quite straight-forward: the logits are returned by the torch model and copied form R into the Julia environment. Probabilities are then computed in Julia, by passing the logits through the sigmoid function.","category":"page"},{"location":"tutorials/interop/","page":"Interoperability","title":"Interoperability","text":"using Flux\nusing CounterfactualExplanations, CounterfactualExplanations.Models\nimport CounterfactualExplanations.Models: logits, probs # import functions in order to extend\n\n# Step 1)\nstruct TorchNetwork <: Models.AbstractFittedModel\n    nn::Any\nend\n\n# Step 2)\nfunction logits(M::TorchNetwork, X::AbstractArray)\n  nn = M.nn\n  yÃÇ = rcopy(R\"as_array($nn(torch_tensor(t($X))))\")\n  yÃÇ = isa(yÃÇ, AbstractArray) ? yÃÇ : [yÃÇ]\n  return yÃÇ'\nend\nprobs(M::TorchNetwork, X::AbstractArray)= œÉ.(logits(M, X))\nM = TorchNetwork(R\"model\")","category":"page"},{"location":"tutorials/interop/#Adapting-the-generator","page":"Interoperability","title":"Adapting the generator","text":"","category":"section"},{"location":"tutorials/interop/","page":"Interoperability","title":"Interoperability","text":"Next we need to do a tiny bit of work on the AbstractGenerator side. By default methods underlying the GenericGenerator are desiged to work with models that have gradient access through Zygote.jl, one of Julia‚Äôs main autodifferentiation packages. Of course, Zygote.jl cannot access the gradients of our torch model, so we need to adapt the code slightly. Fortunately, it turns out that all we need to do is extend the function that computes the gradient with respect to the loss function for the generic counterfactual search: ‚àÇ‚Ñì(generator::GenericGenerator, x‚Ä≤, M, t). In particular, we will extend the function by a method that is specific to the TorchNetwork type we defined above. The code below implements this: our new method ‚àÇ‚Ñì calls R in order to use torch‚Äôs autodifferentiation functionality for computing the gradient.","category":"page"},{"location":"tutorials/interop/","page":"Interoperability","title":"Interoperability","text":"import CounterfactualExplanations.Generators: ‚àÇ‚Ñì\nusing LinearAlgebra\n\n# Countefactual loss:\nfunction ‚àÇ‚Ñì(generator::AbstractGradientBasedGenerator, counterfactual_state::CounterfactualState) \n  M = counterfactual_state.M\n  nn = M.nn\n  x‚Ä≤ = counterfactual_state.x‚Ä≤\n  t = counterfactual_state.target_encoded\n  R\"\"\"\n  x <- torch_tensor($x‚Ä≤, requires_grad=TRUE)\n  output <- $nn(x)\n  obj_loss <- nnf_binary_cross_entropy_with_logits(output,$t)\n  obj_loss$backward()\n  \"\"\"\n  grad = rcopy(R\"as_array(x$grad)\")\n  return grad\nend","category":"page"},{"location":"tutorials/interop/#Generating-counterfactuals","page":"Interoperability","title":"Generating counterfactuals","text":"","category":"section"},{"location":"tutorials/interop/","page":"Interoperability","title":"Interoperability","text":"From here on onwards we use the CounterfactualExplanations.jl functionality as always. Below we choose a random sample, define our generic generator and finally run the search:","category":"page"},{"location":"tutorials/interop/","page":"Interoperability","title":"Interoperability","text":"# Randomly selected factual:\nRandom.seed!(123)\nx = select_factual(counterfactual_data, rand(1:length(xs))) \ny = round(probs(M, x)[1])\ntarget = ifelse(y==1.0,0.0,1.0) # opposite label as target","category":"page"},{"location":"tutorials/interop/","page":"Interoperability","title":"Interoperability","text":"# Define generator:\ngenerator = GenericGenerator()\n# Generate recourse:\ncounterfactual = generate_counterfactual(x, target, counterfactual_data, M, generator)","category":"page"},{"location":"tutorials/interop/","page":"Interoperability","title":"Interoperability","text":"(Image: )","category":"page"},{"location":"tutorials/interop/#Training-a-torch-model-in-Python","page":"Interoperability","title":"Training a torch model in Python","text":"","category":"section"},{"location":"tutorials/interop/","page":"Interoperability","title":"Interoperability","text":"using PyCall\npy\"\"\"\n# Data\nimport torch\nfrom torch import nn\nX = torch.Tensor($X).T\nys = torch.Tensor($ys)\n\nclass MLP(nn.Module):\n  def __init__(self):\n    super(MLP, self).__init__()\n    self.model = nn.Sequential(\n      nn.Flatten(),\n      nn.Linear(2, 32),\n      nn.Sigmoid(),\n      nn.Linear(32, 1)\n    )\n\n  def forward(self, x):\n    logits = self.model(x)\n    return logits\n\nmodel = MLP()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.1)\nloss_fun = nn.BCEWithLogitsLoss()\n\"\"\"","category":"page"},{"location":"tutorials/interop/","page":"Interoperability","title":"Interoperability","text":"py\"\"\"\nfor epoch in range(100):\n  # Compute prediction and loss:\n  output = model(X).squeeze()\n  loss = loss_fun(output, ys)\n  \n  # Backpropagation:\n  optimizer.zero_grad()\n  loss.backward()\n  optimizer.step()\n  print(f\"Loss at epoch {epoch+1}: {loss.item():>7f}\")\n\"\"\"","category":"page"},{"location":"tutorials/interop/","page":"Interoperability","title":"Interoperability","text":"using Flux\nusing CounterfactualExplanations, CounterfactualExplanations.Models\nimport CounterfactualExplanations.Models: logits, probs # import functions in order to extend\n\n# Step 1)\nstruct PyTorchNetwork <: Models.AbstractFittedModel\n    nn::Any\nend\n\n# Step 2)\nfunction logits(M::PyTorchNetwork, X::AbstractArray)\n  nn = M.nn\n  if !isa(X, Matrix)\n    X = reshape(X, length(X), 1)\n  end\n  yÃÇ = py\"$nn(torch.Tensor($X).T).detach().numpy()\"\n  yÃÇ = isa(yÃÇ, AbstractArray) ? yÃÇ : [yÃÇ]\n  return yÃÇ\nend\nprobs(M::PyTorchNetwork, X::AbstractArray)= œÉ.(logits(M, X))\nM = PyTorchNetwork(py\"model\")","category":"page"},{"location":"tutorials/interop/","page":"Interoperability","title":"Interoperability","text":"import CounterfactualExplanations.Generators: ‚àÇ‚Ñì\nusing LinearAlgebra\n\n# Countefactual loss:\nfunction ‚àÇ‚Ñì(generator::AbstractGradientBasedGenerator, counterfactual_state::CounterfactualState) \n  M = counterfactual_state.M\n  nn = M.nn\n  x‚Ä≤ = counterfactual_state.x‚Ä≤\n  t = counterfactual_state.target_encoded\n  x = reshape(x‚Ä≤, 1, length(x‚Ä≤))\n  py\"\"\"\n  x = torch.Tensor($x)\n  x.requires_grad = True\n  t = torch.Tensor($[t]).squeeze()\n  output = $nn(x).squeeze()\n  obj_loss = nn.BCEWithLogitsLoss()(output,t)\n  obj_loss.backward()\n  \"\"\"\n  grad = vec(py\"x.grad.detach().numpy()\")\n  return grad\nend","category":"page"},{"location":"tutorials/interop/","page":"Interoperability","title":"Interoperability","text":"# Define generator:\ngenerator = GenericGenerator()\n# Generate recourse:\ncounterfactual = generate_counterfactual(x, target, counterfactual_data, M, generator)","category":"page"},{"location":"tutorials/interop/","page":"Interoperability","title":"Interoperability","text":"(Image: )","category":"page"},{"location":"reference/","page":"Reference","title":"Reference","text":"CurrentModule = CounterfactualExplanations ","category":"page"},{"location":"reference/#All-functions-and-types","page":"Reference","title":"All functions and types","text":"","category":"section"},{"location":"reference/","page":"Reference","title":"Reference","text":"","category":"page"},{"location":"reference/#Exported-functions","page":"Reference","title":"Exported functions","text":"","category":"section"},{"location":"reference/","page":"Reference","title":"Reference","text":"Modules = [CounterfactualExplanations, CounterfactualExplanations.Generators, CounterfactualExplanations.Models, CounterfactualExplanations.Losses]\nPrivate = false","category":"page"},{"location":"reference/#CounterfactualExplanations.generate_counterfactual-Tuple{Union{Int64, AbstractArray}, Union{Int64, AbstractFloat}, CounterfactualData, AbstractFittedModel, AbstractGenerator}","page":"Reference","title":"CounterfactualExplanations.generate_counterfactual","text":"generate_counterfactual(generator::AbstractGenerator, x::Vector, M::Models.AbstractFittedModel, target::AbstractFloat, Œ≥::AbstractFloat; T=1000)\n\nTakes a recourse generator, the factual sample x, the fitted model M, the target label and its desired threshold probability Œ≥. Returns the generated recourse (an object of type Recourse).\n\nExamples\n\nGeneric generator\n\nusing CounterfactualExplanations.Models\nw = [1.0 -2.0] # true coefficients\nb = [0]\nx = [-1,0.5]\ntarget = 1.0\nŒ≥ = 0.9\nM = LogisticModel(w, b)\ngenerator = GenericGenerator(0.1,0.1,1e-5,:logitbinarycrossentropy,nothing)\ncounterfactual = generate_counterfactual(generator, x, M, target, Œ≥); # generate recourse\n\nGreedy generator (Bayesian model only)\n\nusing Random, LinearAlgebra\nRandom.seed!(1234)\nŒº = [0 1.0 -2.0] # MAP coefficients\nŒ£ = Symmetric(reshape(randn(9),3,3).*0.1 + UniformScaling(1.0)) # MAP covariance matrix\nx = [-1,0.5]\ntarget = 1.0\nŒ≥ = 0.9\nM = CounterfactualExplanations.Models.BayesianLogisticModel(Œº, Œ£);\ngenerator = GreedyGenerator(0.01,20,:logitbinarycrossentropy,nothing)\ncounterfactual = generate_counterfactual(generator, x, M, target, Œ≥); # generate recourse\n\nSee also:\n\nGenericGenerator(Œª::AbstractFloat, œµ::AbstractFloat, œÑ::AbstractFloat, loss::Symbol, ùë≠::Union{Nothing,Vector{Symbol}})\nGreedyGenerator(Œ¥::AbstractFloat, n::Int64, loss::Symbol, ùë≠::Union{Nothing,Vector{Symbol}}).\n\n\n\n\n\n","category":"method"},{"location":"reference/#CounterfactualExplanations.Generators.AbstractGenerator","page":"Reference","title":"CounterfactualExplanations.Generators.AbstractGenerator","text":"AbstractGenerator\n\nAn abstract type that serves as the base type for recourse generators. \n\n\n\n\n\n","category":"type"},{"location":"reference/#CounterfactualExplanations.Generators.GenericGenerator","page":"Reference","title":"CounterfactualExplanations.Generators.GenericGenerator","text":"GenericGenerator(Œª::AbstractFloat, œµ::AbstractFloat, œÑ::AbstractFloat, loss::Symbol, ùë≠::Union{Nothing,Vector{Symbol}})\n\nA constructor for a generic recourse generator. It takes values for the complexity penalty Œª, the learning rate œµ, the tolerance for convergence œÑ,      the type of loss function to be used in the recourse objective and a mutability constraint mask ùë≠.\n\nExamples\n\ngenerator = GenericGenerator(0.1,0.1,1e-5,:logitbinarycrossentropy,nothing)\n\nSee also:\n\ngenerate_counterfactual(generator::AbstractGradientBasedGenerator, x::Vector, M::Models.AbstractFittedModel, target::AbstractFloat; T=1000)\n\n\n\n\n\n","category":"type"},{"location":"reference/#CounterfactualExplanations.Generators.GreedyGenerator","page":"Reference","title":"CounterfactualExplanations.Generators.GreedyGenerator","text":"GreedyGenerator(Œ¥::AbstractFloat, n::Int, loss::Symbol, ùë≠::Union{Nothing,Vector{Symbol}})\n\nConstructs a greedy recourse generator for Bayesian models. It takes values for the perturbation size Œ¥, the maximum number of times n that any feature can be changed,      the type of loss function to be used in the recourse objective and a mutability constraint mask ùë≠.\n\nExamples\n\ngenerator = GreedyGenerator(0.01,20,:logitbinarycrossentropy, nothing)\n\nSee also:\n\ngenerate_counterfactual(generator::AbstractGradientBasedGenerator, x::Vector, M::Models.AbstractFittedModel, target::AbstractFloat; T=1000)\n\n\n\n\n\n","category":"type"},{"location":"reference/#CounterfactualExplanations.Models.AbstractFittedModel","page":"Reference","title":"CounterfactualExplanations.Models.AbstractFittedModel","text":"AbstractFittedModel\n\nBase type for fitted models.\n\n\n\n\n\n","category":"type"},{"location":"reference/#CounterfactualExplanations.Models.BayesianLogisticModel","page":"Reference","title":"CounterfactualExplanations.Models.BayesianLogisticModel","text":"BayesianLogisticModel(Œº::Matrix,Œ£::Matrix)\n\nConstructs a Bayesian logistic classifier based on maximum a posteriori (MAP) estimates Œº (coefficients including constant term(s)) and Œ£ (covariance matrix). \n\nExamples\n\nusing Random, LinearAlgebra\nRandom.seed!(1234)\nŒº = [0 1.0 -2.0] # MAP coefficients\nŒ£ = Symmetric(reshape(randn(9),3,3).*0.1 + UniformScaling(1.0)) # MAP covariance matrix\nM = CounterfactualExplanations.Models.BayesianLogisticModel(Œº, Œ£);\n\nSee also:\n\nlogits(M::BayesianLogisticModel, X::AbstractArray)\nprobs(M::BayesianLogisticModel, X::AbstractArray)\n\n\n\n\n\n","category":"type"},{"location":"reference/#CounterfactualExplanations.Models.LogisticModel","page":"Reference","title":"CounterfactualExplanations.Models.LogisticModel","text":"LogisticModel(W::Matrix,b::AbstractArray)\n\nConstructs a logistic classifier based on arrays containing coefficients w and constant terms b.\n\nExamples\n\nw = [1.0 -2.0] # estimated coefficients\nb = [0] # estimated constant\nM = CounterfactualExplanations.Models.LogisticModel(w, b);\n\nSee also: \n\nlogits(M::LogisticModel, X::AbstractArray)\nprobs(M::LogisticModel, X::AbstractArray)\n\n\n\n\n\n","category":"type"},{"location":"reference/#CounterfactualExplanations.Models.logits-Tuple{BayesianLogisticModel, AbstractArray}","page":"Reference","title":"CounterfactualExplanations.Models.logits","text":"logits(M::BayesianLogisticModel, X::AbstractArray)\n\nComputes logits as Œº[1·µÄ X·µÄ]·µÄ.\n\nExamples\n\nusing CounterfactualExplanations.Models\nusing Random, LinearAlgebra\nRandom.seed!(1234)\nŒº = [0 1.0 -2.0] # MAP coefficients\nŒ£ = Symmetric(reshape(randn(9),3,3).*0.1 + UniformScaling(1.0)) # MAP covariance matrix\nM = BayesianLogisticModel(Œº, Œ£);\nx = [1,1]\nlogits(M, x)\n\nSee also BayesianLogisticModel(Œº::Matrix,Œ£::Matrix)\n\n\n\n\n\n","category":"method"},{"location":"reference/#CounterfactualExplanations.Models.logits-Tuple{LogisticModel, AbstractArray}","page":"Reference","title":"CounterfactualExplanations.Models.logits","text":"logits(M::LogisticModel, X::AbstractArray)\n\nComputes logits as WX+b.\n\nExamples\n\nusing CounterfactualExplanations.Models\nw = [1.0 -2.0] # estimated coefficients\nb = [0] # estimated constant\nM = LogisticModel(w, b);\nx = [1,1]\nlogits(M, x)\n\nSee also LogisticModel(W::Matrix,b::AbstractArray).\n\n\n\n\n\n","category":"method"},{"location":"reference/#CounterfactualExplanations.Models.probs-Tuple{BayesianLogisticModel, AbstractArray}","page":"Reference","title":"CounterfactualExplanations.Models.probs","text":"probs(M::BayesianLogisticModel, X::AbstractArray)\n\nComputes predictive probabilities using a Probit approximation. \n\nExamples\n\nusing CounterfactualExplanations.Models\nusing Random, LinearAlgebra\nRandom.seed!(1234)\nŒº = [0 1.0 -2.0] # MAP coefficients\nŒ£ = Symmetric(reshape(randn(9),3,3).*0.1 + UniformScaling(1.0)) # MAP covariance matrix\nM = BayesianLogisticModel(Œº, Œ£);\nx = [1,1]\nprobs(M, x)\n\nSee also BayesianLogisticModel(Œº::Matrix,Œ£::Matrix)\n\n\n\n\n\n","category":"method"},{"location":"reference/#CounterfactualExplanations.Models.probs-Tuple{LogisticModel, AbstractArray}","page":"Reference","title":"CounterfactualExplanations.Models.probs","text":"probs(M::LogisticModel, X::AbstractArray)\n\nComputes predictive probabilities from logits as œÉ(WX+b) where 'œÉ' is the sigmoid function. \n\nExamples\n\nusing CounterfactualExplanations.Models\nw = [1.0 -2.0] # estimated coefficients\nb = [0] # estimated constant\nM = LogisticModel(w, b);\nx = [1,1]\nprobs(M, x)\n\nSee also LogisticModel(W::Matrix,b::AbstractArray).\n\n\n\n\n\n","category":"method"},{"location":"reference/#Flux.Losses.binary_focal_loss-Tuple{Any, Any}","page":"Reference","title":"Flux.Losses.binary_focal_loss","text":"binary_focal_loss(yÃÇ, y; agg=mean, Œ≥=2, œµ=eps(yÃÇ))\n\nReturn the binaryfocalloss The input, 'yÃÇ', is expected to be normalized (i.e. softmax output).\n\nFor Œ≥ == 0, the loss is mathematically equivalent to Losses.binarycrossentropy.\n\nExample\n\njulia> y = [0  1  0\n            1  0  1]\n2√ó3 Matrix{Int64}:\n 0  1  0\n 1  0  1\n\njulia> ≈∑ = [0.268941  0.5  0.268941\n            0.731059  0.5  0.731059]\n2√ó3 Matrix{Float64}:\n 0.268941  0.5  0.268941\n 0.731059  0.5  0.731059\n\njulia> Flux.binary_focal_loss(≈∑, y) ‚âà 0.0728675615927385\ntrue\n\nSee also: Losses.focal_loss for multi-class setting\n\n\n\n\n\n","category":"method"},{"location":"reference/#Flux.Losses.binarycrossentropy-Tuple{Any, Any}","page":"Reference","title":"Flux.Losses.binarycrossentropy","text":"binarycrossentropy(yÃÇ, y; agg = mean, œµ = eps(yÃÇ))\n\nReturn the binary cross-entropy loss, computed as\n\nagg(@.(-y * log(yÃÇ + œµ) - (1 - y) * log(1 - yÃÇ + œµ)))\n\nWhere typically, the prediction yÃÇ is given by the output of a sigmoid activation. The œµ term is included to avoid infinity. Using logitbinarycrossentropy is recomended over binarycrossentropy for numerical stability.\n\nUse label_smoothing to smooth the y value as preprocessing before computing the loss.\n\nSee also: crossentropy, logitcrossentropy.\n\nExamples\n\njulia> y_bin = Bool[1,0,1]\n3-element Vector{Bool}:\n 1\n 0\n 1\n\njulia> y_prob = softmax(reshape(vcat(1:3, 3:5), 2, 3) .* 1f0)\n2√ó3 Matrix{Float32}:\n 0.268941  0.5  0.268941\n 0.731059  0.5  0.731059\n\njulia> Flux.binarycrossentropy(y_prob[2,:], y_bin)\n0.43989f0\n\njulia> all(p -> 0 < p < 1, y_prob[2,:])  # else DomainError\ntrue\n\njulia> y_hot = Flux.onehotbatch(y_bin, 0:1)\n2√ó3 OneHotMatrix(::Vector{UInt32}) with eltype Bool:\n ‚ãÖ  1  ‚ãÖ\n 1  ‚ãÖ  1\n\njulia> Flux.crossentropy(y_prob, y_hot)\n0.43989f0\n\n\n\n\n\n","category":"method"},{"location":"reference/#Flux.Losses.crossentropy-Tuple{Any, Any}","page":"Reference","title":"Flux.Losses.crossentropy","text":"crossentropy(yÃÇ, y; dims = 1, œµ = eps(yÃÇ), agg = mean)\n\nReturn the cross entropy between the given probability distributions; calculated as\n\nagg(-sum(y .* log.(yÃÇ .+ œµ); dims))\n\nCross entropy is typically used as a loss in multi-class classification, in which case the labels y are given in a one-hot format. dims specifies the dimension (or the dimensions) containing the class probabilities. The prediction yÃÇ is supposed to sum to one across dims, as would be the case with the output of a softmax operation.\n\nFor numerical stability, it is recommended to use logitcrossentropy rather than softmax followed by crossentropy .\n\nUse label_smoothing to smooth the true labels as preprocessing before computing the loss.\n\nSee also: logitcrossentropy, binarycrossentropy, logitbinarycrossentropy.\n\nExample\n\njulia> y_label = Flux.onehotbatch([0, 1, 2, 1, 0], 0:2)\n3√ó5 OneHotMatrix(::Vector{UInt32}) with eltype Bool:\n 1  ‚ãÖ  ‚ãÖ  ‚ãÖ  1\n ‚ãÖ  1  ‚ãÖ  1  ‚ãÖ\n ‚ãÖ  ‚ãÖ  1  ‚ãÖ  ‚ãÖ\n\njulia> y_model = softmax(reshape(-7:7, 3, 5) .* 1f0)\n3√ó5 Matrix{Float32}:\n 0.0900306  0.0900306  0.0900306  0.0900306  0.0900306\n 0.244728   0.244728   0.244728   0.244728   0.244728\n 0.665241   0.665241   0.665241   0.665241   0.665241\n\njulia> sum(y_model; dims=1)\n1√ó5 Matrix{Float32}:\n 1.0  1.0  1.0  1.0  1.0\n\njulia> Flux.crossentropy(y_model, y_label)\n1.6076053f0\n\njulia> 5 * ans ‚âà Flux.crossentropy(y_model, y_label; agg=sum)\ntrue\n\njulia> y_smooth = Flux.label_smoothing(y_label, 0.15f0)\n3√ó5 Matrix{Float32}:\n 0.9   0.05  0.05  0.05  0.9\n 0.05  0.9   0.05  0.9   0.05\n 0.05  0.05  0.9   0.05  0.05\n\njulia> Flux.crossentropy(y_model, y_smooth)\n1.5776052f0\n\n\n\n\n\n","category":"method"},{"location":"reference/#Flux.Losses.ctc_loss-Tuple{AbstractArray, Any}","page":"Reference","title":"Flux.Losses.ctc_loss","text":"ctc_loss(yÃÇ, y)\n\nComputes the connectionist temporal classification loss between yÃÇ and y.\n\nyÃÇ must be a classes-by-time matrices, i.e., each row represents a class and each column represents a time step. Additionally, the logsoftmax function will be applied to yÃÇ, so yÃÇ must be the raw activation values from the neural network and not, for example, the activations after being passed through a softmax activation function. y must be a 1D array of the labels associated with yÃÇ. The blank label is assumed to be the last label category in yÃÇ, so it is equivalent to size(yÃÇ, 1).\n\nUsed for sequence-to-sequence classification problems such as speech recognition and handwriting recognition where the exact time-alignment of the output (e.g., letters) is not needed to solve the problem. See Graves et al. (2006) or Graves (2012) for mathematical details.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Flux.Losses.dice_coeff_loss-Tuple{Any, Any}","page":"Reference","title":"Flux.Losses.dice_coeff_loss","text":"dice_coeff_loss(yÃÇ, y; smooth = 1)\n\nReturn a loss based on the dice coefficient. Used in the V-Net image segmentation architecture. Similar to the F1_score. Calculated as:\n\n1 - 2*sum(|yÃÇ .* y| + smooth) / (sum(yÃÇ.^2) + sum(y.^2) + smooth)\n\n\n\n\n\n","category":"method"},{"location":"reference/#Flux.Losses.focal_loss-Tuple{Any, Any}","page":"Reference","title":"Flux.Losses.focal_loss","text":"focal_loss(yÃÇ, y; dims=1, agg=mean, Œ≥=2, œµ=eps(yÃÇ))\n\nReturn the focal_loss which can be used in classification tasks with highly imbalanced classes. It down-weights well-classified examples and focuses on hard examples. The input, 'yÃÇ', is expected to be normalized (i.e. softmax output).\n\nThe modulating factor, Œ≥, controls the down-weighting strength. For Œ≥ == 0, the loss is mathematically equivalent to Losses.crossentropy.\n\nExample\n\njulia> y = [1  0  0  0  1\n            0  1  0  1  0\n            0  0  1  0  0]\n3√ó5 Matrix{Int64}:\n 1  0  0  0  1\n 0  1  0  1  0\n 0  0  1  0  0\n\njulia> ≈∑ = softmax(reshape(-7:7, 3, 5) .* 1f0)\n3√ó5 Matrix{Float32}:\n 0.0900306  0.0900306  0.0900306  0.0900306  0.0900306\n 0.244728   0.244728   0.244728   0.244728   0.244728\n 0.665241   0.665241   0.665241   0.665241   0.665241\n\njulia> Flux.focal_loss(≈∑, y) ‚âà 1.1277571935622628\ntrue\n\nSee also: Losses.binary_focal_loss for binary (not one-hot) labels\n\n\n\n\n\n","category":"method"},{"location":"reference/#Flux.Losses.hinge_loss-Tuple{Any, Any}","page":"Reference","title":"Flux.Losses.hinge_loss","text":"hinge_loss(yÃÇ, y; agg = mean)\n\nReturn the hinge_loss loss given the prediction yÃÇ and true labels y (containing 1 or -1); calculated as sum(max.(0, 1 .- yÃÇ .* y)) / size(y, 2).\n\nSee also: squared_hinge_loss\n\n\n\n\n\n","category":"method"},{"location":"reference/#Flux.Losses.huber_loss-Tuple{Any, Any}","page":"Reference","title":"Flux.Losses.huber_loss","text":"huber_loss(yÃÇ, y; Œ¥ = 1, agg = mean)\n\nReturn the mean of the Huber loss given the prediction yÃÇ and true values y.\n\n             | 0.5 * |yÃÇ - y|^2,            for |yÃÇ - y| <= Œ¥\nHuber loss = |\n             |  Œ¥ * (|yÃÇ - y| - 0.5 * Œ¥), otherwise\n\n\n\n\n\n","category":"method"},{"location":"reference/#Flux.Losses.kldivergence-Tuple{Any, Any}","page":"Reference","title":"Flux.Losses.kldivergence","text":"kldivergence(yÃÇ, y; agg = mean, œµ = eps(yÃÇ))\n\nReturn the Kullback-Leibler divergence between the given probability distributions.\n\nThe KL divergence is a measure of how much one probability distribution is different from the other. It is always non-negative, and zero only when both the distributions are equal.\n\nExample\n\njulia> p1 = [1 0; 0 1]\n2√ó2 Matrix{Int64}:\n 1  0\n 0  1\n\njulia> p2 = fill(0.5, 2, 2)\n2√ó2 Matrix{Float64}:\n 0.5  0.5\n 0.5  0.5\n\njulia> Flux.kldivergence(p2, p1) ‚âà log(2)\ntrue\n\njulia> Flux.kldivergence(p2, p1; agg = sum) ‚âà 2log(2)\ntrue\n\njulia> Flux.kldivergence(p2, p2; œµ = 0)  # about -2e-16 with the regulator\n0.0\n\njulia> Flux.kldivergence(p1, p2; œµ = 0)  # about 17.3 with the regulator\nInf\n\n\n\n\n\n","category":"method"},{"location":"reference/#Flux.Losses.label_smoothing-Tuple{Union{Number, AbstractArray}, Number}","page":"Reference","title":"Flux.Losses.label_smoothing","text":"label_smoothing(y::Union{Number, AbstractArray}, Œ±; dims::Int=1)\n\nReturns smoothed labels, meaning the confidence on label values are relaxed.\n\nWhen y is given as one-hot vector or batch of one-hot, its calculated as\n\ny .* (1 - Œ±) .+ Œ± / size(y, dims)\n\nwhen y is given as a number or batch of numbers for binary classification, its calculated as\n\ny .* (1 - Œ±) .+ Œ± / 2\n\nin which case the labels are squeezed towards 0.5.\n\nŒ± is a number in interval (0, 1) called the smoothing factor. Higher the value of Œ± larger the smoothing of y.\n\ndims denotes the one-hot dimension, unless dims=0 which denotes the application of label smoothing to binary distributions encoded in a single number.\n\nExample\n\njulia> y = Flux.onehotbatch([1, 1, 1, 0, 1, 0], 0:1)\n2√ó6 OneHotMatrix(::Vector{UInt32}) with eltype Bool:\n ‚ãÖ  ‚ãÖ  ‚ãÖ  1  ‚ãÖ  1\n 1  1  1  ‚ãÖ  1  ‚ãÖ\n\njulia> y_smoothed = Flux.label_smoothing(y, 0.2f0)\n2√ó6 Matrix{Float32}:\n 0.1  0.1  0.1  0.9  0.1  0.9\n 0.9  0.9  0.9  0.1  0.9  0.1\n\njulia> y_sim = softmax(y .* log(2f0))\n2√ó6 Matrix{Float32}:\n 0.333333  0.333333  0.333333  0.666667  0.333333  0.666667\n 0.666667  0.666667  0.666667  0.333333  0.666667  0.333333\n\njulia> y_dis = vcat(y_sim[2,:]', y_sim[1,:]')\n2√ó6 Matrix{Float32}:\n 0.666667  0.666667  0.666667  0.333333  0.666667  0.333333\n 0.333333  0.333333  0.333333  0.666667  0.333333  0.666667\n\njulia> Flux.crossentropy(y_sim, y) < Flux.crossentropy(y_sim, y_smoothed)\ntrue\n\njulia> Flux.crossentropy(y_dis, y) > Flux.crossentropy(y_dis, y_smoothed)\ntrue\n\n\n\n\n\n","category":"method"},{"location":"reference/#Flux.Losses.logitbinarycrossentropy-Tuple{Any, Any}","page":"Reference","title":"Flux.Losses.logitbinarycrossentropy","text":"logitbinarycrossentropy(≈∑, y; agg = mean)\n\nMathematically equivalent to binarycrossentropy(œÉ(≈∑), y) but is more numerically stable.\n\nSee also: crossentropy, logitcrossentropy.\n\nExamples\n\njulia> y_bin = Bool[1,0,1];\n\njulia> y_model = Float32[2, -1, pi]\n3-element Vector{Float32}:\n  2.0\n -1.0\n  3.1415927\n\njulia> Flux.logitbinarycrossentropy(y_model, y_bin)\n0.160832f0\n\njulia> Flux.binarycrossentropy(sigmoid.(y_model), y_bin)\n0.16083185f0\n\n\n\n\n\n","category":"method"},{"location":"reference/#Flux.Losses.logitcrossentropy-Tuple{Any, Any}","page":"Reference","title":"Flux.Losses.logitcrossentropy","text":"logitcrossentropy(yÃÇ, y; dims = 1, agg = mean)\n\nReturn the cross entropy calculated by\n\nagg(-sum(y .* logsoftmax(yÃÇ; dims); dims))\n\nThis is mathematically equivalent to crossentropy(softmax(yÃÇ), y), but is more numerically stable than using functions crossentropy and softmax separately.\n\nSee also: binarycrossentropy, logitbinarycrossentropy, label_smoothing.\n\nExample\n\njulia> y_label = Flux.onehotbatch(collect(\"abcabaa\"), 'a':'c')\n3√ó7 OneHotMatrix(::Vector{UInt32}) with eltype Bool:\n 1  ‚ãÖ  ‚ãÖ  1  ‚ãÖ  1  1\n ‚ãÖ  1  ‚ãÖ  ‚ãÖ  1  ‚ãÖ  ‚ãÖ\n ‚ãÖ  ‚ãÖ  1  ‚ãÖ  ‚ãÖ  ‚ãÖ  ‚ãÖ\n\njulia> y_model = reshape(vcat(-9:0, 0:9, 7.5f0), 3, 7)\n3√ó7 Matrix{Float32}:\n -9.0  -6.0  -3.0  0.0  2.0  5.0  8.0\n -8.0  -5.0  -2.0  0.0  3.0  6.0  9.0\n -7.0  -4.0  -1.0  1.0  4.0  7.0  7.5\n\njulia> Flux.logitcrossentropy(y_model, y_label)\n1.5791205f0\n\njulia> Flux.crossentropy(softmax(y_model), y_label)\n1.5791197f0\n\n\n\n\n\n","category":"method"},{"location":"reference/#Flux.Losses.mae-Tuple{Any, Any}","page":"Reference","title":"Flux.Losses.mae","text":"mae(yÃÇ, y; agg = mean)\n\nReturn the loss corresponding to mean absolute error:\n\nagg(abs.(yÃÇ .- y))\n\nExample\n\njulia> y_model = [1.1, 1.9, 3.1];\n\njulia> Flux.mae(y_model, 1:3)\n0.10000000000000009\n\n\n\n\n\n","category":"method"},{"location":"reference/#Flux.Losses.mse-Tuple{Any, Any}","page":"Reference","title":"Flux.Losses.mse","text":"mse(yÃÇ, y; agg = mean)\n\nReturn the loss corresponding to mean square error:\n\nagg((yÃÇ .- y) .^ 2)\n\nSee also: mae, msle, crossentropy.\n\nExample\n\njulia> y_model = [1.1, 1.9, 3.1];\n\njulia> y_true = 1:3;\n\njulia> Flux.mse(y_model, y_true)\n0.010000000000000018\n\n\n\n\n\n","category":"method"},{"location":"reference/#Flux.Losses.msle-Tuple{Any, Any}","page":"Reference","title":"Flux.Losses.msle","text":"msle(yÃÇ, y; agg = mean, œµ = eps(yÃÇ))\n\nThe loss corresponding to mean squared logarithmic errors, calculated as\n\nagg((log.(yÃÇ .+ œµ) .- log.(y .+ œµ)) .^ 2)\n\nThe œµ term provides numerical stability. Penalizes an under-estimation more than an over-estimatation.\n\nExample\n\njulia> Flux.msle(Float32[1.1, 2.2, 3.3], 1:3)\n0.009084041f0\n\njulia> Flux.msle(Float32[0.9, 1.8, 2.7], 1:3)\n0.011100831f0\n\n\n\n\n\n","category":"method"},{"location":"reference/#Flux.Losses.poisson_loss-Tuple{Any, Any}","page":"Reference","title":"Flux.Losses.poisson_loss","text":"poisson_loss(yÃÇ, y)\n\nReturn how much the predicted distribution yÃÇ diverges from the expected Poisson\n\ndistribution y; calculated as sum(yÃÇ .- y .* log.(yÃÇ)) / size(y, 2).\n\nMore information..\n\n\n\n\n\n","category":"method"},{"location":"reference/#Flux.Losses.squared_hinge_loss-Tuple{Any, Any}","page":"Reference","title":"Flux.Losses.squared_hinge_loss","text":"squared_hinge_loss(yÃÇ, y)\n\nReturn the squared hinge_loss loss given the prediction yÃÇ and true labels y (containing 1 or -1); calculated as sum((max.(0, 1 .- yÃÇ .* y)).^2) / size(y, 2).\n\nSee also: hinge_loss\n\n\n\n\n\n","category":"method"},{"location":"reference/#Flux.Losses.tversky_loss-Tuple{Any, Any}","page":"Reference","title":"Flux.Losses.tversky_loss","text":"tversky_loss(yÃÇ, y; Œ≤ = 0.7)\n\nReturn the Tversky loss. Used with imbalanced data to give more weight to false negatives. Larger Œ≤ weigh recall more than precision (by placing more emphasis on false negatives) Calculated as:     1 - sum(|y .* yÃÇ| + 1) / (sum(y .* yÃÇ + Œ≤(1 .- y) . yÃÇ + (1 - Œ≤)y . (1 .- yÃÇ)) + 1)\n\n\n\n\n\n","category":"method"},{"location":"reference/#Internal-functions","page":"Reference","title":"Internal functions","text":"","category":"section"},{"location":"reference/","page":"Reference","title":"Reference","text":"Modules = [CounterfactualExplanations, CounterfactualExplanations.Generators, CounterfactualExplanations.Models, CounterfactualExplanations.Losses]\nPublic = false","category":"page"},{"location":"reference/#Flux.Losses.add_blanks-Tuple{Any, Any}","page":"Reference","title":"Flux.Losses.add_blanks","text":"add_blanks(z)\n\nAdds blanks to the start and end of z, and between items in z\n\n\n\n\n\n","category":"method"},{"location":"reference/#Flux.Losses.logaddexp-Tuple{Any, Any}","page":"Reference","title":"Flux.Losses.logaddexp","text":"logaddexp(a, b) Adds log-space a and b such that the result equals log(exp(a)+exp(b))\n\n\n\n\n\n","category":"method"},{"location":"reference/#Flux.Losses.xlogx-Tuple{Any}","page":"Reference","title":"Flux.Losses.xlogx","text":"xlogx(x)\n\nReturn x * log(x) for x ‚â• 0, handling x == 0 by taking the limit from above, to get zero.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Flux.Losses.xlogy-Tuple{Any, Any}","page":"Reference","title":"Flux.Losses.xlogy","text":"xlogy(x, y)\n\nReturn x * log(y) for y > 0, and zero when x == 0.\n\n\n\n\n\n","category":"method"},{"location":"cats_dogs/","page":"Motivating example","title":"Motivating example","text":"CurrentModule = CounterfactualExplanations","category":"page"},{"location":"cats_dogs/#From-to-a-motivating-example","page":"Motivating example","title":"From üê± to üê∂ - a motivating example","text":"","category":"section"},{"location":"cats_dogs/","page":"Motivating example","title":"Motivating example","text":"Suppose we have a sample of cats and dogs with information about two features: height and tail length. Based on these two features we have trained two black box classifiers to distinguish between cats and dogs: firstly, an artificial neural network with weight regularization and secondly, that same neural network but its Bayesian counterpart (Figure¬†1 below). One individual cat ‚Äì let‚Äôs call her Kitty üê± ‚Äì is friends with a lot of cool dogs and wants to be part of that group. Let‚Äôs see how we can generate counterfactual paths for her.","category":"page"},{"location":"cats_dogs/","page":"Motivating example","title":"Motivating example","text":"(Image: Figure 1: Classification for toy dataset of cats and dogs. The contour indicates confidence in predicted labels. Left: MLP with weight regularization. Right: That same MLP, but with Laplace approximation for posterior predictive.)","category":"page"},{"location":"cats_dogs/#From-basic-principles-‚Ä¶","page":"Motivating example","title":"From basic principles ‚Ä¶","text":"","category":"section"},{"location":"cats_dogs/","page":"Motivating example","title":"Motivating example","text":"Counterfactual search happens in the feature space: we are interested in understanding how we need to change üê±‚Äôs attributes in order to change the output of the black-box classifier. We will start with the first model, that relies on simple plugin estimates to produce its predictions. The model was built and pre-trained using Flux and can be loaded as follows:","category":"page"},{"location":"cats_dogs/","page":"Motivating example","title":"Motivating example","text":"using CounterfactualExplanations\nusing CounterfactualExplanations.Data: cats_dogs_model\nmodel = cats_dogs_model()","category":"page"},{"location":"cats_dogs/","page":"Motivating example","title":"Motivating example","text":"The training data can be loaded and pre-processed as follows:","category":"page"},{"location":"cats_dogs/","page":"Motivating example","title":"Motivating example","text":"using CounterfactualExplanations.Data: cats_dogs_data\nX, ys = cats_dogs_data()\ncounterfactual_data = CounterfactualData(X,ys')","category":"page"},{"location":"cats_dogs/","page":"Motivating example","title":"Motivating example","text":"In order to make the Flux.jl model compatible with CounterfactualExplanations.jl we need to run the following (more on this in the models tutorial):","category":"page"},{"location":"cats_dogs/","page":"Motivating example","title":"Motivating example","text":"using CounterfactualExplanations.Models\nimport CounterfactualExplanations.Models: logits, probs # import functions in order to extend\n\n# Step 1)\nstruct NeuralNetwork <: Models.AbstractFittedModel\n    model::Any\nend\n\n# Step 2)\nlogits(M::NeuralNetwork, X::AbstractArray) = M.model(X)\nprobs(M::NeuralNetwork, X::AbstractArray)= œÉ.(logits(M, X))\nM = NeuralNetwork(model);","category":"page"},{"location":"cats_dogs/","page":"Motivating example","title":"Motivating example","text":"Let x be the 2D-feature vector describing Kitty üê±. Based on those features she is currently labelled as y = 0.0. We have set the target label to 1.0 and the desired confidence in the prediction to Œ≥ = 0.75. Now we can use the GenericGenerator for our counterfactual search as follows:","category":"page"},{"location":"cats_dogs/","page":"Motivating example","title":"Motivating example","text":"# Define generator:\ngenerator = GenericGenerator()\n# Generate recourse:\ncounterfactual = generate_counterfactual(x, target, counterfactual_data, M, generator)","category":"page"},{"location":"cats_dogs/","page":"Motivating example","title":"Motivating example","text":"The GenericGenerator implements the search algorithm first proposed by Wachter, Mittelstadt, and Russell (2017). The resulting counterfactual path is shown in Figure¬†2 below. We can see that üê± travels through the feature space until she reaches a destination where the black-box model predicts that with a probability of more than 75% she is actually a dog. Her counterfactual self is in the target class so the algorithmic recourse objective is satisfied. We have also gained an intuitive understanding of how the black-model arrives at its decisions: increasing height and decreasing tail length both raise the predicted probability that üê± is actually a dog.","category":"page"},{"location":"cats_dogs/","page":"Motivating example","title":"Motivating example","text":"(Image: Figure 2: Classification for toy dataset of cats and dogs. The contour indicates confidence in predicted labels. Left: MLP with weight regularization. Right: That same MLP, but with Laplace approximation for posterior predictive.)","category":"page"},{"location":"cats_dogs/#‚Ä¶-towards-realistic-counterfactuals.","page":"Motivating example","title":"‚Ä¶ towards realistic counterfactuals.","text":"","category":"section"},{"location":"cats_dogs/","page":"Motivating example","title":"Motivating example","text":"The generic search above yielded a counterfactual sample that is still quite distinct from all other individuals in the target class. While we successfully fooled the black-box model, a human might look at üê±‚Äôs counterfactual self and get a little suspicious. One of the requirements for algorithmic recourse is that counterfactuals are realistic and unambigous. A straight-forward way to meet this requirement is to generate counterfactuals by implicitly minimizing predictive uncertainty (Schut et al. 2021). The simple neural network does not incorporate uncertainty, but its Bayesian counterpart does: note how in Figure¬†1 above the contours for the Bayesian neural network (Laplace) fan out away from the sample. As before we will be using a pre-trained model. Laplace approximation was implemented using BayesLaplace.jl (see here for an introduction). The pre-trained Bayesian model can be loaded as follows:","category":"page"},{"location":"cats_dogs/","page":"Motivating example","title":"Motivating example","text":"using CounterfactualExplanations.Data: cats_dogs_laplace\nla = cats_dogs_laplace()","category":"page"},{"location":"cats_dogs/","page":"Motivating example","title":"Motivating example","text":"As before we need to make the model compatible with CounterfactualExplanations.jl:","category":"page"},{"location":"cats_dogs/","page":"Motivating example","title":"Motivating example","text":"# Step 1)\nstruct LaplaceNeuralNetwork <: Models.AbstractFittedModel\n    la::BayesLaplace.LaplaceRedux\nend\n\n# Step 2)\nlogits(M::LaplaceNeuralNetwork, X::AbstractArray) = M.la.model(X)\nprobs(M::LaplaceNeuralNetwork, X::AbstractArray)= BayesLaplace.predict(M.la, X)\nM·¥∏ = LaplaceNeuralNetwork(la);","category":"page"},{"location":"cats_dogs/","page":"Motivating example","title":"Motivating example","text":"Using the same target and desired confidence Œ≥ as above we finally use the GreedyGenerator generator for our counterfactual search:","category":"page"},{"location":"cats_dogs/","page":"Motivating example","title":"Motivating example","text":"generator = GreedyGenerator(Dict(:Œ¥=>0.1,:n=>15))\ncounterfactual = generate_counterfactual(x, target, counterfactual_data, M, generator)","category":"page"},{"location":"cats_dogs/","page":"Motivating example","title":"Motivating example","text":"The GreedyGenerator implements the approach proposed in Schut et al. (2021): by maximizing the predicted probability of the Bayesian model in Figure¬†3 below, we implicitly minimize the predictive uncertainty around the counterfactual. This way we end up generating a counterfactual that looks more like the individuals üê∂ in the target class and is therefore more realistic.","category":"page"},{"location":"cats_dogs/","page":"Motivating example","title":"Motivating example","text":"(Image: Figure 3: Classification for toy dataset of cats and dogs. The contour indicates confidence in predicted labels. Left: MLP with weight regularization. Right: That same MLP, but with Laplace approximation for posterior predictive.)","category":"page"},{"location":"cats_dogs/#References","page":"Motivating example","title":"References","text":"","category":"section"},{"location":"cats_dogs/","page":"Motivating example","title":"Motivating example","text":"Schut, Lisa, Oscar Key, Rory Mc Grath, Luca Costabello, Bogdan Sacaleanu, Yarin Gal, et al. 2021. ‚ÄúGenerating Interpretable Counterfactual Explanations by Implicit Minimisation of Epistemic and Aleatoric Uncertainties.‚Äù In International Conference on Artificial Intelligence and Statistics, 1756‚Äì64. PMLR.","category":"page"},{"location":"cats_dogs/","page":"Motivating example","title":"Motivating example","text":"Wachter, Sandra, Brent Mittelstadt, and Chris Russell. 2017. ‚ÄúCounterfactual Explanations Without Opening the Black Box: Automated Decisions and the GDPR.‚Äù Harv. JL & Tech. 31: 841.","category":"page"},{"location":"examples/image/MNIST/","page":"MNIST","title":"MNIST","text":"CurrentModule = CounterfactualExplanations ","category":"page"},{"location":"examples/image/MNIST/#MNIST","page":"MNIST","title":"MNIST","text":"","category":"section"},{"location":"examples/image/MNIST/","page":"MNIST","title":"MNIST","text":"In this example we will see how different counterfactual generators can be used to explain deep learning models for image classification. In particular, we will look at MNIST data and visually inspect how the different generators perturb images of handwritten digits in order to change the predicted label to a target label. Figure¬†1 shows a random sample of handwritten digits.","category":"page"},{"location":"examples/image/MNIST/","page":"MNIST","title":"MNIST","text":"(Image: Figure 1: A few random handwritten digits.)","category":"page"},{"location":"examples/image/MNIST/#Pre-trained-classifiers","page":"MNIST","title":"Pre-trained classifiers","text":"","category":"section"},{"location":"examples/image/MNIST/","page":"MNIST","title":"MNIST","text":"Next we will load two pre-trained deep-learning classifiers:","category":"page"},{"location":"examples/image/MNIST/","page":"MNIST","title":"MNIST","text":"Simple MLP - model\nDeep ensemble - ensemble","category":"page"},{"location":"examples/image/MNIST/","page":"MNIST","title":"MNIST","text":"using Flux\nusing CounterfactualExplanations.Data: mnist_data, mnist_model, mnist_ensemble\ndata, X, ys = mnist_data()\nmodel = mnist_model()\nensemble = mnist_ensemble()","category":"page"},{"location":"examples/image/MNIST/","page":"MNIST","title":"MNIST","text":"The following code just prepares the models to be used with CounterfactualExplanations.jl:","category":"page"},{"location":"examples/image/MNIST/","page":"MNIST","title":"MNIST","text":"using CounterfactualExplanations, CounterfactualExplanations.Models\nimport CounterfactualExplanations.Models: logits, probs # import functions in order to extend\n\n# MLP:\n# Step 1)\nstruct NeuralNetwork <: Models.AbstractFittedModel\n    nn::Any\nend\n# Step 2)\nlogits(M::NeuralNetwork, X::AbstractArray) = M.nn(X)\nprobs(M::NeuralNetwork, X::AbstractArray)= softmax(logits(M, X))\nM = NeuralNetwork(model)\n\n# Deep ensemble:\n# Step 1)\nstruct FittedEnsemble <: Models.AbstractFittedModel\n    ensemble::AbstractArray\nend\n# Step 2)\nusing Statistics\nlogits(M::FittedEnsemble, X::AbstractArray) = mean(Flux.stack([nn(X) for nn in M.ensemble],3), dims=3)\nprobs(M::FittedEnsemble, X::AbstractArray) = mean(Flux.stack([softmax(nn(X)) for nn in M.ensemble],3),dims=3)\nM_ensemble=FittedEnsemble(ensemble)","category":"page"},{"location":"examples/image/MNIST/#Generating-counterfactuals","page":"MNIST","title":"Generating counterfactuals","text":"","category":"section"},{"location":"examples/image/MNIST/","page":"MNIST","title":"MNIST","text":"We will look at four different approaches here:","category":"page"},{"location":"examples/image/MNIST/","page":"MNIST","title":"MNIST","text":"Generic approach for the MLP (Wachter, Mittelstadt, and Russell 2017).\nGreedy approach for the MLP.\nGeneric approach for the deep ensemble.\nGreedy approach for the deep ensemble (Schut et al. 2021).","category":"page"},{"location":"examples/image/MNIST/","page":"MNIST","title":"MNIST","text":"They can be implemented using the GenericGenerator and the GreedyGenerator.","category":"page"},{"location":"examples/image/MNIST/#Turning-a-9-into-a-4","page":"MNIST","title":"Turning a 9 into a 4","text":"","category":"section"},{"location":"examples/image/MNIST/","page":"MNIST","title":"MNIST","text":"We will start with an example that should yield intuitive results: the process of turning a handwritten 9 in Figure¬†2 into a 4 is straight-forward for a human - just erase the top part. Let‚Äôs see how the different algorithmic approaches perform. First, we preprocess the data below, where we impose that the features (pixel values) are constrained to the follwoing domain: ùí≥‚ÄÑ=‚ÄÑ[0,1]‚ÄÑ‚äÇ‚ÄÑ‚Ñù.","category":"page"},{"location":"examples/image/MNIST/","page":"MNIST","title":"MNIST","text":"counterfactual_data = CounterfactualData(X,ys';domain=(0,1))","category":"page"},{"location":"examples/image/MNIST/","page":"MNIST","title":"MNIST","text":"Next we choose a random sample for which we will generate counterfactuals in the following:","category":"page"},{"location":"examples/image/MNIST/","page":"MNIST","title":"MNIST","text":"# Randomly selected factual:\nusing Random\nRandom.seed!(1234)\nx = Flux.unsqueeze(select_factual(counterfactual_data, rand(1:size(X)[2])),2)\ntarget = 5\nŒ≥ = 0.95","category":"page"},{"location":"examples/image/MNIST/","page":"MNIST","title":"MNIST","text":"(Image: Figure 2: A random handwritten 9.)","category":"page"},{"location":"examples/image/MNIST/","page":"MNIST","title":"MNIST","text":"The code below implements the four different approaches one by one. Figure¬†3 shows the resulting counterfactuals. In every case the desired label switch is achieved, that is the corresponding classifier classifies the counterfactual as a four. But arguably from a human perspective only the counterfactuals for the deep ensemble look like a 4. For the MLP, both the generic and the greedy approach generate counterfactuals that look much like adversarial examples.","category":"page"},{"location":"examples/image/MNIST/","page":"MNIST","title":"MNIST","text":"# Generic - MLP\ngenerator = GenericGenerator(;loss=:logitcrossentropy)\ncounterfactual = generate_counterfactual(x, target, counterfactual_data, M, generator; Œ≥=Œ≥)\nimg = convert2image(reshape(counterfactual.x‚Ä≤,Int(‚àö(input_dim)),Int(‚àö(input_dim))))\nplt_wachter = plot(img, title=\"MLP - Wachter\")\n\n# Generic - Deep Ensemble\ncounterfactual = generate_counterfactual(x, target, counterfactual_data, M_ensemble, generator; Œ≥=Œ≥)\nimg = convert2image(reshape(counterfactual.x‚Ä≤,Int(‚àö(input_dim)),Int(‚àö(input_dim))))\nplt_wachter_de = plot(img, title=\"Ensemble - Wachter\")\n\n# Greedy - MLP\ngenerator = GreedyGenerator(;loss=:logitcrossentropy)\ncounterfactual = generate_counterfactual(x, target, counterfactual_data, M, generator; Œ≥=Œ≥)\nimg = convert2image(reshape(counterfactual.x‚Ä≤,Int(‚àö(input_dim)),Int(‚àö(input_dim))))\nplt_greedy = plot(img, title=\"MLP - Greedy\")\n\n# Greedy - Deep Ensemble\ncounterfactual = generate_counterfactual(x, target, counterfactual_data, M_ensemble, generator; Œ≥=Œ≥)\nimg = convert2image(reshape(counterfactual.x‚Ä≤,Int(‚àö(input_dim)),Int(‚àö(input_dim))))\nplt_greedy_de = plot(img, title=\"Ensemble - Greedy\")\n\nplt_list = [plt_orig, plt_wachter, plt_greedy, plt_wachter_de, plt_greedy_de]\nplt = plot(plt_list...,layout=(1,length(plt_list)),axis=nothing, size=(1200,240))\nsavefig(plt, joinpath(www_path, \"MNIST_9to4.png\"))","category":"page"},{"location":"examples/image/MNIST/","page":"MNIST","title":"MNIST","text":"(Image: Figure 3: Counterfactual explanations for MNIST data: turning a 9 into a 4)","category":"page"},{"location":"examples/image/MNIST/#References","page":"MNIST","title":"References","text":"","category":"section"},{"location":"examples/image/MNIST/","page":"MNIST","title":"MNIST","text":"Schut, Lisa, Oscar Key, Rory Mc Grath, Luca Costabello, Bogdan Sacaleanu, Yarin Gal, et al. 2021. ‚ÄúGenerating Interpretable Counterfactual Explanations by Implicit Minimisation of Epistemic and Aleatoric Uncertainties.‚Äù In International Conference on Artificial Intelligence and Statistics, 1756‚Äì64. PMLR.","category":"page"},{"location":"examples/image/MNIST/","page":"MNIST","title":"MNIST","text":"Wachter, Sandra, Brent Mittelstadt, and Chris Russell. 2017. ‚ÄúCounterfactual Explanations Without Opening the Black Box: Automated Decisions and the GDPR.‚Äù Harv. JL & Tech. 31: 841.","category":"page"},{"location":"tutorials/multi/","page":"Multi-class target","title":"Multi-class target","text":"CurrentModule = CounterfactualExplanations ","category":"page"},{"location":"tutorials/multi/#Counterfactuals-for-multi-class-targets","page":"Multi-class target","title":"Counterfactuals for multi-class targets","text":"","category":"section"},{"location":"tutorials/multi/","page":"Multi-class target","title":"Multi-class target","text":"In the existing literature counterfactual explanations have typically been applied in the binary classification setting (Verma, Dickerson, and Hines 2020). Research on algorithmic recourse in particular typically involves real-world datasets with an obvious target class - e.g.¬†individual receives credit - and an adverse outcome - e.g.¬†individual is denied loan (Karimi et al. 2020). Still, counterfactual explanations are very much also applicable in the multi-class setting. In this tutorial we will go through an illustrative example involving the toy dataset shown in Figure¬†1 below.","category":"page"},{"location":"tutorials/multi/","page":"Multi-class target","title":"Multi-class target","text":"using CounterfactualExplanations.Data\nxs, ys = Data.toy_data_multi()\nX = hcat(xs...)\ny_train = Flux.onehotbatch(ys, unique(ys))\ny_train = Flux.unstack(y_train',1)","category":"page"},{"location":"tutorials/multi/","page":"Multi-class target","title":"Multi-class target","text":"(Image: Figure 1: Synthetic dataset containing four different classes.)","category":"page"},{"location":"tutorials/multi/#Classifier","page":"Multi-class target","title":"Classifier","text":"","category":"section"},{"location":"tutorials/multi/","page":"Multi-class target","title":"Multi-class target","text":"To classify the data we use a simple multi-layer perceptron (MLP). In this case the MLP outputs four logits, one for each class. Contrary to the binary setting we therefore choose logitcrossentropy as our loss functiona as opposed to logitbinarycrossentropy.","category":"page"},{"location":"tutorials/multi/","page":"Multi-class target","title":"Multi-class target","text":"n_hidden = 32\nout_dim = length(unique(ys))\nkw = (output_dim=out_dim, dropout=true)\nnn = build_model(;kw...)\nloss(x, y) = Flux.Losses.logitcrossentropy(nn(x), y)\nps = Flux.params(nn)\ndata = zip(xs,y_train)","category":"page"},{"location":"tutorials/multi/","page":"Multi-class target","title":"Multi-class target","text":"The following code just trains the neural network for the task:","category":"page"},{"location":"tutorials/multi/","page":"Multi-class target","title":"Multi-class target","text":"using Flux.Optimise: update!, ADAM\nopt = ADAM()\nepochs = 10\navg_loss(data) = mean(map(d -> loss(d[1],d[2]), data))\nshow_every = epochs/10\n\nfor epoch = 1:epochs\n  for d in data\n    gs = gradient(params(nn)) do\n      l = loss(d...)\n    end\n    update!(opt, params(nn), gs)\n  end\n  if epoch % show_every == 0\n    println(\"Epoch \" * string(epoch))\n    @show avg_loss(data)\n  end\nend","category":"page"},{"location":"tutorials/multi/","page":"Multi-class target","title":"Multi-class target","text":"To make the model compatible with our package we need to 1) declare it as a subtype of Models.AbstractFittedModel and 2) dispatch the relevant methods. Logits are returned by the model on call and passed through the softmax function to generate the vector of class probabilities.","category":"page"},{"location":"tutorials/multi/","page":"Multi-class target","title":"Multi-class target","text":"using CounterfactualExplanations, CounterfactualExplanations.Models\nimport CounterfactualExplanations.Models: logits, probs # import functions in order to extend\n\n# Step 1)\nstruct NeuralNetwork <: Models.AbstractFittedModel\n    nn::Any\nend\n\n# Step 2)\nlogits(M::NeuralNetwork, X::AbstractArray) = M.nn(X)\nprobs(M::NeuralNetwork, X::AbstractArray)= softmax(logits(M, X))\nM = NeuralNetwork(nn);","category":"page"},{"location":"tutorials/multi/","page":"Multi-class target","title":"Multi-class target","text":"Figure¬†2 shows the resulting class probabilities in the two-dimensional feature domain.","category":"page"},{"location":"tutorials/multi/","page":"Multi-class target","title":"Multi-class target","text":"(Image: Figure 2: Class probabilities for MLP.)","category":"page"},{"location":"tutorials/multi/#Generating-counterfactuals","page":"Multi-class target","title":"Generating counterfactuals","text":"","category":"section"},{"location":"tutorials/multi/","page":"Multi-class target","title":"Multi-class target","text":"We first preprocess the data:","category":"page"},{"location":"tutorials/multi/","page":"Multi-class target","title":"Multi-class target","text":"counterfactual_data = CounterfactualData(X,ys')","category":"page"},{"location":"tutorials/multi/","page":"Multi-class target","title":"Multi-class target","text":"Next we randomly select an individual sample from any class and choose any of the remaining classes as our target at random.","category":"page"},{"location":"tutorials/multi/","page":"Multi-class target","title":"Multi-class target","text":"# Randomly selected factual:\nRandom.seed!(42)\nx = select_factual(counterfactual_data, rand(1:size(X)[2])) \ny = Flux.onecold(probs(M, x),unique(ys))\ntarget = rand(unique(ys)[1:end .!= y]) # opposite label as target","category":"page"},{"location":"tutorials/multi/","page":"Multi-class target","title":"Multi-class target","text":"Generic counterfactual search can then be implemented as follows. The only difference to the binary setting is that we need to declare logitcrossentropy as the loss function for the counterfactual search. Figure¬†3 shows the resulting counterfactual path.","category":"page"},{"location":"tutorials/multi/","page":"Multi-class target","title":"Multi-class target","text":"# Define generator:\ngenerator = GenericGenerator(;loss=:logitcrossentropy)\n# Generate recourse:\ncounterfactual = generate_counterfactual(x, target, counterfactual_data, M, generator)","category":"page"},{"location":"tutorials/multi/","page":"Multi-class target","title":"Multi-class target","text":"(Image: Figure 3: Counterfactual path for generic generator.)","category":"page"},{"location":"tutorials/multi/#Deep-ensemble","page":"Multi-class target","title":"Deep ensemble","text":"","category":"section"},{"location":"tutorials/multi/","page":"Multi-class target","title":"Multi-class target","text":"Staying consistent with previous tutorial we will also briefly look at the Bayesian setting. To incorporate uncertainty we use a simple deep ensemble instead of a single MLP.","category":"page"},{"location":"tutorials/multi/","page":"Multi-class target","title":"Multi-class target","text":"ensemble = build_ensemble(5;kw=(output_dim=out_dim,))\nensemble, = forward(ensemble, data, opt, n_epochs=epochs, plot_loss=false)","category":"page"},{"location":"tutorials/multi/","page":"Multi-class target","title":"Multi-class target","text":"As before, we need to subtype and disptach:","category":"page"},{"location":"tutorials/multi/","page":"Multi-class target","title":"Multi-class target","text":"# Step 1)\nstruct FittedEnsemble <: Models.AbstractFittedModel\n    ensemble::AbstractArray\nend\n\n# Step 2)\nusing Statistics\nlogits(M::FittedEnsemble, X::AbstractArray) = mean(Flux.stack([nn(X) for nn in M.ensemble],3), dims=3)\nprobs(M::FittedEnsemble, X::AbstractArray) = mean(Flux.stack([softmax(nn(X)) for nn in M.ensemble],3),dims=3)\n\nM=FittedEnsemble(ensemble)","category":"page"},{"location":"tutorials/multi/","page":"Multi-class target","title":"Multi-class target","text":"Figure¬†4 shows the resulting class probabilities.","category":"page"},{"location":"tutorials/multi/","page":"Multi-class target","title":"Multi-class target","text":"(Image: Figure 4: Class probabilities for deep ensemble.)","category":"page"},{"location":"tutorials/multi/","page":"Multi-class target","title":"Multi-class target","text":"For the greedy recourse generator we also specify logitcrossentropy as our loss function and modify the hyperparameters slightly. Figure¬†5 shows the resulting counterfactual path.","category":"page"},{"location":"tutorials/multi/","page":"Multi-class target","title":"Multi-class target","text":"generator = GreedyGenerator(loss=:logitcrossentropy,Œ¥=0.25,n=20)\ncounterfactual = generate_counterfactual(x, target, counterfactual_data, M, generator)","category":"page"},{"location":"tutorials/multi/","page":"Multi-class target","title":"Multi-class target","text":"(Image: Figure 5: Counterfactual path for greedy generator.)","category":"page"},{"location":"tutorials/multi/#References","page":"Multi-class target","title":"References","text":"","category":"section"},{"location":"tutorials/multi/","page":"Multi-class target","title":"Multi-class target","text":"Karimi, Amir-Hossein, Gilles Barthe, Bernhard Sch√∂lkopf, and Isabel Valera. 2020. ‚ÄúA Survey of Algorithmic Recourse: Definitions, Formulations, Solutions, and Prospects.‚Äù arXiv Preprint arXiv:2010.04050.","category":"page"},{"location":"tutorials/multi/","page":"Multi-class target","title":"Multi-class target","text":"Verma, Sahil, John Dickerson, and Keegan Hines. 2020. ‚ÄúCounterfactual Explanations for Machine Learning: A Review.‚Äù arXiv Preprint arXiv:2010.10596.","category":"page"},{"location":"","page":"Home","title":"Home","text":"CurrentModule = CounterfactualExplanations","category":"page"},{"location":"#CounterfactualExplanations","page":"Home","title":"CounterfactualExplanations","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Documentation for CounterfactualExplanations.jl.","category":"page"},{"location":"","page":"Home","title":"Home","text":"CounterfactualExplanations.jl is a Julia package for generating Counterfactual Explanations (CE) and Algorithmic Recourse (AR) for black-box algorithms. Both CE and AR are related tools for interpretable machine learning. See below for short introduction and other resources or dive straight into the docs.","category":"page"},{"location":"#Installation","page":"Home","title":"Installation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The first release of this package is now on Julia‚Äôs General Registry and can be installed as follows:","category":"page"},{"location":"","page":"Home","title":"Home","text":"using Pkg\nPkg.add(\"CounterfactualExplanations\")","category":"page"},{"location":"","page":"Home","title":"Home","text":"CounterfactualExplanations.jl is currently under active development. To install the development version of the package you can run the following command:","category":"page"},{"location":"","page":"Home","title":"Home","text":"using Pkg\nPkg.add(url=\"https://github.com/pat-alt/CounterfactualExplanations.jl\", rev=\"dev\")","category":"page"},{"location":"#Background-and-motivation","page":"Home","title":"Background and motivation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Algorithms used for automated decision-making such as deep neural networks have become so complex and opaque over recent years that they are generally considered as black boxes. This creates the following undesirable scenario: the human operators in charge of the black-box decision-making system do not understand how it works and essentially rely on it blindly. Conversely, those individuals who are subject to the decisions produced by such systems typically have no way of challenging them.","category":"page"},{"location":"","page":"Home","title":"Home","text":"‚ÄúYou cannot appeal to (algorithms). They do not listen. Nor do they bend.‚Äù‚Äî Cathy O‚ÄôNeil in Weapons of Math Destruction, 2016","category":"page"},{"location":"","page":"Home","title":"Home","text":"Counterfactual Explanations can help programmers make sense of the systems they build: they explain how inputs into a system need to change for it to produce a different output. The figure below, for example, shows various counterfactuals generated through different approaches that all turn the predicted label of some classifier from a 9 into a 4. CEs that involve realistic and actionable changes such as the one on the far right can be used for the purpose of individual counterfactual.","category":"page"},{"location":"","page":"Home","title":"Home","text":"(Image: Realistic counterfactual explanations for MNIST data: turning a 4 into a 9.)","category":"page"},{"location":"","page":"Home","title":"Home","text":"Algorithmic Recourse (AR) offers individuals subject to algorithms a way to turn a negative decision into positive one. The figure below illustrates the point of AR through a toy example: it shows the counterfactual path of one sad cat üê± that would like to be grouped with her cool dog friends. Unfortunately, based on her tail length and height she was classified as a cat by a black-box classifier. The recourse algorithm perturbs her features in such a way that she ends up crossing the decision boundary into a dense region inside the target class.","category":"page"},{"location":"","page":"Home","title":"Home","text":"(Image: A sad üê± on its counterfactual path to its cool dog friends.)","category":"page"},{"location":"#Usage-example","page":"Home","title":"Usage example","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Generating counterfactuals will typically look like follows:","category":"page"},{"location":"","page":"Home","title":"Home","text":"using CounterfactualExplanations\nusing CounterfactualExplanations.Models\nw = [1.0 -2.0] # true coefficients\nb = [0]\nM = LogisticModel(w, b)\nx = [-1,0.5]\ntarget = 1.0\nŒ≥ = 0.9\ngenerator = GenericGenerator(0.1,0.1,1e-5,:logitbinarycrossentropy,nothing)\ncounterfactual = generate_counterfactual(generator, x, M, target, Œ≥); # generate recourse","category":"page"},{"location":"","page":"Home","title":"Home","text":"We can see that the counterfactual label y‚Ä≤ corresponds to the target:","category":"page"},{"location":"","page":"Home","title":"Home","text":"julia> counterfactual.y‚Ä≤\n1.0\n\njulia> counterfactual.x\n2-element Vector{Float64}:\n -1.0\n  0.5\n\njulia> counterfactual.y\n0.0\n\njulia> counterfactual.x‚Ä≤\n2-element Vector{Float64}:\n -0.15867040347424893\n -1.182659193051502\n\njulia> counterfactual.y‚Ä≤\n1.0","category":"page"},{"location":"#Goals-and-limitations","page":"Home","title":"Goals and limitations","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The goal for this library is to contribute to efforts towards trustworthy machine learning in Julia. The Julia language has an edge when it comes to trustworthiness: it is very transparent. Packages like this one are generally written in 100% Julia, which makes it easy for users and developers to understand and contribute to open source code.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Eventually the aim for this project is to be at least at par with the amazing CARLA Python library which was presented at NeurIPS 2021. Currently CounterfactualExplanations.jl falls short of this goal in a number of ways: 1) the number of counterfactual generators is limited, 2) it lacks a framework for evaluating and benchmarking different generators, 3) it has so far been a one-person effort and not yet gone through a formal review.","category":"page"},{"location":"#Citation","page":"Home","title":"Citation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"If you want to use this codebase, please cite:","category":"page"},{"location":"","page":"Home","title":"Home","text":"@software{altmeyer2022CounterfactualExplanations,\n  author = {Patrick Altmeyer},\n  title = {{CounterfactualExplanations.jl - a Julia package for Counterfactual Explanations and Algorithmic Recourse}},\n  url = {https://github.com/pat-alt/CounterfactualExplanations.jl},\n  version = {0.1.0},\n  year = {2022}\n}","category":"page"},{"location":"tutorials/models/","page":"Custom models","title":"Custom models","text":"CurrentModule = CounterfactualExplanations ","category":"page"},{"location":"tutorials/models/#Models","page":"Custom models","title":"Models","text":"","category":"section"},{"location":"tutorials/models/#Default-models","page":"Custom models","title":"Default models","text":"","category":"section"},{"location":"tutorials/models/","page":"Custom models","title":"Custom models","text":"There are currently constructors for two default models, which mainly serve illustrative purposes (Figure¬†1 below). Both take sets of estimated parameters at the point of instantiation: the constructors will not fit a model for you, but assume that you have already estimated the respective model yourself and have access to its parameter estimates. Based on the supplied parameters methods to predict logits and probabilities are already implemented and used in the counterfactual search.","category":"page"},{"location":"tutorials/models/","page":"Custom models","title":"Custom models","text":"using GraphRecipes\np = plot(CounterfactualExplanations.Models.AbstractFittedModel, method=:tree, fontsize=8, nodeshape=:rect, axis_buffer=0.4, nodecolor=:white)\nsavefig(p, joinpath(www_path,\"models.png\"))","category":"page"},{"location":"tutorials/models/","page":"Custom models","title":"Custom models","text":"(Image: Figure 1: Schematic overview of classes in `Models` module.)","category":"page"},{"location":"tutorials/models/","page":"Custom models","title":"Custom models","text":"For the simple logistic regression model logits are computed as a‚ÄÑ=‚ÄÑX**w‚ÄÖ+‚ÄÖb and probabilities are simply œÉ(a). For the Bayesian logistic regression model logits are computed as X**Œº and the predictive posterior is computed through Laplace approximation.","category":"page"},{"location":"tutorials/models/#Custom-models","page":"Custom models","title":"Custom models","text":"","category":"section"},{"location":"tutorials/models/","page":"Custom models","title":"Custom models","text":"Apart from the default models you can use any arbitrary (differentiable) model and generate recourse in the same way as before. Only two steps are necessary to make your own model compatible with CounterfactualExplanations.jl:","category":"page"},{"location":"tutorials/models/","page":"Custom models","title":"Custom models","text":"The model needs to be declared as a subtype of CounterfactualExplanations.Models.AbstractFittedModel.\nYou need to extend the functions CounterfactualExplanations.Models.logits and CounterfactualExplanations.Models.probs to accept your custom model.","category":"page"},{"location":"tutorials/models/","page":"Custom models","title":"Custom models","text":"Below we will go through a simple example to see how this can be done in practice.","category":"page"},{"location":"tutorials/models/#Neural-network","page":"Custom models","title":"Neural network","text":"","category":"section"},{"location":"tutorials/models/","page":"Custom models","title":"Custom models","text":"In this example we will build a simple artificial neural network using Flux.jl for a binary classification task. First we generate some toy data below. The code that generates this data was borrowed from a great tutorial about Bayesian neural networks provided by Turing.jl, which you may find here.","category":"page"},{"location":"tutorials/models/","page":"Custom models","title":"Custom models","text":"The plot below shows the generated samples in the 2D feature space where colours indicate the associated labels. CounterfactualExplanationsly this data is not linearly separable and the default LogisticModel would be ill suited for this classification task.","category":"page"},{"location":"tutorials/models/","page":"Custom models","title":"Custom models","text":"# Number of points to generate.\nN = 80\nM = round(Int, N / 4)\nRandom.seed!(1234)\n\nusing CounterfactualExplanations.Data\nxs, ys = Data.toy_data_non_linear(N)\nX = hcat(xs...)","category":"page"},{"location":"tutorials/models/","page":"Custom models","title":"Custom models","text":"(Image: )","category":"page"},{"location":"tutorials/models/#Training-the-model","page":"Custom models","title":"Training the model","text":"","category":"section"},{"location":"tutorials/models/","page":"Custom models","title":"Custom models","text":"Instead we will build a simple artificial neural network nn with one hidden layer. For additional resources on how to do deep learning with Flux.jl just have a look at their documentation.","category":"page"},{"location":"tutorials/models/","page":"Custom models","title":"Custom models","text":"nn = build_model(dropout=true,activation=Flux.œÉ)\nloss(x, y) = Flux.Losses.logitbinarycrossentropy(nn(x), y)\nps = Flux.params(nn)\ndata = zip(xs,ys);","category":"page"},{"location":"tutorials/models/","page":"Custom models","title":"Custom models","text":"The code below trains the neural network for the task at hand. The plot shows the (training) loss over time. Note that normally we would be interested in loss with respect to a validation data set. But since we are primarily interested in generated recourse for a trained classifier, here we will just keep things very simple.","category":"page"},{"location":"tutorials/models/","page":"Custom models","title":"Custom models","text":"using Flux.Optimise: update!, ADAM\nopt = ADAM()\nepochs = 100\navg_loss(data) = mean(map(d -> loss(d[1],d[2]), data))\nshow_every = epochs/10\n\nfor epoch = 1:epochs\n  for d in data\n    gs = gradient(params(nn)) do\n      l = loss(d...)\n    end\n    update!(opt, params(nn), gs)\n  end\n  if epoch % show_every == 0\n    println(\"Epoch \" * string(epoch))\n    @show avg_loss(data)\n  end\nend","category":"page"},{"location":"tutorials/models/#Generating-counterfactuals","page":"Custom models","title":"Generating counterfactuals","text":"","category":"section"},{"location":"tutorials/models/","page":"Custom models","title":"Custom models","text":"Now it‚Äôs game time: we have a fitted model M‚ÄÑ:‚ÄÑùí≥‚ÄÑ‚Ü¶‚ÄÑùí¥ and are interested in generating recourse for some individual x‚ÄÑ‚àà‚ÄÑùí≥. As mentioned above we need to do a bit more work to prepare the model to be used by CounterfactualExplanations.jl.","category":"page"},{"location":"tutorials/models/","page":"Custom models","title":"Custom models","text":"The code below takes care of all of that: in step 1) it declares our model as a subtype of Models.AbstractFittedModel and in step 2) it just extends the two functions.","category":"page"},{"location":"tutorials/models/","page":"Custom models","title":"Custom models","text":"using CounterfactualExplanations, CounterfactualExplanations.Models\nimport CounterfactualExplanations.Models: logits, probs # import functions in order to extend\n\n# Step 1)\nstruct NeuralNetwork <: Models.AbstractFittedModel\n    nn::Any\nend\n\n# Step 2)\nlogits(M::NeuralNetwork, X::AbstractArray) = M.nn(X)\nprobs(M::NeuralNetwork, X::AbstractArray)= œÉ.(logits(M, X))\nM = NeuralNetwork(nn)","category":"page"},{"location":"tutorials/models/","page":"Custom models","title":"Custom models","text":"The plot below shows the predicted probabilities in the feature domain. Evidently our simple neural network is doing very well on the training data, as expected.","category":"page"},{"location":"tutorials/models/","page":"Custom models","title":"Custom models","text":"(Image: )","category":"page"},{"location":"tutorials/models/","page":"Custom models","title":"Custom models","text":"To preprocess the data we simply run the following:","category":"page"},{"location":"tutorials/models/","page":"Custom models","title":"Custom models","text":"counterfactual_data = CounterfactualData(X,ys')","category":"page"},{"location":"tutorials/models/","page":"Custom models","title":"Custom models","text":"Now we just select a random sample from our data and based on its current label we set as our target the opposite label and desired threshold for the predicted probability.","category":"page"},{"location":"tutorials/models/","page":"Custom models","title":"Custom models","text":"using Random\nRandom.seed!(123)\nx = select_factual(counterfactual_data, rand(1:size(X)[2])) \ny = round(probs(M, x)[1])\ntarget = ifelse(y==1.0,0.0,1.0) # opposite label as target","category":"page"},{"location":"tutorials/models/","page":"Custom models","title":"Custom models","text":"Then finally we use the GenericGenerator to generate counterfactual. The plot further below shows the resulting counterfactual path.","category":"page"},{"location":"tutorials/models/","page":"Custom models","title":"Custom models","text":"# Define generator:\ngenerator = GenericGenerator()\n# Generate recourse:\ncounterfactual = generate_counterfactual(x, target, counterfactual_data, M, generator)","category":"page"},{"location":"tutorials/models/","page":"Custom models","title":"Custom models","text":"(Image: )","category":"page"},{"location":"tutorials/models/#Ensemble-of-neural-networks","page":"Custom models","title":"Ensemble of neural networks","text":"","category":"section"},{"location":"tutorials/models/","page":"Custom models","title":"Custom models","text":"In the context of Bayesian classifiers the GreedyGenerator can be used since minimizing the predictive uncertainty acts as a proxy for realism and unambiquity. In other words, if we have a model that incorporates uncertainty, we can generate realistic counterfactuals without the need for a complexity penalty.","category":"page"},{"location":"tutorials/models/","page":"Custom models","title":"Custom models","text":"One efficient way to produce uncertainty estimates in the context of deep learning is to simply use an ensemble of artificial neural networks (also referred to as deep ensemble). To this end we can use the build_model function from above repeatedly to compose an ensemble of K neural networks:","category":"page"},{"location":"tutorials/models/","page":"Custom models","title":"Custom models","text":"ensemble = build_ensemble(5;kw=(dropout=true,activation=Flux.œÉ))","category":"page"},{"location":"tutorials/models/","page":"Custom models","title":"Custom models","text":"Training this ensemble boils down to training each neural network separately:","category":"page"},{"location":"tutorials/models/","page":"Custom models","title":"Custom models","text":"ensemble, anim = forward(ensemble, data, opt, n_epochs=epochs, plot_every=show_every); # fit the ensemble\ngif(anim, joinpath(www_path, \"models_ensemble_loss.gif\"), fps=10)","category":"page"},{"location":"tutorials/models/","page":"Custom models","title":"Custom models","text":"(Image: )","category":"page"},{"location":"tutorials/models/","page":"Custom models","title":"Custom models","text":"Once again it is straight-forward to make the model compatible with the package. Note that for an ensemble model the predicted logits and probabilities are just averages over predictions produced by all K models.","category":"page"},{"location":"tutorials/models/","page":"Custom models","title":"Custom models","text":"# Step 1)\nstruct FittedEnsemble <: Models.AbstractFittedModel\n    ensemble::AbstractArray\nend\n\n# Step 2)\nlogits(M::FittedEnsemble, X::AbstractArray) = mean(Flux.flatten(Flux.stack([nn(X) for nn in M.ensemble],1)),dims=1)\nprobs(M::FittedEnsemble, X::AbstractArray) = mean(Flux.flatten(Flux.stack([œÉ.(nn(X)) for nn in M.ensemble],1)),dims=1)\n\nM=FittedEnsemble(ensemble)","category":"page"},{"location":"tutorials/models/","page":"Custom models","title":"Custom models","text":"Again we plot the predicted probabilities in the feature domain. As expected the ensemble is more conservative because it incorporates uncertainty: the predicted probabilities splash out more than before, especially in regions that are not populated by samples.","category":"page"},{"location":"tutorials/models/","page":"Custom models","title":"Custom models","text":"(Image: )","category":"page"},{"location":"tutorials/models/","page":"Custom models","title":"Custom models","text":"Finally, we use the GreedyGenerator for the counterfactual search. For the same desired threshold Œ≥ as before, the counterfactual ends up somewhat closer to a cluster of original samples. In other words we end up providing more realisitic albeit likely more costly counterfactual.","category":"page"},{"location":"tutorials/models/","page":"Custom models","title":"Custom models","text":"generator = GreedyGenerator(Dict(:Œ¥=>0.1,:n=>30))\ncounterfactual = generate_counterfactual(x, target, counterfactual_data, M, generator)","category":"page"},{"location":"tutorials/models/","page":"Custom models","title":"Custom models","text":"(Image: )","category":"page"}]
}
