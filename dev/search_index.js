var documenterSearchIndex = {"docs":
[{"location":"contributing/","page":"Overview","title":"Overview","text":"CurrentModule = CounterfactualExplanations ","category":"page"},{"location":"contributing/#Contributing","page":"Overview","title":"Contributing","text":"","category":"section"},{"location":"contributing/","page":"Overview","title":"Overview","text":"CounterfactualExplanations.jl is designed to be scalable: through multiple dispatch and modularization we hope to make it as straight-forward as possible for members of the community to contribute to its functionality. At the moment we are primarily looking for the following contributions:","category":"page"},{"location":"contributing/","page":"Overview","title":"Overview","text":"Additional counterfactual generators.\nAdditional predictive models.\nMore examples to be added to the documentation.","category":"page"},{"location":"contributing/","page":"Overview","title":"Overview","text":"We are also interested in suggestions on how to adjust and improve the inner workings of our package. To facilitate this process the following page explain and justify the package architecture and the design choices we have made. ","category":"page"},{"location":"contributing/#How-to-contribute?","page":"Overview","title":"How to contribute?","text":"","category":"section"},{"location":"contributing/","page":"Overview","title":"Overview","text":"All of the following contributions are welcome:","category":"page"},{"location":"contributing/","page":"Overview","title":"Overview","text":"Should you spot any errors or something is not working, please just open an issue.\nIf you want to contribute your own code, please proceed as follows:\nFork this repo and clone your fork: git clone https://github.com/your_username/CounterfactualExplanations.jl.\nAdd a remote corresponding to this repository: git remote add upstream https://github.com/pat-alt/CounterfactualExplanations.jl.git\nImplement your modifications and submit a pull request.\nFor any other questions or comments you can also start a discussion.","category":"page"},{"location":"tutorials/binary/","page":"Binary target","title":"Binary target","text":"CurrentModule = CounterfactualExplanations ","category":"page"},{"location":"tutorials/binary/#Counterfactual-explanations-for-binary-classification","page":"Binary target","title":"Counterfactual explanations for binary classification","text":"","category":"section"},{"location":"tutorials/binary/","page":"Binary target","title":"Binary target","text":"To understand the core functionality of CounterfactualExplanations.jl we will look at two example use cases of the generate_counterfactual function. This function takes a structure of type AbstractGenerator as its main argument. Users can utilize one of the default generators: GenericGenerator <: AbstractGenerator, GreedyGenerator <: AbstractGenerator. Alternatively, users can also create their own custom generator.","category":"page"},{"location":"tutorials/binary/#Default-generators","page":"Binary target","title":"Default generators","text":"","category":"section"},{"location":"tutorials/binary/#GenericGenerator","page":"Binary target","title":"GenericGenerator","text":"","category":"section"},{"location":"tutorials/binary/","page":"Binary target","title":"Binary target","text":"Let t ∈ {0, 1} denote the target label, M the model (classifier) and x′ ∈ ℝᴰ the vector of counterfactual features. In order to generate recourse the GenericGenerator optimizes the following objective function through steepest descent","category":"page"},{"location":"tutorials/binary/","page":"Binary target","title":"Binary target","text":"xprime = arg min_xprime  ell(M(xprime)t) + lambda h(xprime)","category":"page"},{"location":"tutorials/binary/","page":"Binary target","title":"Binary target","text":"where ℓ denotes some loss function targeting the deviation between the target label and the predicted label and h(⋅) as a complexity penalty generally addressing the realism or cost of the proposed counterfactual.","category":"page"},{"location":"tutorials/binary/","page":"Binary target","title":"Binary target","text":"Let’s generate some toy data:","category":"page"},{"location":"tutorials/binary/","page":"Binary target","title":"Binary target","text":"# Some random data:\nusing CounterfactualExplanations.Data\nRandom.seed!(1234);\nN = 25\nw = [1.0 1.0]# true coefficients\nb = 0\nxs, ys = Data.toy_data_linear(N)\nX = hcat(xs...)\ncounterfactual_data = CounterfactualData(X,ys')\nplt = plot()\nplt = plot_data!(plt,X',ys);\nsavefig(plt, joinpath(www_path, \"binary_samples.png\"))","category":"page"},{"location":"tutorials/binary/","page":"Binary target","title":"Binary target","text":"(Image: )","category":"page"},{"location":"tutorials/binary/","page":"Binary target","title":"Binary target","text":"For this toy data we will now implement algorithmic recourse as follows:","category":"page"},{"location":"tutorials/binary/","page":"Binary target","title":"Binary target","text":"Use the coefficients w and b to define our model using CounterfactualExplanations.Models.LogisticModel(w, b).\nDefine our GenericGenerator.\nGenerate counterfactual.","category":"page"},{"location":"tutorials/binary/","page":"Binary target","title":"Binary target","text":"using CounterfactualExplanations.Models: LogisticModel, probs \n# Logit model:\nM = LogisticModel(w, [b])\n# Randomly selected factual:\nRandom.seed!(123);\nx = select_factual(counterfactual_data,rand(1:size(X)[2]))\ny = round(probs(M, x)[1])\ntarget = ifelse(y==1.0,0.0,1.0) # opposite label as target","category":"page"},{"location":"tutorials/binary/","page":"Binary target","title":"Binary target","text":"plt = plot_contour(X',ys,M;title=\"Posterior predictive - Plugin\")\nsavefig(plt, joinpath(www_path, \"binary_contour.png\"))","category":"page"},{"location":"tutorials/binary/","page":"Binary target","title":"Binary target","text":"(Image: )","category":"page"},{"location":"tutorials/binary/","page":"Binary target","title":"Binary target","text":"# Define generator:\ngenerator = GenericGenerator()\n# Generate recourse:\ncounterfactual = generate_counterfactual(x, target, counterfactual_data, M, generator)","category":"page"},{"location":"tutorials/binary/","page":"Binary target","title":"Binary target","text":"Now let’s plot the resulting counterfactual path in the 2-D feature space (left) and the predicted probability (right):","category":"page"},{"location":"tutorials/binary/","page":"Binary target","title":"Binary target","text":"import CounterfactualExplanations.Counterfactuals: target_probs\nT = total_steps(counterfactual)\nX_path = reduce(hcat,path(counterfactual))\nŷ = target_probs(counterfactual,X_path)\np1 = plot_contour(X',ys,M;clegend=false, title=\"Posterior predictive - Plugin\")\nanim = @animate for t in 1:T\n    scatter!(p1, [path(counterfactual)[t][1]], [path(counterfactual)[t][2]], ms=5, color=Int(y), label=\"\")\n    p2 = plot(1:t, ŷ[1:t], xlim=(0,T), ylim=(0, 1), label=\"p(y′=\" * string(target) * \")\", title=\"Validity\", lc=:black)\n    Plots.abline!(p2,0,counterfactual.params[:γ],label=\"threshold γ\", ls=:dash) # decision boundary\n    plot(p1,p2,size=(800,400))\nend\ngif(anim, joinpath(www_path, \"binary_generic_recourse.gif\"), fps=25)","category":"page"},{"location":"tutorials/binary/","page":"Binary target","title":"Binary target","text":"(Image: )","category":"page"},{"location":"tutorials/binary/#GreedyGenerator","page":"Binary target","title":"GreedyGenerator","text":"","category":"section"},{"location":"tutorials/binary/","page":"Binary target","title":"Binary target","text":"Next we will repeat the exercise above, but instead use the GreedyGenerator in the context of a Bayesian classifier. This generator is greedy in the sense that it simply chooses the most salient feature {x′}ᵈ where","category":"page"},{"location":"tutorials/binary/","page":"Binary target","title":"Binary target","text":"d=argmax_d in 1D nabla_xprime ell(M(xprime)t)","category":"page"},{"location":"tutorials/binary/","page":"Binary target","title":"Binary target","text":"and perturbs it by a fixed amount δ. In other words, optimization is penalty-free. This is possible in the Bayesian context, because maximizing the predictive probability γ corresponds to minimizing the predictive uncertainty: by construction the generated counterfactual will therefore be realistic (low epistemic uncertainty) and unambiguous (low aleotoric uncertainty).","category":"page"},{"location":"tutorials/binary/","page":"Binary target","title":"Binary target","text":"using LinearAlgebra\nΣ = Symmetric(reshape(randn(9),3,3).*0.01 + UniformScaling(1)) # MAP covariance matrix\nμ = hcat(b, w)\nM = CounterfactualExplanations.Models.BayesianLogisticModel(μ, Σ);\ngenerator = GreedyGenerator(Dict(:δ=>0.1,:n=>25))\ncounterfactual = generate_counterfactual(x, target, counterfactual_data, M, generator)","category":"page"},{"location":"tutorials/binary/","page":"Binary target","title":"Binary target","text":"Once again we plot the resulting counterfactual path (left) and changes in the predicted probability (right). For the Bayesian classifier predicted probabilities splash out: uncertainty increases in regions with few samples. Note how the greedy approach selects the same most salient feature over and over again until its exhausted (i.e. it has been chosen GreedyGenerator.n times).","category":"page"},{"location":"tutorials/binary/","page":"Binary target","title":"Binary target","text":"import CounterfactualExplanations.Counterfactuals: target_probs\nT = total_steps(counterfactual)\nX_path = reduce(hcat,path(counterfactual))\nŷ = target_probs(counterfactual,X_path)\np1 = plot_contour(X',ys,M;clegend=false, title=\"Posterior predictive - Plugin\")\nanim = @animate for t in 1:T\n    scatter!(p1, [path(counterfactual)[t][1]], [path(counterfactual)[t][2]], ms=5, color=Int(y), label=\"\")\n    p2 = plot(1:t, ŷ[1:t], xlim=(0,T), ylim=(0, 1), label=\"p(y′=\" * string(target) * \")\", title=\"Validity\", lc=:black)\n    Plots.abline!(p2,0,counterfactual.params[:γ],label=\"threshold γ\", ls=:dash) # decision boundary\n    plot(p1,p2,size=(800,400))\nend\ngif(anim, joinpath(www_path, \"binary_greedy_recourse.gif\"), fps=25);","category":"page"},{"location":"tutorials/binary/","page":"Binary target","title":"Binary target","text":"(Image: )","category":"page"},{"location":"tutorials/","page":"Overview","title":"Overview","text":"CurrentModule = CounterfactualExplanations ","category":"page"},{"location":"tutorials/#Using-CounterfactualExplanations.jl","page":"Overview","title":"Using CounterfactualExplanations.jl","text":"","category":"section"},{"location":"tutorials/","page":"Overview","title":"Overview","text":"The following pages introduce the main package functionality through various illustrative examples involving synthetic data. Among other things, the tutorials cover binary classification, multi-class problem and language interoperability with Python and R. For anyone primarily interested in using and understanding the existing package functionality, these tutorials should provide sufficient detail. If you are interested in contributing your own custom generators and models or have ideas for how to improve this package, we encourage you to also take a look at the Contributor's Guide. ","category":"page"},{"location":"intro/","page":"-","title":"-","text":"Installation\nBackground and motivation\nUsage example\nGoals and limitations\nCitation","category":"page"},{"location":"intro/","page":"-","title":"-","text":"CounterfactualExplanations.jl is a Julia package for generating Counterfactual Explanations (CE) and Algorithmic Recourse (AR) for black-box algorithms. Both CE and AR are related tools for interpretable machine learning. See below for short introduction and other resources or dive straight into the docs.","category":"page"},{"location":"intro/#Installation","page":"-","title":"Installation","text":"","category":"section"},{"location":"intro/","page":"-","title":"-","text":"The package is in its early stages of development and currently awaiting registry on Julia’s General Registry. In the meantime it can be installed as follows:","category":"page"},{"location":"intro/","page":"-","title":"-","text":"using Pkg\nPkg.add(\"https://github.com/pat-alt/CounterfactualExplanations.jl\")","category":"page"},{"location":"intro/","page":"-","title":"-","text":"To instead install the development version of the package you can run the following command:","category":"page"},{"location":"intro/","page":"-","title":"-","text":"using Pkg\nPkg.add(url=\"https://github.com/pat-alt/CounterfactualExplanations.jl\", rev=\"dev\")","category":"page"},{"location":"intro/#Background-and-motivation","page":"-","title":"Background and motivation","text":"","category":"section"},{"location":"intro/","page":"-","title":"-","text":"Algorithms used for automated decision-making such as deep neural networks have become so complex and opaque over recent years that they are generally considered as black boxes. This creates the following undesirable scenario: the human operators in charge of the black-box decision-making system do not understand how it works and essentially rely on it blindly. Conversely, those individuals who are subject to the decisions produced by such systems typically have no way of challenging them.","category":"page"},{"location":"intro/","page":"-","title":"-","text":"“You cannot appeal to (algorithms). They do not listen. Nor do they bend.”— Cathy O’Neil in Weapons of Math Destruction, 2016","category":"page"},{"location":"intro/","page":"-","title":"-","text":"Counterfactual Explanations can help programmers make sense of the systems they build: they explain how inputs into a system need to change for it to produce a different output. Figure 1, for example, shows various counterfactuals generated through different approaches that all turn the predicted label of some classifier from a 9 into a 4. CEs that involve realistic and actionable changes such as the one on the far right can be used for the purpose of individual counterfactual.","category":"page"},{"location":"intro/","page":"-","title":"-","text":"<figure> <img src=\"examples/image/www/MNIST_9to4.png\" id=\"fig-mnist\" alt=\"Figure 1: Realistic counterfactual explanations for MNIST data: turning a 4 into a 9.\" /> <figcaption aria-hidden=\"true\">Figure 1: Realistic counterfactual explanations for MNIST data: turning a 4 into a 9.</figcaption> </figure>","category":"page"},{"location":"intro/","page":"-","title":"-","text":"Algorithmic Recourse (AR) offers individuals subject to algorithms a way to turn a negative decision into positive one. Figure 2 illustrates the point of AR through a toy example: it shows the counterfactual path of one sad cat 🐱 that would like to be grouped with her cool dog friends. Unfortunately, based on her tail length and height she was classified as a cat by a black-box classifier. The recourse algorithm perturbs her features in such a way that she ends up crossing the decision boundary into a dense region inside the target class.","category":"page"},{"location":"intro/","page":"-","title":"-","text":"<figure> <img src=\"examples/www/recourse_laplace.gif\" id=\"fig-cat\" alt=\"Figure 2: A sad 🐱 on its counterfactual path to its cool dog friends.\" /> <figcaption aria-hidden=\"true\">Figure 2: A sad 🐱 on its counterfactual path to its cool dog friends.</figcaption> </figure>","category":"page"},{"location":"intro/#Usage-example","page":"-","title":"Usage example","text":"","category":"section"},{"location":"intro/#Goals-and-limitations","page":"-","title":"Goals and limitations","text":"","category":"section"},{"location":"intro/","page":"-","title":"-","text":"The goal for this library is to contribute to efforts towards trustworthy machine learning in Julia. The Julia language has an edge when it comes to trustworthiness: it is very transparent. Packages like this one are generally written in 100% Julia, which makes it easy for users and developers to understand and contribute to open source code.","category":"page"},{"location":"intro/","page":"-","title":"-","text":"Eventually the aim for this project is to be at least at par with the amazing CARLA Python library which was presented at NeurIPS 2021. Currently CounterfactualExplanations.jl falls short of this goal in a number of ways: 1) the number of counterfactual generators is limited, 2) it lacks a framework for evaluating and benchmarking different generators, 3) it has so far been a one-person effort and not yet gone through a formal review.","category":"page"},{"location":"intro/#Citation","page":"-","title":"Citation","text":"","category":"section"},{"location":"intro/","page":"-","title":"-","text":"If you want to use this codebase, please cite:","category":"page"},{"location":"intro/","page":"-","title":"-","text":"@software{altmeyer2022CounterfactualExplanations,\n  author = {Patrick Altmeyer},\n  title = {{CounterfactualExplanations.jl - a julia package for Counterfactual Explanations and Algorithmic Recourse}},\n  url = {https://github.com/pat-alt/CounterfactualExplanations.jl},\n  version = {0.1.0},\n  year = {2022}\n}","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"CurrentModule = CounterfactualExplanations ","category":"page"},{"location":"contributing/loss/#Loss-functions-and-gradients","page":"Loss functions","title":"Loss functions and gradients","text":"","category":"section"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"This is a short tutorial on loss functions and gradients typically involved in counterfactual search. It involves more maths than perhaps some of the other tutorials.","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"using Zygote, Plots, PlotThemes, LinearAlgebra\ntheme(:wong)\nusing Logging\ndisable_logging(Logging.Info)","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"LogLevel(1)","category":"page"},{"location":"contributing/loss/#General-setup","page":"Loss functions","title":"General setup","text":"","category":"section"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"We begin by restating the general setup for generic counterfactual search. Let tin01 denote the target label, M the model (classifier) and xprimeinmathbbR^D the vector of counterfactual features (we will assume all features are continuous). Then the differentiable optimization problem in algorithmic recourse is generally of the following form","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"xprime = arg min_xprime  ell(M(xprime)t) + lambda h(xprime)","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"where ell denotes some loss function targeting the deviation between the target label and the predicted label and h(cdot) acts as a complexity penality generally addressing the realism or cost of the proposed counterfactual. ","category":"page"},{"location":"contributing/loss/#Loss-function-\\ell","page":"Loss functions","title":"Loss function ell","text":"","category":"section"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"Different choices for ell come to mind, each potentially leading to very different counterfactual outcomes. In practice, ell is often implemented with respect to the logits a=mathbfw^Tx rather than the probabilities p(yprime=1xprime)=sigma(a) predicted by the classifier. We follow this convention here, but as we shall see depeding on the label domain this convention does not work well for every type of loss function. Common choices for ell in the literature include margin-based loss function like hinge loss and logit binary crossentropy (or log) loss. Some use distance-based loss such as mean squared error loss (MSE).","category":"page"},{"location":"contributing/loss/#hinge-loss","page":"Loss functions","title":"hinge loss","text":"","category":"section"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"With respect to the logits a=mathbfwx hinge loss can be defined as follows","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"ell(at^*)=(1-acdot t^*)_+=max01-acdot t^*","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"where t^* is the target label in -11. Since above we defined tin01 we need a mapping h 01 mapsto -11. Specifically, we want to plug in h(t)=t^* where h(cdot) is just the following conditional:","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"beginaligned\nh(t)=begincases\n-1  textif  t=0  1  textif  t=1\nendcases\nendaligned","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"Then our loss function as function of t can restated as follows:","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"ell(at^*)=ell(at)=(1-acdot h(t))_+=max01-acdot h(t)","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"The first-order derivative of hinge loss with respect to the logits a is simply","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"beginaligned\nell(at)=begincases\n-h(t)  textif  a cdot h(t)=1  0  textotherwise \nendcases\nendaligned","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"In the context of counterfactual search the gradient with respect to the feature vector is then:","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"beginaligned\n nabla_xprime ell(at)= begincases\n-h(t)mathbfw  textif  h(t)mathbfw^Txprime=1  0  textotherwise \nendcases\nendaligned","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"In practice gradients are commonly computed through autodifferentiation. In this tutorial we use the Zygote.jl package which is at the core of Flux.jl, the main deep learning library for Julia.","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"The side-by-side plot below visualises the loss function and its derivative. The plot further below serves as a simple sanity check to verify that autodifferentiation indeed yields the same result as the closed-form solution for the gradient.","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"h(t) = ifelse(t==1,1,-1)\nhinge(a,t) = max(0,1-a*h(t))","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"hinge (generic function with 1 method)","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"default(size=(500,500))\na = -2:0.05:2\np1 = plot(a, [hinge(a,1) for a=a], title=\"Loss, t=1\", xlab=\"logits\")\np2 = plot(a, [gradient(hinge,a,1)[1] for a=a], title=\"Gradient, t=1\", xlab=\"logits\")\np3 = plot(a, [hinge(a,0) for a=a], title=\"Loss, t=0\", xlab=\"logits\")\np4 = plot(a, [gradient(hinge,a,0)[1] for a=a], title=\"Gradient, t=0\", xlab=\"logits\")\nplot(p1, p2, p3, p4, layout = (2, 2), legend = false)\nsavefig(\"www/loss_grad_hinge.png\")","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"(Image: )","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"# Just verifying that the formula for the gradient above indeed yields the same result.\nfunction gradient_man(x,w,t)\n    𝐠 = ifelse(h(t)*w'x<=1, -h(t)*w, 0)\n    return 𝐠\nend;\nplot(a, [gradient_man(a,1,1) for a=a], legend=:bottomright, label=\"Manual\", title=\"Gradient\", xlab=\"logits\")\nscatter!(a, [gradient(hinge,a,1)[1] for a=a], label=\"Autodiff\")\nsavefig(\"www/loss_grad_hinge_test.png\")","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"(Image: )","category":"page"},{"location":"contributing/loss/#Logit-binary-crossentropy-loss","page":"Loss functions","title":"Logit binary crossentropy loss","text":"","category":"section"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"Logit binary crossentropy loss loss (sometimes referred to as log loss) is defined as follows:","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"beginaligned\n ell(at)=- left( t cdot log(sigma(a)) + (1-t) cdot log (1-sigma(a)) right) \nendaligned","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"where sigma(a) is the logit/sigmoid link function.","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"Once again for the purpose of counter factual search we are interested in the first-order derivative with respect to our feature vector xprime. You can verify that the partial derivative with respect to feature xprime_d is as follows:","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"beginaligned\n fracpartial ell(at)partial xprime_d= (sigma(a) - t) w_d \nendaligned","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"The gradient just corresponds to the stacked vector of partial derivatives:","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"beginaligned\n nabla_xprime ell(at)= (sigma(a) - t) mathbfw \nendaligned","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"As before implementation below is done through autodifferentiation. As before the side-by-side plot shows the resulting loss function and its gradient and the plot further below is a simple sanity check.","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"# sigmoid function:\nfunction 𝛔(a)\n    trunc = 8.0 # truncation to avoid numerical over/underflow\n    a = clamp.(a,-trunc,trunc)\n    p = exp.(a)\n    p = p ./ (1 .+ p)\n    return p\nend\n\n# Logit binary crossentropy:\nlogitbinarycrossentropy(a, t) = - (t * log(𝛔(a)) + (1-t) * log(1-𝛔(a)))","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"logitbinarycrossentropy (generic function with 1 method)","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"(Image: )","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"p1 = plot(a, [logitbinarycrossentropy(a,1) for a=a], title=\"Loss, t=1\", xlab=\"logits\")\np2 = plot(a, [gradient(logitbinarycrossentropy,a,1)[1] for a=a], title=\"Gradient, t=1\", xlab=\"logits\")\np3 = plot(a, [logitbinarycrossentropy(a,0) for a=a], title=\"Loss, t=0\", xlab=\"logits\")\np4 = plot(a, [gradient(logitbinarycrossentropy,a,0)[1] for a=a], title=\"Gradient, t=0\", xlab=\"logits\")\nplot(p1, p2, p3, p4, layout = (2, 2), legend = false)\nsavefig(\"www/loss_grad_log.png\")","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"(Image: )","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"# Just verifying that the formula for the gradient above indeed yields the same result.\nfunction gradient_man(x,w,y)\n    𝐠 = (𝛔(w'x) - y) .* w\n    return 𝐠\nend;\nplot(a, [gradient_man(a,1,1) for a=a], legend=:bottomright, label=\"Manual\", title=\"Gradient\", xlab=\"logits\")\nscatter!(a, [gradient(logitbinarycrossentropy,a,1)[1] for a=a], label=\"Autodiff\")\nsavefig(\"www/loss_grad_log_test.png\")","category":"page"},{"location":"contributing/loss/#Mean-squared-error","page":"Loss functions","title":"Mean squared error","text":"","category":"section"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"Some authors work with distance-based loss functions instead. Since in general we are interested in providing valid recourse, that is counterfactual explanations that indeed lead to the desired label switch, using one of the margin-based loss functions introduced above seems like a more natural choice. Nonetheless, we shall briefly introduce one of the common distance-based loss functions as well. ","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"The mean squared error for counterfactual search implemented with respect to the logits is simply the squared ell^2 norm between the target label and a=mathbfw^Tx:","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"beginaligned\n ell(at)= t-a^2\nendaligned","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"The gradient with respect to the vector of features is then:","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"beginaligned\n nabla_xprime ell(at)= 2(a - t) mathbfw \nendaligned","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"As before implementation and visualizations follow below.","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"mse(a,t) = norm(t - a)^2","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"mse (generic function with 1 method)","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"NOTE: I hinted above that the convention of taking derivatives with respect to logits can go wrong depending on the loss function we choose. The plot below demonstrates this point: for t=0 the global minimum of the MSE is of course also at 0. The implication for counterfactual search is that for t=0 the search stops when mathbfw^Txprime=0. But at this point sigma(mathbfw^Txprime)=05, in other words we stop right at the decision boundary, but never cross it. We will see an example of this below. Key takeaway: carefully think about the choice of your loss function and DON'T us distance-based loss functions when optimizing with respect to logits.","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"p1 = plot(a, [mse(a,1) for a=a], title=\"Loss, t=1\", xlab=\"logits\")\np2 = plot(a, [gradient(mse,a,1)[1] for a=a], title=\"Gradient, t=1\", xlab=\"logits\")\np3 = plot(a, [mse(a,0) for a=a], title=\"Loss, t=0\", xlab=\"logits\")\np4 = plot(a, [gradient(mse,a,0)[1] for a=a], title=\"Gradient, t=0\", xlab=\"logits\")\nplot(p1, p2, p3, p4, layout = (2, 2), legend = false)\nsavefig(\"www/loss_grad_mse.png\")","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"(Image: )","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"# Just verifying that the formula for the gradient above indeed yields the same result.\nfunction gradient_man(x,w,y)\n    𝐠 = 2*(w'x - y) .* w\n    return 𝐠\nend;\nplot(a, [gradient_man(a,1,1) for a=a], legend=:bottomright, label=\"Manual\", title=\"Gradient\", xlab=\"logits\")\nscatter!(a, [gradient(mse,a,1)[1] for a=a], label=\"Autodiff\")\nsavefig(\"www/loss_grad_mse_test.png\")","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"(Image: )","category":"page"},{"location":"contributing/loss/#Example-in-2D","page":"Loss functions","title":"Example in 2D","text":"","category":"section"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"To understand the properties of the different loss functions we will now look at a toy example in 2D. The code below generates some random features and assigns labels based on a fixed vector of coefficients using the sigmoid function.","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"# Some random data:\nusing Flux\nusing Random\nRandom.seed!(1234);\nN = 25\nw = [1.0 -2.0]# true coefficients\nb = 0\nX = reshape(randn(2*N),2,N).*1 # random features\ny = Int.(round.(Flux.σ.(w*X .+ b))); # label based on sigmoid","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"The plot below shows the samples coloured by label along with the decision boundary. You can think of this as representing the outcome of some automated decision making system. The highlighted sample was chosen to receive algorithmic recourse in the following: we will search for a counterfactual that leads to a label switch.","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"# Plot with random sample chose for recourse\nfunction plot_data(;clegend=true,title=\"\",size=1.2.*(400,300))\n    x_range = collect(range(minimum(X[1,:]),stop=maximum(X[1,:]),length=50))\n    y_range = collect(range(minimum(X[2,:]),stop=maximum(X[2,:]),length=50))\n    Z = [Flux.σ.(w * [x,y] .+ b)[1] for x=x_range, y=y_range]\n    plt = contourf(\n        x_range, y_range, Z', legend=clegend, title=title, size=size, lw=0.1\n    )\n    scatter!(plt, X[1,reshape(y.==1,25)],X[2,reshape(y.==1,25)],label=\"y=1\",color=1) # features\n    scatter!(plt, X[1,reshape(y.==0,25)],X[2,reshape(y.==0,25)],label=\"y=0\",color=0) # features\n    Plots.abline!(plt,0.5,b,color=\"black\",label=\"\",lw=2) # decision boundary\n    return plt\nend\n\nplt = plot_data()\nx = X[:,5]\ny = round.(Flux.σ.(w*x .+ b))[1]\nscatter!(plt,[x[1]],[x[2]],color=Int.(y),markersize=10,label=\"\")\nsavefig(plt, \"www/loss_examlpe.png\")","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"(Image: )","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"Next we will generating recourse using the CounterfactualExplanations.jl package. First we intantiate our model and based on the assigned label we identify the target (the opposite label).","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"using CounterfactualExplanations\nusing CounterfactualExplanations.Models: LogisticModel\nM = LogisticModel(w, [b]);\ntarget = ifelse(y==1.0,0.0,1.0)\nγ = 0.75","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"0.75","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"Now we instantiate different generators for our different loss functions and different choices of lambda. Finally we generate recourse for each of them:","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"# Generating recourse\nΛ = [0, 1, 5] # varying complexity penalties\nlosses = [:hinge_loss, :logitbinarycrossentropy, :mse]\nrecourses = []\nfor loss in losses\n    for λ in Λ\n        gen = GenericGenerator(λ,0.1,1e-5,loss,nothing) \n        rec = generate_counterfactual(gen, x, M, target, γ, T=25)\n        recourses = vcat(recourses, (rec=rec, λ=λ, loss=loss))\n    end\nend","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"The code below plots the resulting counterfactual paths. ","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"Complexity penalty lambda: has the expected effect of penalizing long counterfactual paths: as the distance between x and xprime the penalty exerts more and more pressure on the gradient in the opposite direction nablaell. For large choices of lambda valid recourse is not attainable.\nConfidence threshold gamma: note how for both log loss and hinge loss we overshoot a bit, that is we end up well beyond the decision boundary. This is because above we chose a confidence threshold of gamma=075. In the context of recourse this choice matters a lot: we have a longer distance to travel (=higher costs for the individual), but we can be more confident that recourse will remain valid. There is of course an interplay between lambda and gamma.\nThe choice of the loss function matters: the distance-based MSE does NOT work without further ajustments when optimizing with respect to logits, as discussed above. ","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"Overall, in the context of this toy example log loss arguably generates the most reasonable outcome: firstly, we can observe that the step size decreases at an increasing rate as the search approaches convergence (which may be desirable); secondly, it appears that increasing lambda leads to a roughly proportional decrease in the distance of the final counterfactual. This stands in contrast to the outcome for hinge loss, where increasing lambda from 0 to 1 barely has any effect at all.","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"# Plotting\nk = length(recourses)\nfunction plot_recourse(rec, idx)\n    plt = plot_data(clegend=false, size=(floor(sqrt(k)) * 350, ceil(sqrt(k)) * 350))\n    idx_path = minimum([idx, size(rec.rec.path)[1]])\n    scatter!(plt, rec.rec.path[1:idx_path,1], rec.rec.path[1:idx_path,2], color=Int(y))\n    scatter!(plt, [rec.rec.path[idx_path,1]],[rec.rec.path[idx_path,2]],color=Int(y),markersize=10)\nend\nmax_path_length = maximum(map(rec -> size(rec.rec.path)[1], recourses))\nanim = @animate for i in 1:max_path_length\n    plots = map(rec -> plot_recourse(rec, i), recourses);\n    plot(plots..., layout = (Int(floor(sqrt(k))), Int(ceil(sqrt(k)))), legend = false, plot_title=\"Iteration: \" * string(i))\nend\ngif(anim, \"www/loss_paths.gif\", fps=5);","category":"page"},{"location":"contributing/loss/","page":"Loss functions","title":"Loss functions","text":"(Image: )","category":"page"},{"location":"tutorials/interop/","page":"Interoperability","title":"Interoperability","text":"CurrentModule = CounterfactualExplanations ","category":"page"},{"location":"tutorials/interop/#Interoperability","page":"Interoperability","title":"Interoperability","text":"","category":"section"},{"location":"tutorials/interop/","page":"Interoperability","title":"Interoperability","text":"The Julia language offers unique support for programming language interoperability. For example, calling Python and R is made remarkably easy through PyCall.jl and RCall.jl. In this tutorial we will see how CounterfactualExplanations.jl leverages this functionality. In particular, we will see that through minimal extra effort the package can be used to explain models that were developed in train in Python or R.","category":"page"},{"location":"tutorials/interop/","page":"Interoperability","title":"Interoperability","text":"!!! warning “Experimental feature” Our work on language interoperability is still in its early stages. What follows is a proof-of-concept.","category":"page"},{"location":"tutorials/interop/","page":"Interoperability","title":"Interoperability","text":"To get started we will first load some two-dimensional toy data:","category":"page"},{"location":"tutorials/interop/","page":"Interoperability","title":"Interoperability","text":"using Random\n# Some random data:\nRandom.seed!(1234);\nN = 100\nusing CounterfactualExplanations\nusing CounterfactualExplanations.Data\nxs, ys = Data.toy_data_non_linear(N)\nX = hcat(xs...)\ncounterfactual_data = CounterfactualData(X,ys')","category":"page"},{"location":"tutorials/interop/#torch-model-trained-in-R","page":"Interoperability","title":"torch model trained in R","text":"","category":"section"},{"location":"tutorials/interop/","page":"Interoperability","title":"Interoperability","text":"The code below builds a simple MLP in R:","category":"page"},{"location":"tutorials/interop/","page":"Interoperability","title":"Interoperability","text":"using RCall\nR\"\"\"\n# Data\nlibrary(torch)\nX <- torch_tensor(t($X))\nys <- torch_tensor($ys)\n\n# Model:\nmlp <- nn_module(\n  initialize = function() {\n    self$layer1 <- nn_linear(2, 32)\n    self$layer2 <- nn_linear(32, 1)\n  },\n  forward = function(input) {\n    input <- self$layer1(input)\n    input <- nnf_sigmoid(input)\n    input <- self$layer2(input)\n    input\n  }\n)\nmodel <- mlp()\noptimizer <- optim_adam(model$parameters, lr = 0.1)\nloss_fun <- nnf_binary_cross_entropy_with_logits\n\"\"\"","category":"page"},{"location":"tutorials/interop/","page":"Interoperability","title":"Interoperability","text":"The following code trains the MLP for the binary prediction task at hand:","category":"page"},{"location":"tutorials/interop/","page":"Interoperability","title":"Interoperability","text":"R\"\"\"\nfor (epoch in 1:100) {\n\n  model$train()  \n\n  # Compute prediction and loss:\n  output <- model(X)[,1]\n  loss <- loss_fun(output, ys)\n\n  # Backpropagation:\n  optimizer$zero_grad()\n  loss$backward()\n  optimizer$step()\n  \n  cat(sprintf(\"Loss at epoch %d: %7f\\n\", epoch, loss$item()))\n}\n\"\"\"","category":"page"},{"location":"tutorials/interop/#Making-the-model-compatible","page":"Interoperability","title":"Making the model compatible","text":"","category":"section"},{"location":"tutorials/interop/","page":"Interoperability","title":"Interoperability","text":"As always we need to extend the logits and probs functions to make the model compatible with CounterfactualExplanations.jl. As evident from the code below, this is actually quite straight-forward: the logits are returned by the torch model and copied form R into the Julia environment. Probabilities are then computed in Julia, by passing the logits through the sigmoid function.","category":"page"},{"location":"tutorials/interop/","page":"Interoperability","title":"Interoperability","text":"using Flux\nusing CounterfactualExplanations, CounterfactualExplanations.Models\nimport CounterfactualExplanations.Models: logits, probs # import functions in order to extend\n\n# Step 1)\nstruct TorchNetwork <: Models.AbstractFittedModel\n    nn::Any\nend\n\n# Step 2)\nfunction logits(M::TorchNetwork, X::AbstractArray)\n  nn = M.nn\n  ŷ = rcopy(R\"as_array($nn(torch_tensor(t($X))))\")\n  ŷ = isa(ŷ, AbstractArray) ? ŷ : [ŷ]\n  return ŷ'\nend\nprobs(M::TorchNetwork, X::AbstractArray)= σ.(logits(M, X))\nM = TorchNetwork(R\"model\")","category":"page"},{"location":"tutorials/interop/#Adapting-the-generator","page":"Interoperability","title":"Adapting the generator","text":"","category":"section"},{"location":"tutorials/interop/","page":"Interoperability","title":"Interoperability","text":"Next we need to do a tiny bit of work on the AbstractGenerator side. By default methods underlying the GenericGenerator are desiged to work with models that have gradient access through Zygote.jl, one of Julia’s main autodifferentiation packages. Of course, Zygote.jl cannot access the gradients of our torch model, so we need to adapt the code slightly. Fortunately, it turns out that all we need to do is extend the function that computes the gradient with respect to the loss function for the generic counterfactual search: ∂ℓ(generator::GenericGenerator, x′, M, t). In particular, we will extend the function by a method that is specific to the TorchNetwork type we defined above. The code below implements this: our new method ∂ℓ calls R in order to use torch’s autodifferentiation functionality for computing the gradient.","category":"page"},{"location":"tutorials/interop/","page":"Interoperability","title":"Interoperability","text":"import CounterfactualExplanations.Generators: ∂ℓ\nusing LinearAlgebra\n\n# Countefactual loss:\nfunction ∂ℓ(generator::AbstractGradientBasedGenerator, counterfactual_state::CounterfactualState) \n  M = counterfactual_state.M\n  nn = M.nn\n  x′ = counterfactual_state.x′\n  t = counterfactual_state.target_encoded\n  R\"\"\"\n  x <- torch_tensor($x′, requires_grad=TRUE)\n  output <- $nn(x)\n  obj_loss <- nnf_binary_cross_entropy_with_logits(output,$t)\n  obj_loss$backward()\n  \"\"\"\n  grad = rcopy(R\"as_array(x$grad)\")\n  return grad\nend","category":"page"},{"location":"tutorials/interop/#Generating-counterfactuals","page":"Interoperability","title":"Generating counterfactuals","text":"","category":"section"},{"location":"tutorials/interop/","page":"Interoperability","title":"Interoperability","text":"From here on onwards we use the CounterfactualExplanations.jl functionality as always. Below we choose a random sample, define our generic generator and finally run the search:","category":"page"},{"location":"tutorials/interop/","page":"Interoperability","title":"Interoperability","text":"# Randomly selected factual:\nRandom.seed!(123)\nx = select_factual(counterfactual_data, rand(1:length(xs))) \ny = round(probs(M, x)[1])\ntarget = ifelse(y==1.0,0.0,1.0) # opposite label as target","category":"page"},{"location":"tutorials/interop/","page":"Interoperability","title":"Interoperability","text":"# Define generator:\ngenerator = GenericGenerator()\n# Generate recourse:\ncounterfactual = generate_counterfactual(x, target, counterfactual_data, M, generator)","category":"page"},{"location":"tutorials/interop/","page":"Interoperability","title":"Interoperability","text":"(Image: )","category":"page"},{"location":"tutorials/interop/#Training-a-torch-model-in-Python","page":"Interoperability","title":"Training a torch model in Python","text":"","category":"section"},{"location":"tutorials/interop/","page":"Interoperability","title":"Interoperability","text":"using PyCall\npy\"\"\"\n# Data\nimport torch\nfrom torch import nn\nX = torch.Tensor($X).T\nys = torch.Tensor($ys)\n\nclass MLP(nn.Module):\n  def __init__(self):\n    super(MLP, self).__init__()\n    self.model = nn.Sequential(\n      nn.Flatten(),\n      nn.Linear(2, 32),\n      nn.Sigmoid(),\n      nn.Linear(32, 1)\n    )\n\n  def forward(self, x):\n    logits = self.model(x)\n    return logits\n\nmodel = MLP()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.1)\nloss_fun = nn.BCEWithLogitsLoss()\n\"\"\"","category":"page"},{"location":"tutorials/interop/","page":"Interoperability","title":"Interoperability","text":"py\"\"\"\nfor epoch in range(100):\n  # Compute prediction and loss:\n  output = model(X).squeeze()\n  loss = loss_fun(output, ys)\n  \n  # Backpropagation:\n  optimizer.zero_grad()\n  loss.backward()\n  optimizer.step()\n  print(f\"Loss at epoch {epoch+1}: {loss.item():>7f}\")\n\"\"\"","category":"page"},{"location":"tutorials/interop/","page":"Interoperability","title":"Interoperability","text":"using Flux\nusing CounterfactualExplanations, CounterfactualExplanations.Models\nimport CounterfactualExplanations.Models: logits, probs # import functions in order to extend\n\n# Step 1)\nstruct PyTorchNetwork <: Models.AbstractFittedModel\n    nn::Any\nend\n\n# Step 2)\nfunction logits(M::PyTorchNetwork, X::AbstractArray)\n  nn = M.nn\n  if !isa(X, Matrix)\n    X = reshape(X, length(X), 1)\n  end\n  ŷ = py\"$nn(torch.Tensor($X).T).detach().numpy()\"\n  ŷ = isa(ŷ, AbstractArray) ? ŷ : [ŷ]\n  return ŷ\nend\nprobs(M::PyTorchNetwork, X::AbstractArray)= σ.(logits(M, X))\nM = PyTorchNetwork(py\"model\")","category":"page"},{"location":"tutorials/interop/","page":"Interoperability","title":"Interoperability","text":"import CounterfactualExplanations.Generators: ∂ℓ\nusing LinearAlgebra\n\n# Countefactual loss:\nfunction ∂ℓ(generator::AbstractGradientBasedGenerator, counterfactual_state::CounterfactualState) \n  M = counterfactual_state.M\n  nn = M.nn\n  x′ = counterfactual_state.x′\n  t = counterfactual_state.target_encoded\n  x = reshape(x′, 1, length(x′))\n  py\"\"\"\n  x = torch.Tensor($x)\n  x.requires_grad = True\n  t = torch.Tensor($[t]).squeeze()\n  output = $nn(x).squeeze()\n  obj_loss = nn.BCEWithLogitsLoss()(output,t)\n  obj_loss.backward()\n  \"\"\"\n  grad = vec(py\"x.grad.detach().numpy()\")\n  return grad\nend","category":"page"},{"location":"tutorials/interop/","page":"Interoperability","title":"Interoperability","text":"# Define generator:\ngenerator = GenericGenerator()\n# Generate recourse:\ncounterfactual = generate_counterfactual(x, target, counterfactual_data, M, generator)","category":"page"},{"location":"tutorials/interop/","page":"Interoperability","title":"Interoperability","text":"(Image: )","category":"page"},{"location":"reference/","page":"Reference","title":"Reference","text":"CurrentModule = CounterfactualExplanations ","category":"page"},{"location":"reference/#All-functions-and-types","page":"Reference","title":"All functions and types","text":"","category":"section"},{"location":"reference/","page":"Reference","title":"Reference","text":"","category":"page"},{"location":"reference/#Exported-functions","page":"Reference","title":"Exported functions","text":"","category":"section"},{"location":"reference/","page":"Reference","title":"Reference","text":"Modules = [CounterfactualExplanations, CounterfactualExplanations.Generators, CounterfactualExplanations.Models, CounterfactualExplanations.Losses]\nPrivate = false","category":"page"},{"location":"reference/#CounterfactualExplanations.generate_counterfactual-Tuple{Union{Int64, AbstractArray}, Union{Int64, AbstractFloat}, CounterfactualData, AbstractFittedModel, AbstractGenerator}","page":"Reference","title":"CounterfactualExplanations.generate_counterfactual","text":"generate_counterfactual(generator::AbstractGenerator, x::Vector, M::Models.AbstractFittedModel, target::AbstractFloat, γ::AbstractFloat; T=1000)\n\nTakes a recourse generator, the factual sample x, the fitted model M, the target label and its desired threshold probability γ. Returns the generated recourse (an object of type Recourse).\n\nExamples\n\nGeneric generator\n\nusing CounterfactualExplanations.Models\nw = [1.0 -2.0] # true coefficients\nb = [0]\nx = [-1,0.5]\ntarget = 1.0\nγ = 0.9\nM = LogisticModel(w, b)\ngenerator = GenericGenerator(0.1,0.1,1e-5,:logitbinarycrossentropy,nothing)\ncounterfactual = generate_counterfactual(generator, x, M, target, γ); # generate recourse\n\nGreedy generator (Bayesian model only)\n\nusing Random, LinearAlgebra\nRandom.seed!(1234)\nμ = [0 1.0 -2.0] # MAP coefficients\nΣ = Symmetric(reshape(randn(9),3,3).*0.1 + UniformScaling(1.0)) # MAP covariance matrix\nx = [-1,0.5]\ntarget = 1.0\nγ = 0.9\nM = CounterfactualExplanations.Models.BayesianLogisticModel(μ, Σ);\ngenerator = GreedyGenerator(0.01,20,:logitbinarycrossentropy,nothing)\ncounterfactual = generate_counterfactual(generator, x, M, target, γ); # generate recourse\n\nSee also:\n\nGenericGenerator(λ::AbstractFloat, ϵ::AbstractFloat, τ::AbstractFloat, loss::Symbol, 𝑭::Union{Nothing,Vector{Symbol}})\nGreedyGenerator(δ::AbstractFloat, n::Int64, loss::Symbol, 𝑭::Union{Nothing,Vector{Symbol}}).\n\n\n\n\n\n","category":"method"},{"location":"reference/#CounterfactualExplanations.Generators.AbstractGenerator","page":"Reference","title":"CounterfactualExplanations.Generators.AbstractGenerator","text":"AbstractGenerator\n\nAn abstract type that serves as the base type for recourse generators. \n\n\n\n\n\n","category":"type"},{"location":"reference/#CounterfactualExplanations.Generators.GenericGenerator","page":"Reference","title":"CounterfactualExplanations.Generators.GenericGenerator","text":"GenericGenerator(λ::AbstractFloat, ϵ::AbstractFloat, τ::AbstractFloat, loss::Symbol, 𝑭::Union{Nothing,Vector{Symbol}})\n\nA constructor for a generic recourse generator. It takes values for the complexity penalty λ, the learning rate ϵ, the tolerance for convergence τ,      the type of loss function to be used in the recourse objective and a mutability constraint mask 𝑭.\n\nExamples\n\ngenerator = GenericGenerator(0.1,0.1,1e-5,:logitbinarycrossentropy,nothing)\n\nSee also:\n\ngenerate_counterfactual(generator::AbstractGradientBasedGenerator, x::Vector, M::Models.AbstractFittedModel, target::AbstractFloat; T=1000)\n\n\n\n\n\n","category":"type"},{"location":"reference/#CounterfactualExplanations.Generators.GreedyGenerator","page":"Reference","title":"CounterfactualExplanations.Generators.GreedyGenerator","text":"GreedyGenerator(δ::AbstractFloat, n::Int, loss::Symbol, 𝑭::Union{Nothing,Vector{Symbol}})\n\nConstructs a greedy recourse generator for Bayesian models. It takes values for the perturbation size δ, the maximum number of times n that any feature can be changed,      the type of loss function to be used in the recourse objective and a mutability constraint mask 𝑭.\n\nExamples\n\ngenerator = GreedyGenerator(0.01,20,:logitbinarycrossentropy, nothing)\n\nSee also:\n\ngenerate_counterfactual(generator::AbstractGradientBasedGenerator, x::Vector, M::Models.AbstractFittedModel, target::AbstractFloat; T=1000)\n\n\n\n\n\n","category":"type"},{"location":"reference/#CounterfactualExplanations.Models.AbstractFittedModel","page":"Reference","title":"CounterfactualExplanations.Models.AbstractFittedModel","text":"AbstractFittedModel\n\nBase type for fitted models.\n\n\n\n\n\n","category":"type"},{"location":"reference/#CounterfactualExplanations.Models.BayesianLogisticModel","page":"Reference","title":"CounterfactualExplanations.Models.BayesianLogisticModel","text":"BayesianLogisticModel(μ::Matrix,Σ::Matrix)\n\nConstructs a Bayesian logistic classifier based on maximum a posteriori (MAP) estimates μ (coefficients including constant term(s)) and Σ (covariance matrix). \n\nExamples\n\nusing Random, LinearAlgebra\nRandom.seed!(1234)\nμ = [0 1.0 -2.0] # MAP coefficients\nΣ = Symmetric(reshape(randn(9),3,3).*0.1 + UniformScaling(1.0)) # MAP covariance matrix\nM = CounterfactualExplanations.Models.BayesianLogisticModel(μ, Σ);\n\nSee also:\n\nlogits(M::BayesianLogisticModel, X::AbstractArray)\nprobs(M::BayesianLogisticModel, X::AbstractArray)\n\n\n\n\n\n","category":"type"},{"location":"reference/#CounterfactualExplanations.Models.LogisticModel","page":"Reference","title":"CounterfactualExplanations.Models.LogisticModel","text":"LogisticModel(W::Matrix,b::AbstractArray)\n\nConstructs a logistic classifier based on arrays containing coefficients w and constant terms b.\n\nExamples\n\nw = [1.0 -2.0] # estimated coefficients\nb = [0] # estimated constant\nM = CounterfactualExplanations.Models.LogisticModel(w, b);\n\nSee also: \n\nlogits(M::LogisticModel, X::AbstractArray)\nprobs(M::LogisticModel, X::AbstractArray)\n\n\n\n\n\n","category":"type"},{"location":"reference/#CounterfactualExplanations.Models.logits-Tuple{BayesianLogisticModel, AbstractArray}","page":"Reference","title":"CounterfactualExplanations.Models.logits","text":"logits(M::BayesianLogisticModel, X::AbstractArray)\n\nComputes logits as μ[1ᵀ Xᵀ]ᵀ.\n\nExamples\n\nusing CounterfactualExplanations.Models\nusing Random, LinearAlgebra\nRandom.seed!(1234)\nμ = [0 1.0 -2.0] # MAP coefficients\nΣ = Symmetric(reshape(randn(9),3,3).*0.1 + UniformScaling(1.0)) # MAP covariance matrix\nM = BayesianLogisticModel(μ, Σ);\nx = [1,1]\nlogits(M, x)\n\nSee also BayesianLogisticModel(μ::Matrix,Σ::Matrix)\n\n\n\n\n\n","category":"method"},{"location":"reference/#CounterfactualExplanations.Models.logits-Tuple{LogisticModel, AbstractArray}","page":"Reference","title":"CounterfactualExplanations.Models.logits","text":"logits(M::LogisticModel, X::AbstractArray)\n\nComputes logits as WX+b.\n\nExamples\n\nusing CounterfactualExplanations.Models\nw = [1.0 -2.0] # estimated coefficients\nb = [0] # estimated constant\nM = LogisticModel(w, b);\nx = [1,1]\nlogits(M, x)\n\nSee also LogisticModel(W::Matrix,b::AbstractArray).\n\n\n\n\n\n","category":"method"},{"location":"reference/#CounterfactualExplanations.Models.probs-Tuple{BayesianLogisticModel, AbstractArray}","page":"Reference","title":"CounterfactualExplanations.Models.probs","text":"probs(M::BayesianLogisticModel, X::AbstractArray)\n\nComputes predictive probabilities using a Probit approximation. \n\nExamples\n\nusing CounterfactualExplanations.Models\nusing Random, LinearAlgebra\nRandom.seed!(1234)\nμ = [0 1.0 -2.0] # MAP coefficients\nΣ = Symmetric(reshape(randn(9),3,3).*0.1 + UniformScaling(1.0)) # MAP covariance matrix\nM = BayesianLogisticModel(μ, Σ);\nx = [1,1]\nprobs(M, x)\n\nSee also BayesianLogisticModel(μ::Matrix,Σ::Matrix)\n\n\n\n\n\n","category":"method"},{"location":"reference/#CounterfactualExplanations.Models.probs-Tuple{LogisticModel, AbstractArray}","page":"Reference","title":"CounterfactualExplanations.Models.probs","text":"probs(M::LogisticModel, X::AbstractArray)\n\nComputes predictive probabilities from logits as σ(WX+b) where 'σ' is the sigmoid function. \n\nExamples\n\nusing CounterfactualExplanations.Models\nw = [1.0 -2.0] # estimated coefficients\nb = [0] # estimated constant\nM = LogisticModel(w, b);\nx = [1,1]\nprobs(M, x)\n\nSee also LogisticModel(W::Matrix,b::AbstractArray).\n\n\n\n\n\n","category":"method"},{"location":"reference/#CounterfactualExplanations.Losses.hinge_loss-Tuple{Any, Any}","page":"Reference","title":"CounterfactualExplanations.Losses.hinge_loss","text":"hinge_loss(ŷ, y)\n\nUses Flux.Losses.hinge_loss to compute hinge loss. If provided labels are in {0,1} they are mapped to {-1,1}. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Internal-functions","page":"Reference","title":"Internal functions","text":"","category":"section"},{"location":"reference/","page":"Reference","title":"Reference","text":"Modules = [CounterfactualExplanations, CounterfactualExplanations.Generators, CounterfactualExplanations.Models, CounterfactualExplanations.Losses]\nPublic = false","category":"page"},{"location":"cats_dogs/","page":"Motivating example","title":"Motivating example","text":"CurrentModule = CounterfactualExplanations","category":"page"},{"location":"cats_dogs/#From-to-a-motivating-example","page":"Motivating example","title":"From 🐱 to 🐶 - a motivating example","text":"","category":"section"},{"location":"cats_dogs/","page":"Motivating example","title":"Motivating example","text":"Suppose we have a sample of cats and dogs with information about two features: height and tail length. Based on these two features we have trained two black box classifiers to distinguish between cats and dogs: firstly, an artificial neural network with weight regularization and secondly, that same neural network but its Bayesian counterpart (Figure 1 below). One individual cat – let’s call her Kitty 🐱 – is friends with a lot of cool dogs and wants to be part of that group. Let’s see how we can generate counterfactual paths for her.","category":"page"},{"location":"cats_dogs/","page":"Motivating example","title":"Motivating example","text":"(Image: Figure 1: Classification for toy dataset of cats and dogs. The contour indicates confidence in predicted labels. Left: MLP with weight regularization. Right: That same MLP, but with Laplace approximation for posterior predictive.)","category":"page"},{"location":"cats_dogs/#From-basic-principles-…","page":"Motivating example","title":"From basic principles …","text":"","category":"section"},{"location":"cats_dogs/","page":"Motivating example","title":"Motivating example","text":"Counterfactual search happens in the feature space: we are interested in understanding how we need to change 🐱’s attributes in order to change the output of the black-box classifier. We will start with the first model, that relies on simple plugin estimates to produce its predictions. The model was built and pre-trained using Flux and can be loaded as follows:","category":"page"},{"location":"cats_dogs/","page":"Motivating example","title":"Motivating example","text":"using CounterfactualExplanations\nusing CounterfactualExplanations.Data: cats_dogs_model\nmodel = cats_dogs_model()","category":"page"},{"location":"cats_dogs/","page":"Motivating example","title":"Motivating example","text":"The training data can be loaded and pre-processed as follows:","category":"page"},{"location":"cats_dogs/","page":"Motivating example","title":"Motivating example","text":"using CounterfactualExplanations.Data: cats_dogs_data\nX, ys = cats_dogs_data()\ncounterfactual_data = CounterfactualData(X,ys')","category":"page"},{"location":"cats_dogs/","page":"Motivating example","title":"Motivating example","text":"In order to make the Flux.jl model compatible with CounterfactualExplanations.jl we need to run the following (more on this in the models tutorial):","category":"page"},{"location":"cats_dogs/","page":"Motivating example","title":"Motivating example","text":"using CounterfactualExplanations.Models\nimport CounterfactualExplanations.Models: logits, probs # import functions in order to extend\n\n# Step 1)\nstruct NeuralNetwork <: Models.AbstractFittedModel\n    model::Any\nend\n\n# Step 2)\nlogits(M::NeuralNetwork, X::AbstractArray) = M.model(X)\nprobs(M::NeuralNetwork, X::AbstractArray)= σ.(logits(M, X))\nM = NeuralNetwork(model);","category":"page"},{"location":"cats_dogs/","page":"Motivating example","title":"Motivating example","text":"Let x be the 2D-feature vector describing Kitty 🐱. Based on those features she is currently labelled as y = 0.0. We have set the target label to 1.0 and the desired confidence in the prediction to γ = 0.75. Now we can use the GenericGenerator for our counterfactual search as follows:","category":"page"},{"location":"cats_dogs/","page":"Motivating example","title":"Motivating example","text":"# Define generator:\ngenerator = GenericGenerator()\n# Generate recourse:\ncounterfactual = generate_counterfactual(x, target, counterfactual_data, M, generator)","category":"page"},{"location":"cats_dogs/","page":"Motivating example","title":"Motivating example","text":"The GenericGenerator implements the search algorithm first proposed by Wachter, Mittelstadt, and Russell (2017). The resulting counterfactual path is shown in Figure 2 below. We can see that 🐱 travels through the feature space until she reaches a destination where the black-box model predicts that with a probability of more than 75% she is actually a dog. Her counterfactual self is in the target class so the algorithmic recourse objective is satisfied. We have also gained an intuitive understanding of how the black-model arrives at its decisions: increasing height and decreasing tail length both raise the predicted probability that 🐱 is actually a dog.","category":"page"},{"location":"cats_dogs/","page":"Motivating example","title":"Motivating example","text":"(Image: Figure 2: Classification for toy dataset of cats and dogs. The contour indicates confidence in predicted labels. Left: MLP with weight regularization. Right: That same MLP, but with Laplace approximation for posterior predictive.)","category":"page"},{"location":"cats_dogs/#…-towards-realistic-counterfactuals.","page":"Motivating example","title":"… towards realistic counterfactuals.","text":"","category":"section"},{"location":"cats_dogs/","page":"Motivating example","title":"Motivating example","text":"The generic search above yielded a counterfactual sample that is still quite distinct from all other individuals in the target class. While we successfully fooled the black-box model, a human might look at 🐱’s counterfactual self and get a little suspicious. One of the requirements for algorithmic recourse is that counterfactuals are realistic and unambigous. A straight-forward way to meet this requirement is to generate counterfactuals by implicitly minimizing predictive uncertainty (Schut et al. 2021). The simple neural network does not incorporate uncertainty, but its Bayesian counterpart does: note how in Figure 1 above the contours for the Bayesian neural network (Laplace) fan out away from the sample. As before we will be using a pre-trained model. Laplace approximation was implemented using BayesLaplace.jl (see here for an introduction). The pre-trained Bayesian model can be loaded as follows:","category":"page"},{"location":"cats_dogs/","page":"Motivating example","title":"Motivating example","text":"using CounterfactualExplanations.Data: cats_dogs_laplace\nla = cats_dogs_laplace()","category":"page"},{"location":"cats_dogs/","page":"Motivating example","title":"Motivating example","text":"As before we need to make the model compatible with CounterfactualExplanations.jl:","category":"page"},{"location":"cats_dogs/","page":"Motivating example","title":"Motivating example","text":"# Step 1)\nstruct LaplaceNeuralNetwork <: Models.AbstractFittedModel\n    la::BayesLaplace.LaplaceRedux\nend\n\n# Step 2)\nlogits(M::LaplaceNeuralNetwork, X::AbstractArray) = M.la.model(X)\nprobs(M::LaplaceNeuralNetwork, X::AbstractArray)= BayesLaplace.predict(M.la, X)\nMᴸ = LaplaceNeuralNetwork(la);","category":"page"},{"location":"cats_dogs/","page":"Motivating example","title":"Motivating example","text":"Using the same target and desired confidence γ as above we finally use the GreedyGenerator generator for our counterfactual search:","category":"page"},{"location":"cats_dogs/","page":"Motivating example","title":"Motivating example","text":"generator = GreedyGenerator(Dict(:δ=>0.1,:n=>15))\ncounterfactual = generate_counterfactual(x, target, counterfactual_data, M, generator)","category":"page"},{"location":"cats_dogs/","page":"Motivating example","title":"Motivating example","text":"The GreedyGenerator implements the approach proposed in Schut et al. (2021): by maximizing the predicted probability of the Bayesian model in Figure 3 below, we implicitly minimize the predictive uncertainty around the counterfactual. This way we end up generating a counterfactual that looks more like the individuals 🐶 in the target class and is therefore more realistic.","category":"page"},{"location":"cats_dogs/","page":"Motivating example","title":"Motivating example","text":"(Image: Figure 3: Classification for toy dataset of cats and dogs. The contour indicates confidence in predicted labels. Left: MLP with weight regularization. Right: That same MLP, but with Laplace approximation for posterior predictive.)","category":"page"},{"location":"cats_dogs/#References","page":"Motivating example","title":"References","text":"","category":"section"},{"location":"cats_dogs/","page":"Motivating example","title":"Motivating example","text":"Schut, Lisa, Oscar Key, Rory Mc Grath, Luca Costabello, Bogdan Sacaleanu, Yarin Gal, et al. 2021. “Generating Interpretable Counterfactual Explanations by Implicit Minimisation of Epistemic and Aleatoric Uncertainties.” In International Conference on Artificial Intelligence and Statistics, 1756–64. PMLR.","category":"page"},{"location":"cats_dogs/","page":"Motivating example","title":"Motivating example","text":"Wachter, Sandra, Brent Mittelstadt, and Chris Russell. 2017. “Counterfactual Explanations Without Opening the Black Box: Automated Decisions and the GDPR.” Harv. JL & Tech. 31: 841.","category":"page"},{"location":"examples/image/MNIST/","page":"MNIST","title":"MNIST","text":"CurrentModule = CounterfactualExplanations ","category":"page"},{"location":"examples/image/MNIST/#MNIST","page":"MNIST","title":"MNIST","text":"","category":"section"},{"location":"examples/image/MNIST/","page":"MNIST","title":"MNIST","text":"In this examples we will see how different counterfactual generators can be used to explain deep learning models for image classification. In particular, we will look at MNIST data and visually inspect how the different generators perturb images of handwritten digits in order to change the predicted label to a target label. Figure 1 shows a random sample of handwritten digits.","category":"page"},{"location":"examples/image/MNIST/","page":"MNIST","title":"MNIST","text":"using CounterfactualExplanations, Plots, MLDatasets\nusing MLDatasets.MNIST: convert2image\nusing BSON: @save, @load","category":"page"},{"location":"examples/image/MNIST/","page":"MNIST","title":"MNIST","text":"train_x, train_y = MNIST.traindata()\ninput_dim = prod(size(train_x[:,:,1]))\nusing Images, Random, StatsBase\nRandom.seed!(1)\nn_samples = 10\nsamples = train_x[:,:,sample(1:end, n_samples, replace=false)]\nmosaic = mosaicview([convert2image(samples[:,:,i]) for i ∈ 1:n_samples]...,ncol=Int(n_samples/2))\nplt = plot(mosaic, size=(500,260), axis=nothing, background=:transparent)\nsavefig(plt, \"www/mnist_samples.png\")","category":"page"},{"location":"examples/image/MNIST/","page":"MNIST","title":"MNIST","text":"(Image: Figure 1: A few random handwritten digits.)","category":"page"},{"location":"examples/image/MNIST/#Pre-trained-classifiers","page":"MNIST","title":"Pre-trained classifiers","text":"","category":"section"},{"location":"examples/image/MNIST/","page":"MNIST","title":"MNIST","text":"Next we will load two pre-trained deep-learning classifiers:","category":"page"},{"location":"examples/image/MNIST/","page":"MNIST","title":"MNIST","text":"Simple MLP - model\nDeep ensemble - ensemble","category":"page"},{"location":"examples/image/MNIST/","page":"MNIST","title":"MNIST","text":"using Flux\nusing CounterfactualExplanations.Data: mnist_data, mnist_model, mnist_ensemble\nx,y,data = getindex.(Ref(mnist_data()), (\"x\", \"y\", \"data\"))\nmodel = mnist_model()\nensemble = mnist_ensemble();","category":"page"},{"location":"examples/image/MNIST/","page":"MNIST","title":"MNIST","text":"The following code just prepares the models to be used with CounterfactualExplanations.jl:","category":"page"},{"location":"examples/image/MNIST/","page":"MNIST","title":"MNIST","text":"using CounterfactualExplanations, CounterfactualExplanations.Models\nimport CounterfactualExplanations.Models: logits, probs # import functions in order to extend\n\n# MLP:\n# Step 1)\nstruct NeuralNetwork <: Models.AbstractFittedModel\n    nn::Any\nend\n# Step 2)\nlogits(M::NeuralNetwork, X::AbstractArray) = M.nn(X)\nprobs(M::NeuralNetwork, X::AbstractArray)= softmax(logits(M, X))\nM = NeuralNetwork(model)\n\n# Deep ensemble:\n# Step 1)\nstruct FittedEnsemble <: Models.AbstractFittedModel\n    ensemble::AbstractArray\nend\n# Step 2)\nusing Statistics\nlogits(M::FittedEnsemble, X::AbstractArray) = mean(Flux.stack([nn(X) for nn in M.ensemble],3), dims=3)\nprobs(M::FittedEnsemble, X::AbstractArray) = mean(Flux.stack([softmax(nn(X)) for nn in M.ensemble],3),dims=3)\nM_ensemble=FittedEnsemble(ensemble);","category":"page"},{"location":"examples/image/MNIST/#Generating-counterfactuals","page":"MNIST","title":"Generating counterfactuals","text":"","category":"section"},{"location":"examples/image/MNIST/","page":"MNIST","title":"MNIST","text":"We will look at four different approaches here:","category":"page"},{"location":"examples/image/MNIST/","page":"MNIST","title":"MNIST","text":"Generic approach for the MLP (Wachter, Mittelstadt, and Russell 2017).\nGreedy approach for the MLP.\nGeneric approach for the deep ensemble.\nGreedy approach for the deep ensemble (Schut et al. 2021).","category":"page"},{"location":"examples/image/MNIST/","page":"MNIST","title":"MNIST","text":"They can be implemented using the GenericGenerator and the GreedyGenerator.","category":"page"},{"location":"examples/image/MNIST/#Turning-a-9-into-a-4","page":"MNIST","title":"Turning a 9 into a 4","text":"","category":"section"},{"location":"examples/image/MNIST/","page":"MNIST","title":"MNIST","text":"We will start with an example that should yield intuitive results: the process of turning a handwritten 9 in Figure 2 into a 4 is straight-forward for a human - just erase the top part. Let’s see how the different algorithmic approaches perform.","category":"page"},{"location":"examples/image/MNIST/","page":"MNIST","title":"MNIST","text":"# Randomly selected factual:\nRandom.seed!(1234);\nx = Flux.unsqueeze(x[:,rand(1:size(x)[2])],2)\ntarget = 5\nγ = 0.95\nimg = convert2image(reshape(x,Int(sqrt(input_dim)),Int(sqrt(input_dim))))\nplt_orig = plot(img, title=\"Original\", axis=nothing)\nsavefig(plt_orig, \"www/mnist_original.png\")","category":"page"},{"location":"examples/image/MNIST/","page":"MNIST","title":"MNIST","text":"(Image: Figure 2: A random handwritten 9.)","category":"page"},{"location":"examples/image/MNIST/","page":"MNIST","title":"MNIST","text":"The code below implements the four different approaches one by one. Figure 3 shows the resulting counterfactuals. In every case the desired label switch is achieved, that is the corresponding classifier classifies the counterfactual as a four. But arguably from a human perspective only the counterfactuals for the deep ensemble look like a 4. For the MLP, both the generic and the greedy approach generate coutnerfactuals that look much like adversarial examples.","category":"page"},{"location":"examples/image/MNIST/","page":"MNIST","title":"MNIST","text":"# Generic - MLP\ngenerator = GenericGenerator(0.1,0.1,1e-5,:logitcrossentropy,nothing)\ncounterfactual = generate_counterfactual(generator, x, M, target, γ; feasible_range=(0.0,1.0)) # generate recourse\nimg = convert2image(reshape(counterfactual.x′,Int(sqrt(input_dim)),Int(sqrt(input_dim))))\nplt_wachter = plot(img, title=\"MLP - Wachter\")\n\n# Greedy - MLP\ngenerator = GreedyGenerator(0.1,15,:logitcrossentropy,nothing)\ncounterfactual = generate_counterfactual(generator, x, M, target, γ; feasible_range=(0.0,1.0)) # generate recourse\nimg = convert2image(reshape(counterfactual.x′,Int(sqrt(input_dim)),Int(sqrt(input_dim))))\nplt_greedy = plot(img, title=\"MLP - Greedy\")\n\n# Generic - Deep Ensemble\ngenerator = GenericGenerator(0.1,0.1,1e-5,:logitcrossentropy,nothing)\ncounterfactual = generate_counterfactual(generator, x, M_ensemble, target, γ; feasible_range=(0.0,1.0)) # generate recourse\nimg = convert2image(reshape(counterfactual.x′,Int(sqrt(input_dim)),Int(sqrt(input_dim))))\nplt_wachter_de = plot(img, title=\"Ensemble - Wachter\")\n\n# Greedy - Deep Ensemble\ngenerator = GreedyGenerator(0.1,15,:logitcrossentropy,nothing)\ncounterfactual = generate_counterfactual(generator, x, M_ensemble, target, γ; feasible_range=(0.0,1.0)) # generate recourse\nimg = convert2image(reshape(counterfactual.x′,Int(sqrt(input_dim)),Int(sqrt(input_dim))))\nplt_greedy_de = plot(img, title=\"Ensemble - Greedy\")\n\nplt_list = [plt_orig, plt_wachter, plt_greedy, plt_wachter_de, plt_greedy_de]\nplt = plot(plt_list...,layout=(1,length(plt_list)),axis=nothing, size=(1200,240))\nsavefig(plt, \"www/MNIST_9to4.png\")","category":"page"},{"location":"examples/image/MNIST/","page":"MNIST","title":"MNIST","text":"(Image: Figure 3: Counterfactual explanations for MNIST data: turning a 9 into a 4)","category":"page"},{"location":"examples/image/MNIST/#References","page":"MNIST","title":"References","text":"","category":"section"},{"location":"examples/image/MNIST/","page":"MNIST","title":"MNIST","text":"Schut, Lisa, Oscar Key, Rory Mc Grath, Luca Costabello, Bogdan Sacaleanu, Yarin Gal, et al. 2021. “Generating Interpretable Counterfactual Explanations by Implicit Minimisation of Epistemic and Aleatoric Uncertainties.” In International Conference on Artificial Intelligence and Statistics, 1756–64. PMLR.","category":"page"},{"location":"examples/image/MNIST/","page":"MNIST","title":"MNIST","text":"Wachter, Sandra, Brent Mittelstadt, and Chris Russell. 2017. “Counterfactual Explanations Without Opening the Black Box: Automated Decisions and the GDPR.” Harv. JL & Tech. 31: 841.","category":"page"},{"location":"tutorials/multi/","page":"Multi-class target","title":"Multi-class target","text":"CurrentModule = CounterfactualExplanations ","category":"page"},{"location":"tutorials/multi/#Recourse-for-multi-class-targets","page":"Multi-class target","title":"Recourse for multi-class targets","text":"","category":"section"},{"location":"tutorials/multi/","page":"Multi-class target","title":"Multi-class target","text":"using CounterfactualExplanations.Data\nxs, ys = Data.toy_data_multi()\nX = hcat(xs...)\ny_train = Flux.onehotbatch(ys, unique(ys))\ny_train = Flux.unstack(y_train',1)\nplt = plot()\nplt = plot_data!(plt,X',ys)\nsavefig(plt, joinpath(www_path, \"multi_samples.png\"))","category":"page"},{"location":"tutorials/multi/","page":"Multi-class target","title":"Multi-class target","text":"(Image: )","category":"page"},{"location":"tutorials/multi/#Classifier","page":"Multi-class target","title":"Classifier","text":"","category":"section"},{"location":"tutorials/multi/","page":"Multi-class target","title":"Multi-class target","text":"n_hidden = 32\nout_dim = length(unique(ys))\nkw = (output_dim=out_dim, dropout=true)\nnn = build_model(;kw...)\nloss(x, y) = Flux.Losses.logitcrossentropy(nn(x), y)\nps = Flux.params(nn)\ndata = zip(xs,y_train)","category":"page"},{"location":"tutorials/multi/","page":"Multi-class target","title":"Multi-class target","text":"using Flux.Optimise: update!, ADAM\nopt = ADAM()\nepochs = 10\navg_loss(data) = mean(map(d -> loss(d[1],d[2]), data))\nshow_every = epochs/10\n\nfor epoch = 1:epochs\n  for d in data\n    gs = gradient(params(nn)) do\n      l = loss(d...)\n    end\n    update!(opt, params(nn), gs)\n  end\n  if epoch % show_every == 0\n    println(\"Epoch \" * string(epoch))\n    @show avg_loss(data)\n  end\nend","category":"page"},{"location":"tutorials/multi/","page":"Multi-class target","title":"Multi-class target","text":"using CounterfactualExplanations, CounterfactualExplanations.Models\nimport CounterfactualExplanations.Models: logits, probs # import functions in order to extend\n\n# Step 1)\nstruct NeuralNetwork <: Models.AbstractFittedModel\n    nn::Any\nend\n\n# Step 2)\nlogits(M::NeuralNetwork, X::AbstractArray) = M.nn(X)\nprobs(M::NeuralNetwork, X::AbstractArray)= softmax(logits(M, X))\nM = NeuralNetwork(nn);","category":"page"},{"location":"tutorials/multi/","page":"Multi-class target","title":"Multi-class target","text":"(Image: )","category":"page"},{"location":"tutorials/multi/","page":"Multi-class target","title":"Multi-class target","text":"counterfactual_data = CounterfactualData(X,ys')","category":"page"},{"location":"tutorials/multi/","page":"Multi-class target","title":"Multi-class target","text":"# Randomly selected factual:\nRandom.seed!(42)\nx = select_factual(counterfactual_data, rand(1:size(X)[2])) \ny = Flux.onecold(probs(M, x),unique(ys))\ntarget = rand(unique(ys)[1:end .!= y]) # opposite label as target","category":"page"},{"location":"tutorials/multi/","page":"Multi-class target","title":"Multi-class target","text":"# Define generator:\ngenerator = GenericGenerator(;loss=:logitcrossentropy)\n# Generate recourse:\ncounterfactual = generate_counterfactual(x, target, counterfactual_data, M, generator)","category":"page"},{"location":"tutorials/multi/","page":"Multi-class target","title":"Multi-class target","text":"(Image: )","category":"page"},{"location":"tutorials/multi/#Deep-ensemble","page":"Multi-class target","title":"Deep ensemble","text":"","category":"section"},{"location":"tutorials/multi/","page":"Multi-class target","title":"Multi-class target","text":"ensemble = build_ensemble(5;kw=(output_dim=out_dim,))\nensemble, = forward(ensemble, data, opt, n_epochs=epochs, plot_loss=false)","category":"page"},{"location":"tutorials/multi/","page":"Multi-class target","title":"Multi-class target","text":"# Step 1)\nstruct FittedEnsemble <: Models.AbstractFittedModel\n    ensemble::AbstractArray\nend\n\n# Step 2)\nusing Statistics\nlogits(M::FittedEnsemble, X::AbstractArray) = mean(Flux.stack([nn(X) for nn in M.ensemble],3), dims=3)\nprobs(M::FittedEnsemble, X::AbstractArray) = mean(Flux.stack([softmax(nn(X)) for nn in M.ensemble],3),dims=3)\n\nM=FittedEnsemble(ensemble);","category":"page"},{"location":"tutorials/multi/","page":"Multi-class target","title":"Multi-class target","text":"(Image: )","category":"page"},{"location":"tutorials/multi/","page":"Multi-class target","title":"Multi-class target","text":"generator = GreedyGenerator(loss=:logitcrossentropy,δ=0.25,n=20)\ncounterfactual = generate_counterfactual(generator, x, M, target, γ); # generate recourse","category":"page"},{"location":"tutorials/multi/","page":"Multi-class target","title":"Multi-class target","text":"(Image: )","category":"page"},{"location":"","page":"Home","title":"Home","text":"CurrentModule = CounterfactualExplanations","category":"page"},{"location":"#CounterfactualExplanations","page":"Home","title":"CounterfactualExplanations","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Documentation for CounterfactualExplanations.jl.","category":"page"},{"location":"","page":"Home","title":"Home","text":"CounterfactualExplanations.jl is a Julia package for generating Counterfactual Explanations (CE) and Algorithmic Recourse (AR) for black-box algorithms. Both CE and AR are related tools for interpretable machine learning. See below for short introduction and other resources or dive straight into the docs.","category":"page"},{"location":"#Installation","page":"Home","title":"Installation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The first release of this package is now on Julia’s General Registry and can be installed as follows:","category":"page"},{"location":"","page":"Home","title":"Home","text":"using Pkg\nPkg.add(\"CounterfactualExplanations\")","category":"page"},{"location":"","page":"Home","title":"Home","text":"CounterfactualExplanations.jl is currently under active development. To install the development version of the package you can run the following command:","category":"page"},{"location":"","page":"Home","title":"Home","text":"using Pkg\nPkg.add(url=\"https://github.com/pat-alt/CounterfactualExplanations.jl\", rev=\"dev\")","category":"page"},{"location":"#Background-and-motivation","page":"Home","title":"Background and motivation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Algorithms used for automated decision-making such as deep neural networks have become so complex and opaque over recent years that they are generally considered as black boxes. This creates the following undesirable scenario: the human operators in charge of the black-box decision-making system do not understand how it works and essentially rely on it blindly. Conversely, those individuals who are subject to the decisions produced by such systems typically have no way of challenging them.","category":"page"},{"location":"","page":"Home","title":"Home","text":"“You cannot appeal to (algorithms). They do not listen. Nor do they bend.”— Cathy O’Neil in Weapons of Math Destruction, 2016","category":"page"},{"location":"","page":"Home","title":"Home","text":"Counterfactual Explanations can help programmers make sense of the systems they build: they explain how inputs into a system need to change for it to produce a different output. The figure below, for example, shows various counterfactuals generated through different approaches that all turn the predicted label of some classifier from a 9 into a 4. CEs that involve realistic and actionable changes such as the one on the far right can be used for the purpose of individual counterfactual.","category":"page"},{"location":"","page":"Home","title":"Home","text":"(Image: Realistic counterfactual explanations for MNIST data: turning a 4 into a 9.)","category":"page"},{"location":"","page":"Home","title":"Home","text":"Algorithmic Recourse (AR) offers individuals subject to algorithms a way to turn a negative decision into positive one. The figure below illustrates the point of AR through a toy example: it shows the counterfactual path of one sad cat 🐱 that would like to be grouped with her cool dog friends. Unfortunately, based on her tail length and height she was classified as a cat by a black-box classifier. The recourse algorithm perturbs her features in such a way that she ends up crossing the decision boundary into a dense region inside the target class.","category":"page"},{"location":"","page":"Home","title":"Home","text":"(Image: A sad 🐱 on its counterfactual path to its cool dog friends.)","category":"page"},{"location":"#Usage-example","page":"Home","title":"Usage example","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Generating counterfactuals will typically look like follows:","category":"page"},{"location":"","page":"Home","title":"Home","text":"using CounterfactualExplanations\nusing CounterfactualExplanations.Models\nw = [1.0 -2.0] # true coefficients\nb = [0]\nM = LogisticModel(w, b)\nx = [-1,0.5]\ntarget = 1.0\nγ = 0.9\ngenerator = GenericGenerator(0.1,0.1,1e-5,:logitbinarycrossentropy,nothing)\ncounterfactual = generate_counterfactual(generator, x, M, target, γ); # generate recourse","category":"page"},{"location":"","page":"Home","title":"Home","text":"We can see that the counterfactual label y′ corresponds to the target:","category":"page"},{"location":"","page":"Home","title":"Home","text":"julia> counterfactual.y′\n1.0\n\njulia> counterfactual.x\n2-element Vector{Float64}:\n -1.0\n  0.5\n\njulia> counterfactual.y\n0.0\n\njulia> counterfactual.x′\n2-element Vector{Float64}:\n -0.15867040347424893\n -1.182659193051502\n\njulia> counterfactual.y′\n1.0","category":"page"},{"location":"#Goals-and-limitations","page":"Home","title":"Goals and limitations","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The goal for this library is to contribute to efforts towards trustworthy machine learning in Julia. The Julia language has an edge when it comes to trustworthiness: it is very transparent. Packages like this one are generally written in 100% Julia, which makes it easy for users and developers to understand and contribute to open source code.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Eventually the aim for this project is to be at least at par with the amazing CARLA Python library which was presented at NeurIPS 2021. Currently CounterfactualExplanations.jl falls short of this goal in a number of ways: 1) the number of counterfactual generators is limited, 2) it lacks a framework for evaluating and benchmarking different generators, 3) it has so far been a one-person effort and not yet gone through a formal review.","category":"page"},{"location":"#Citation","page":"Home","title":"Citation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"If you want to use this codebase, please cite:","category":"page"},{"location":"","page":"Home","title":"Home","text":"@software{altmeyer2022CounterfactualExplanations,\n  author = {Patrick Altmeyer},\n  title = {{CounterfactualExplanations.jl - a Julia package for Counterfactual Explanations and Algorithmic Recourse}},\n  url = {https://github.com/pat-alt/CounterfactualExplanations.jl},\n  version = {0.1.0},\n  year = {2022}\n}","category":"page"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"CurrentModule = CounterfactualExplanations ","category":"page"},{"location":"tutorials/models/#Models","page":"Models","title":"Models","text":"","category":"section"},{"location":"tutorials/models/#Default-models","page":"Models","title":"Default models","text":"","category":"section"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"There are currently constructors for two default models, which mainly serve illustrative purposes (Figure 1 below). Both take sets of estimated parameters at the point of instantiation: the constructors will not fit a model for you, but assume that you have already estimated the respective model yourself and have access to its parameter estimates. Based on the supplied parameters methods to predict logits and probabilities are already implemented and used in the counterfactual search.","category":"page"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"using GraphRecipes\np = plot(CounterfactualExplanations.Models.AbstractFittedModel, method=:tree, fontsize=8, nodeshape=:rect, axis_buffer=0.4, nodecolor=:white)\nsavefig(p, joinpath(www_path,\"models.png\"))","category":"page"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"(Image: Figure 1: Schematic overview of classes in `Models` module.)","category":"page"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"For the simple logistic regression model logits are computed as a = X**w + b and probabilities are simply σ(a). For the Bayesian logistic regression model logits are computed as X**μ and the predictive posterior is computed through Laplace approximation.","category":"page"},{"location":"tutorials/models/#Custom-models","page":"Models","title":"Custom models","text":"","category":"section"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"Apart from the default models you can use any arbitrary (differentiable) model and generate recourse in the same way as before. Only two steps are necessary to make your own model compatible with CounterfactualExplanations.jl:","category":"page"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"The model needs to be declared as a subtype of CounterfactualExplanations.Models.AbstractFittedModel.\nYou need to extend the functions CounterfactualExplanations.Models.logits and CounterfactualExplanations.Models.probs to accept your custom model.","category":"page"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"Below we will go through a simple example to see how this can be done in practice.","category":"page"},{"location":"tutorials/models/#Neural-network","page":"Models","title":"Neural network","text":"","category":"section"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"In this example we will build a simple artificial neural network using Flux.jl for a binary classification task. First we generate some toy data below. The code that generates this data was borrowed from a great tutorial about Bayesian neural networks provided by Turing.jl, which you may find here.","category":"page"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"The plot below shows the generated samples in the 2D feature space where colours indicate the associated labels. CounterfactualExplanationsly this data is not linearly separable and the default LogisticModel would be ill suited for this classification task.","category":"page"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"# Number of points to generate.\nN = 80\nM = round(Int, N / 4)\nRandom.seed!(1234)\n\nusing CounterfactualExplanations.Data\nxs, ys = Data.toy_data_non_linear(N)\nX = hcat(xs...)","category":"page"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"(Image: )","category":"page"},{"location":"tutorials/models/#Training-the-model","page":"Models","title":"Training the model","text":"","category":"section"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"Instead we will build a simple artificial neural network nn with one hidden layer. For additional resources on how to do deep learning with Flux.jl just have a look at their documentation.","category":"page"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"nn = build_model(dropout=true,activation=Flux.σ)\nloss(x, y) = Flux.Losses.logitbinarycrossentropy(nn(x), y)\nps = Flux.params(nn)\ndata = zip(xs,ys);","category":"page"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"The code below trains the neural network for the task at hand. The plot shows the (training) loss over time. Note that normally we would be interested in loss with respect to a validation data set. But since we are primarily interested in generated recourse for a trained classifier, here we will just keep things very simple.","category":"page"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"using Flux.Optimise: update!, ADAM\nopt = ADAM()\nepochs = 100\navg_loss(data) = mean(map(d -> loss(d[1],d[2]), data))\nshow_every = epochs/10\n\nfor epoch = 1:epochs\n  for d in data\n    gs = gradient(params(nn)) do\n      l = loss(d...)\n    end\n    update!(opt, params(nn), gs)\n  end\n  if epoch % show_every == 0\n    println(\"Epoch \" * string(epoch))\n    @show avg_loss(data)\n  end\nend","category":"page"},{"location":"tutorials/models/#Generating-counterfactuals","page":"Models","title":"Generating counterfactuals","text":"","category":"section"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"Now it’s game time: we have a fitted model M : 𝒳 ↦ 𝒴 and are interested in generating recourse for some individual x ∈ 𝒳. As mentioned above we need to do a bit more work to prepare the model to be used by CounterfactualExplanations.jl.","category":"page"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"The code below takes care of all of that: in step 1) it declares our model as a subtype of Models.AbstractFittedModel and in step 2) it just extends the two functions.","category":"page"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"using CounterfactualExplanations, CounterfactualExplanations.Models\nimport CounterfactualExplanations.Models: logits, probs # import functions in order to extend\n\n# Step 1)\nstruct NeuralNetwork <: Models.AbstractFittedModel\n    nn::Any\nend\n\n# Step 2)\nlogits(M::NeuralNetwork, X::AbstractArray) = M.nn(X)\nprobs(M::NeuralNetwork, X::AbstractArray)= σ.(logits(M, X))\nM = NeuralNetwork(nn)","category":"page"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"The plot below shows the predicted probabilities in the feature domain. Evidently our simple neural network is doing very well on the training data, as expected.","category":"page"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"(Image: )","category":"page"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"To preprocess the data we simply run the following:","category":"page"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"counterfactual_data = CounterfactualData(X,ys')","category":"page"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"Now we just select a random sample from our data and based on its current label we set as our target the opposite label and desired threshold for the predicted probability.","category":"page"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"using Random\nRandom.seed!(123)\nx = select_factual(counterfactual_data, rand(1:size(X)[2])) \ny = round(probs(M, x)[1])\ntarget = ifelse(y==1.0,0.0,1.0) # opposite label as target","category":"page"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"Then finally we use the GenericGenerator to generate counterfactual. The plot further below shows the resulting counterfactual path.","category":"page"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"# Define generator:\ngenerator = GenericGenerator()\n# Generate recourse:\ncounterfactual = generate_counterfactual(x, target, counterfactual_data, M, generator)","category":"page"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"(Image: )","category":"page"},{"location":"tutorials/models/#Ensemble-of-neural-networks","page":"Models","title":"Ensemble of neural networks","text":"","category":"section"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"In the context of Bayesian classifiers the GreedyGenerator can be used since minimizing the predictive uncertainty acts as a proxy for realism and unambiquity. In other words, if we have a model that incorporates uncertainty, we can generate realistic counterfactuals without the need for a complexity penalty.","category":"page"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"One efficient way to produce uncertainty estimates in the context of deep learning is to simply use an ensemble of artificial neural networks (also referred to as deep ensemble). To this end we can use the build_model function from above repeatedly to compose an ensemble of K neural networks:","category":"page"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"ensemble = build_ensemble(5;kw=(dropout=true,activation=Flux.σ))","category":"page"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"Training this ensemble boils down to training each neural network separately:","category":"page"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"ensemble, anim = forward(ensemble, data, opt, n_epochs=epochs, plot_every=show_every); # fit the ensemble\ngif(anim, joinpath(www_path, \"models_ensemble_loss.gif\"), fps=10)","category":"page"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"(Image: )","category":"page"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"Once again it is straight-forward to make the model compatible with the package. Note that for an ensemble model the predicted logits and probabilities are just averages over predictions produced by all K models.","category":"page"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"# Step 1)\nstruct FittedEnsemble <: Models.AbstractFittedModel\n    ensemble::AbstractArray\nend\n\n# Step 2)\nlogits(M::FittedEnsemble, X::AbstractArray) = mean(Flux.flatten(Flux.stack([nn(X) for nn in M.ensemble],1)),dims=1)\nprobs(M::FittedEnsemble, X::AbstractArray) = mean(Flux.flatten(Flux.stack([σ.(nn(X)) for nn in M.ensemble],1)),dims=1)\n\nM=FittedEnsemble(ensemble)","category":"page"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"Again we plot the predicted probabilities in the feature domain. As expected the ensemble is more conservative because it incorporates uncertainty: the predicted probabilities splash out more than before, especially in regions that are not populated by samples.","category":"page"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"(Image: )","category":"page"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"Finally, we use the GreedyGenerator for the counterfactual search. For the same desired threshold γ as before, the counterfactual ends up somewhat closer to a cluster of original samples. In other words we end up providing more realisitic albeit likely more costly counterfactual.","category":"page"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"generator = GreedyGenerator(Dict(:δ=>0.1,:n=>30))\ncounterfactual = generate_counterfactual(x, target, counterfactual_data, M, generator)","category":"page"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"(Image: )","category":"page"}]
}
