var documenterSearchIndex = {"docs":
[{"location":"reference/reference/","page":"Full references","title":"Full references","text":"CurrentModule = AlgorithmicRecourse ","category":"page"},{"location":"reference/reference/#All-functions-and-types","page":"Full references","title":"All functions and types","text":"","category":"section"},{"location":"reference/reference/","page":"Full references","title":"Full references","text":"","category":"page"},{"location":"reference/reference/","page":"Full references","title":"Full references","text":"Modules = [AlgorithmicRecourse, AlgorithmicRecourse.Generators, AlgorithmicRecourse.Models, AlgorithmicRecourse.Losses]\nPrivate = true","category":"page"},{"location":"reference/reference/#AlgorithmicRecourse.Recourse","page":"Full references","title":"AlgorithmicRecourse.Recourse","text":"Recourse(x̲::AbstractArray, y̲::Float64, path::Matrix{Float64}, generator::Generators.Generator, x̅::AbstractArray, y̅::Float64, 𝑴::Models.FittedModel, target::Float64)\n\nCollects all variables relevant to the recourse outcome. \n\n\n\n\n\n","category":"type"},{"location":"reference/reference/#AlgorithmicRecourse.apply_mutability-Tuple{AbstractArray, Vector{Symbol}}","page":"Full references","title":"AlgorithmicRecourse.apply_mutability","text":"apply_mutability(Δx̲::AbstractArray, 𝑭::Vector{Symbol})\n\nApply mutability constraints to Δx̲ based on vector of constraints 𝑭.\n\nExamples\n\n𝑭 = [:both, :increase, :decrease, :none] _mutability([-1,1,-1,1], 𝑭) # all but :none pass _mutability([-1,-1,-1,1], 𝑭) # all but :increase and :none pass _mutability([-1,1,1,1], 𝑭) # all but :decrease and :none pass _mutability([-1,-1,1,1], 𝑭) # only :both passes\n\n\n\n\n\n","category":"method"},{"location":"reference/reference/#AlgorithmicRecourse.threshold_reached-Tuple{AlgorithmicRecourse.Models.FittedModel, AbstractArray, Float64, Float64}","page":"Full references","title":"AlgorithmicRecourse.threshold_reached","text":"threshold_reached(𝑴::Models.FittedModel, x̲::AbstractArray, target::Float64, γ::Float64)\n\nChecks if confidence threshold has been reached. \n\n\n\n\n\n","category":"method"},{"location":"reference/reference/#AlgorithmicRecourse.Models.BayesianLogisticModel","page":"Full references","title":"AlgorithmicRecourse.Models.BayesianLogisticModel","text":"BayesianLogisticModel(w::AbstractArray,b::AbstractArray)\n\nConstructs a Bayesian logistic classifier based on maximum a posteriori (MAP) estimates μ (coefficients including constant term(s)) and Σ (covariance matrix). \n\nExamples\n\nusing Random, LinearAlgebra\nRandom.seed!(1234)\nμ = [0, 1.0,-2.0] # MAP coefficients\nΣ = Symmetric(reshape(randn(9),3,3).*0.1 + UniformScaling(1.0)) # MAP covariance matrix\n𝑴 = AlgorithmicRecourse.Models.BayesianLogisticModel(μ, Σ);\n\nSee also:\n\nlogits(𝑴::BayesianLogisticModel, X::AbstractArray)\nprobs(𝑴::BayesianLogisticModel, X::AbstractArray)\nconfidence(𝑴::BayesianLogisticModel, X::AbstractArray)\n\n\n\n\n\n","category":"type"},{"location":"reference/reference/#AlgorithmicRecourse.Models.LogisticModel","page":"Full references","title":"AlgorithmicRecourse.Models.LogisticModel","text":"LogisticModel(w::AbstractArray,b::AbstractArray)\n\nConstructs a logistic classifier based on arrays containing coefficients w and constant terms b.\n\nExamples\n\nw = [1.0,-2.0] # estimated coefficients\nb = [0] # estimated constant\n𝑴 = AlgorithmicRecourse.Models.LogisticModel(w, b);\n\nSee also: \n\nlogits(𝑴::LogisticModel, X::AbstractArray)\nprobs(𝑴::LogisticModel, X::AbstractArray)\n\n\n\n\n\n","category":"type"},{"location":"reference/reference/#AlgorithmicRecourse.Models.logits-Tuple{AlgorithmicRecourse.Models.BayesianLogisticModel, AbstractArray}","page":"Full references","title":"AlgorithmicRecourse.Models.logits","text":"logits(𝑴::BayesianLogisticModel, X::AbstractArray)\n\nComputes logits as [1 X]μ.\n\nExamples\n\nusing Random, LinearAlgebra\nRandom.seed!(1234)\nμ = [0, 1.0,-2.0] # MAP coefficients\nΣ = Symmetric(reshape(randn(9),3,3).*0.1 + UniformScaling(1.0)) # MAP covariance matrix\n𝑴 = AlgorithmicRecourse.Models.BayesianLogisticModel(μ, Σ);\nx = reshape([1,1],1,2)\nlogits(𝑴, x)\n\nSee also BayesianLogisticModel(w::AbstractArray,b::AbstractArray)\n\n\n\n\n\n","category":"method"},{"location":"reference/reference/#AlgorithmicRecourse.Models.logits-Tuple{AlgorithmicRecourse.Models.LogisticModel, AbstractArray}","page":"Full references","title":"AlgorithmicRecourse.Models.logits","text":"logits(𝑴::LogisticModel, X::AbstractArray)\n\nComputes logits as Xw+b.\n\nExamples\n\nw = [1.0,-2.0] # estimated coefficients\nb = [0] # estimated constant\n𝑴 = AlgorithmicRecourse.Models.LogisticModel(w, b);\nx = reshape([1,1],1,2)\nlogits(𝑴, x)\n\nSee also LogisticModel(w::AbstractArray,b::AbstractArray).\n\n\n\n\n\n","category":"method"},{"location":"reference/reference/#AlgorithmicRecourse.Models.probs-Tuple{AlgorithmicRecourse.Models.BayesianLogisticModel, AbstractArray}","page":"Full references","title":"AlgorithmicRecourse.Models.probs","text":"probs(𝑴::BayesianLogisticModel, X::AbstractArray)\n\nComputes predictive probabilities using a Probit approximation. \n\nExamples\n\nusing Random, LinearAlgebra\nRandom.seed!(1234)\nμ = [0, 1.0,-2.0] # MAP coefficients\nΣ = Symmetric(reshape(randn(9),3,3).*0.1 + UniformScaling(1.0)) # MAP covariance matrix\n𝑴 = AlgorithmicRecourse.Models.BayesianLogisticModel(μ, Σ);\nx = reshape([1,1],1,2)\nprobs(𝑴, x)\n\nSee also BayesianLogisticModel(w::AbstractArray,b::AbstractArray)\n\n\n\n\n\n","category":"method"},{"location":"reference/reference/#AlgorithmicRecourse.Models.probs-Tuple{AlgorithmicRecourse.Models.LogisticModel, AbstractArray}","page":"Full references","title":"AlgorithmicRecourse.Models.probs","text":"probs(𝑴::LogisticModel, X::AbstractArray)\n\nComputes predictive probabilities from logits as σ(Xw+b) where 'σ' is the sigmoid function. \n\nExamples\n\nw = [1.0,-2.0] # estimated coefficients\nb = [0] # estimated constant\n𝑴 = AlgorithmicRecourse.Models.LogisticModel(w, b);\nx = reshape([1,1],1,2)\nprobs(𝑴, x)\n\nSee also LogisticModel(w::AbstractArray,b::AbstractArray).\n\n\n\n\n\n","category":"method"},{"location":"","page":"Home","title":"Home","text":"CurrentModule = AlgorithmicRecourse","category":"page"},{"location":"#AlgorithmicRecourse","page":"Home","title":"AlgorithmicRecourse","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Documentation for AlgorithmicRecourse.jl.","category":"page"},{"location":"","page":"Home","title":"Home","text":"A package for counterfactual explanations (CE) and algorithmic recourse (AR) in Julia. The former (CE) is a common approach towards explaining machine learning models. The latter (AR) uses counterfactual explanations to systematically provide recourse to individuals faced with an undesirable algorithmic outcome. ","category":"page"},{"location":"#Installation","page":"Home","title":"Installation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The package is in its early stages of development and not yet registered. In the meantime it can be installed as follows:","category":"page"},{"location":"","page":"Home","title":"Home","text":"using Pkg\nPkg.add(\"https://github.com/pat-alt/AlgorithmicRecourse.jl\")","category":"page"},{"location":"reference/exported/","page":"Exported","title":"Exported","text":"CurrentModule = AlgorithmicRecourse ","category":"page"},{"location":"reference/exported/#Exported-functions-and-types","page":"Exported","title":"Exported functions and types","text":"","category":"section"},{"location":"reference/exported/","page":"Exported","title":"Exported","text":"Modules = [AlgorithmicRecourse, AlgorithmicRecourse.Generators, AlgorithmicRecourse.Models, AlgorithmicRecourse.Losses]\nPrivate = false","category":"page"},{"location":"reference/exported/#AlgorithmicRecourse.generate_recourse-Tuple{Generator, AbstractArray, AlgorithmicRecourse.Models.FittedModel, Float64, Float64}","page":"Exported","title":"AlgorithmicRecourse.generate_recourse","text":"generate_recourse(generator::Generator, x̅::AbstractArray, 𝑴::Models.FittedModel, target::Float64, γ::Float64; T=1000)\n\nTakes a recourse generator, the factual sample x̅, the fitted model 𝑴, the target label and its desired threshold probability γ. Returns the generated recourse (an object of type Recourse).\n\nExamples\n\nGeneric generators\n\nw = [1.0,-2.0] # true coefficients\nb = [0]\nx̅ = reshape([-1,0.5],1,2)\ntarget = 1.0\nγ = 0.9\n𝑴 = AlgorithmicRecourse.Models.LogisticModel(w, b);\ngenerator = GenericGenerator(0.1,0.1,1e-5,:logitbinarycrossentropy, nothing)\nrecourse = generate_recourse(generator, x̅, 𝑴, target, γ); # generate recourse\n\nGreedy generator for Bayesian model\n\nusing Random, LinearAlgebra\nRandom.seed!(1234)\nμ = [0, 1.0,-2.0] # MAP coefficients\nΣ = Symmetric(reshape(randn(9),3,3).*0.1 + UniformScaling(1.0)) # MAP covariance matrix\nx̅ = reshape([-1,0.5],1,2)\ntarget = 1.0\nγ = 0.9\n𝑴 = AlgorithmicRecourse.Models.BayesianLogisticModel(μ, Σ);\ngenerator = GreedyGenerator(0.01,20,:logitbinarycrossentropy, nothing)\nrecourse = generate_recourse(generator, x̅, 𝑴, target, γ); # generate recourse\n\nSee also GenericGenerator(λ::Float64, ϵ::Float64, τ::Float64, loss::Symbol), GreedyGenerator(Γ::Float64, δ::Float64, n::Int64, loss::Symbol).\n\n\n\n\n\n","category":"method"},{"location":"reference/exported/#AlgorithmicRecourse.Generators.Generator","page":"Exported","title":"AlgorithmicRecourse.Generators.Generator","text":"Generator\n\nAn abstract type that serves as the base type for recourse generators. \n\n\n\n\n\n","category":"type"},{"location":"reference/exported/#AlgorithmicRecourse.Generators.GenericGenerator","page":"Exported","title":"AlgorithmicRecourse.Generators.GenericGenerator","text":"GenericGenerator(λ::Float64, ϵ::Float64, τ::Float64, loss::Symbol, 𝑭::Union{Nothing,Vector{Symbol}})\n\nA constructor for a generic recourse generator. It takes values for the complexity penalty λ, the learning rate ϵ, the tolerance for convergence τ,      the type of loss function to be used in the recourse objective and a mutability constraint mask 𝑭.\n\nExamples\n\ngenerator = GenericGenerator(0.1,0.1,1e-5,:logitbinarycrossentropy,nothing)\n\nSee also generate_recourse(generator::Generator, x̅::AbstractArray, 𝑴::Models.FittedModel, target::Float64; T=1000).\n\n\n\n\n\n","category":"type"},{"location":"reference/exported/#AlgorithmicRecourse.Generators.GreedyGenerator","page":"Exported","title":"AlgorithmicRecourse.Generators.GreedyGenerator","text":"GreedyGenerator(δ::Float64, n::Int64, loss::Symbol, 𝑭::Union{Nothing,Vector{Symbol}})\n\nConstructs a greedy recourse generator for Bayesian models. It takes values for the perturbation size δ, the maximum number of times n that any feature can be changed,      the type of loss function to be used in the recourse objective and a mutability constraint mask 𝑭.\n\nExamples\n\ngenerator = GreedyGenerator(0.01,20,:logitbinarycrossentropy, nothing)\n\nSee also generate_recourse(generator::Generator, x̅::AbstractArray, 𝑴::Models.FittedModel, target::Float64; T=1000).\n\n\n\n\n\n","category":"type"},{"location":"reference/exported/#AlgorithmicRecourse.Losses.hinge_loss-Tuple{Any, Any}","page":"Exported","title":"AlgorithmicRecourse.Losses.hinge_loss","text":"hinge_loss(ŷ, y)\n\nUses Flux.Losses.hinge_loss to compute Hinge loss. If provided labels are in {0,1} they are mapped to {-1,1}. \n\n\n\n\n\n","category":"method"},{"location":"tutorials/generate_recourse/","page":"Generate recourse","title":"Generate recourse","text":"CurrentModule = AlgorithmicRecourse ","category":"page"},{"location":"tutorials/generate_recourse/","page":"Generate recourse","title":"Generate recourse","text":"using Flux\nusing Random\nusing Plots\nusing PlotThemes\ntheme(:juno)\nusing Logging\ndisable_logging(Logging.Info)","category":"page"},{"location":"tutorials/generate_recourse/","page":"Generate recourse","title":"Generate recourse","text":"LogLevel(1)","category":"page"},{"location":"tutorials/generate_recourse/#Generating-recourse","page":"Generate recourse","title":"Generating recourse","text":"","category":"section"},{"location":"tutorials/generate_recourse/","page":"Generate recourse","title":"Generate recourse","text":"To understand the core functionality of AlgorithmicRecourse.jl we will look at two example use cases of the generate_recourse function. This function takes a structure of type Generator as its main argument. Users can utilize one of the default generators: GenericGenerator <: Generator, GreedyGenerator <: Generator. Alternatively, users can also create their own custom generator. ","category":"page"},{"location":"tutorials/generate_recourse/","page":"Generate recourse","title":"Generate recourse","text":"generate_recourse(generator::Generator, x̅::AbstractArray, 𝑴::Models.FittedModel, target::Float64, γ::Float64; T=1000)","category":"page"},{"location":"tutorials/generate_recourse/#Default-generators","page":"Generate recourse","title":"Default generators","text":"","category":"section"},{"location":"tutorials/generate_recourse/#GenericGenerator","page":"Generate recourse","title":"GenericGenerator","text":"","category":"section"},{"location":"tutorials/generate_recourse/","page":"Generate recourse","title":"Generate recourse","text":"Let tin01 denote the target label, M the model (classifier) and underlinexinmathbbR^D the vector of counterfactual features. In order to generate recourse the GenericGenerator optimizes the following objective function through steepest descent","category":"page"},{"location":"tutorials/generate_recourse/","page":"Generate recourse","title":"Generate recourse","text":"underlinex = arg min_underlinex  ell(M(underlinex)t) + lambda h(underlinex)","category":"page"},{"location":"tutorials/generate_recourse/","page":"Generate recourse","title":"Generate recourse","text":"where ell denotes some loss function targeting the deviation between the target label and the predicted label and h(cdot) as a complexity penality generally addressing the realism or cost of the proposed counterfactual. ","category":"page"},{"location":"tutorials/generate_recourse/","page":"Generate recourse","title":"Generate recourse","text":"Let's generate some toy data:","category":"page"},{"location":"tutorials/generate_recourse/","page":"Generate recourse","title":"Generate recourse","text":"# Some random data:\nRandom.seed!(1234);\nN = 25\nw = reshape([1.0,-2.0],2,1) # true coefficients\nb = 0\nX = reshape(randn(2*N),N,2).*1 # random features\ny = Int.(round.(Flux.σ.(X*w .+ b))); # label based on sigmoid\n# Choose sample and plot:\nx̅ = reshape(X[5,:],1,2);","category":"page"},{"location":"tutorials/generate_recourse/","page":"Generate recourse","title":"Generate recourse","text":"For this toy data we will now implement algorithmic recourse as follows:","category":"page"},{"location":"tutorials/generate_recourse/","page":"Generate recourse","title":"Generate recourse","text":"Use the coefficients w and b to define our model using AlgorithmicRecourse.Models.LogisticModel(w, b).\nDefine our GenericGenerator.\nGenerate recourse.","category":"page"},{"location":"tutorials/generate_recourse/","page":"Generate recourse","title":"Generate recourse","text":"using AlgorithmicRecourse\n𝑴 = AlgorithmicRecourse.Models.LogisticModel(w, [b]);\ny̅ = round.(AlgorithmicRecourse.Models.probs(𝑴, x̅))[1]\ntarget = ifelse(y̅==1.0,0.0,1.0)\nγ = ifelse(target==1.0,0.75,0.25)\ngenerator = GenericGenerator(0.1,0.1,1e-5,:logitbinarycrossentropy,nothing)\nrecourse = generate_recourse(generator, x̅, 𝑴, target, γ); # generate recourse","category":"page"},{"location":"tutorials/generate_recourse/","page":"Generate recourse","title":"Generate recourse","text":"Now let's plot the resulting counterfactual path in the 2-D feature space (left) and the predicted probability (right):","category":"page"},{"location":"tutorials/generate_recourse/","page":"Generate recourse","title":"Generate recourse","text":"x1 = (minimum(X[:,1])-1):0.1:(maximum(X[:,1])+1)\nx2 = (minimum(X[:,2])-1):0.1:(maximum(X[:,2])+1)\np1 = Plots.contourf(\n    x1,x2,(x, y) -> AlgorithmicRecourse.Models.probs(recourse.𝑴, reshape([x,y],(1,2)))[1],\n    color = :viridis,\n    linewidth = 0,\n    legend=false\n)\nscatter!(p1,X[:,1],X[:,2],legend=false,color=y,title=\"Logistic Regression\") # features\nPlots.abline!(p1, -w[1]/w[2],0,color=\"black\") # decision boundary\nT = size(recourse.path)[1]\nprobs = AlgorithmicRecourse.Models.probs(recourse.𝑴, recourse.path)\nanim = @animate for t in 1:T\n    scatter!(p1, [recourse.path[t,1]], [recourse.path[t,2]], ms=5, color=Int(y̅))\n    p2 = plot(1:t, probs[1:t], xlim=(0,T), ylim=(0, 1), label=\"p(y̲=1)\", title=\"Validity\")\n    Plots.abline!(p2,0,γ,label=\"threshold γ\") # decision boundary\n    plot(p1,p2,size=(800,400))\nend\ngif(anim, \"www/generic_recourse.gif\", fps=5);","category":"page"},{"location":"tutorials/generate_recourse/","page":"Generate recourse","title":"Generate recourse","text":"(Image: )","category":"page"},{"location":"tutorials/generate_recourse/#GreedyGenerator","page":"Generate recourse","title":"GreedyGenerator","text":"","category":"section"},{"location":"tutorials/generate_recourse/","page":"Generate recourse","title":"Generate recourse","text":"Next we will repeat the exercise above, but instead use the GreedyGenerator in the context of a Bayesian classifier. This generator is greedy in the sense that it simply chooses the most salient feature underlinexd where d=argmax_d in 1D nabla_underlinex ell(M(underlinex)t) and perturbs it by a fixed amount delta. In other words, optimization is penalty-free. This is possible in the Bayesian context, because maximizing the predictive probability gamma corresponds to minimizing the predictive uncertainty: by construction the generated counterfactual will therefore be realistic (low epistemic uncertainty) and unambiguous (low aleotoric uncertainty).","category":"page"},{"location":"tutorials/generate_recourse/","page":"Generate recourse","title":"Generate recourse","text":"using LinearAlgebra\nΣ = Symmetric(reshape(randn(9),3,3).*0.01 + UniformScaling(1)) # MAP covariance matrix\nμ = vcat(b, w)\n𝑴 = AlgorithmicRecourse.Models.BayesianLogisticModel(μ, Σ);\ngenerator = GreedyGenerator(0.1,12,:logitbinarycrossentropy,nothing)\nrecourse = generate_recourse(generator, x̅, 𝑴, target, γ); # generate recourse","category":"page"},{"location":"tutorials/generate_recourse/","page":"Generate recourse","title":"Generate recourse","text":"Once again we plot the resulting counterfactual path (left) and changes in the predicted probability (right). For the Bayesian classifier predicted probabilities splash out: uncertainty increases in regions with few samples. Note how the greedy approach selects the same most salient feature over and over again until its exhausted (i.e. it has been chosen GreedyGenerator.n times).","category":"page"},{"location":"tutorials/generate_recourse/","page":"Generate recourse","title":"Generate recourse","text":"p1 = Plots.contourf(\n    x1,x2,(x, y) -> AlgorithmicRecourse.Models.probs(recourse.𝑴, reshape([x,y],(1,2)))[1],\n    color = :viridis,\n    linewidth = 0,\n    legend=false\n)\nscatter!(p1,X[:,1],X[:,2],legend=false,color=y,title=\"Bayesian Logistic Regression\") # features\nPlots.abline!(p1, -w[1]/w[2],0,color=\"black\") # decision boundary\nT = size(recourse.path)[1]\nprobs = AlgorithmicRecourse.Models.probs(recourse.𝑴, recourse.path)\nanim = @animate for t in 1:T\n    scatter!(p1, [recourse.path[t,1]], [recourse.path[t,2]], ms=5, color=Int(y̅))\n    p2 = plot(1:t, probs[1:t], xlim=(0,T), ylim=(0, 1), label=\"p(y̲=1)\", title=\"Validity\")\n    Plots.abline!(p2,0,γ,label=\"threshold γ\") # decision boundary\n    plot(p1,p2,size=(800,400))\nend\ngif(anim, \"www/greedy_recourse.gif\", fps=5);","category":"page"},{"location":"tutorials/generate_recourse/","page":"Generate recourse","title":"Generate recourse","text":"(Image: )","category":"page"}]
}
