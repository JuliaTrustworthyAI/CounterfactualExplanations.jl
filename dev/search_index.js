var documenterSearchIndex = {"docs":
[{"location":"tutorials/install/#Installation","page":"Installation","title":"Installation","text":"","category":"section"},{"location":"tutorials/install/","page":"Installation","title":"Installation","text":"The package is in its early stages of development and not yet registered. In the meantime it can be installed as follows:","category":"page"},{"location":"tutorials/install/","page":"Installation","title":"Installation","text":"using Pkg\nPkg.add(\"https://github.com/pat-alt/AlgorithmicRecourse.jl\")","category":"page"},{"location":"tutorials/install/","page":"Installation","title":"Installation","text":"To instead install the development version of the package you can run the following command:","category":"page"},{"location":"tutorials/install/","page":"Installation","title":"Installation","text":"using Pkg\nPkg.add(url=\"https://github.com/pat-alt/AlgorithmicRecourse.jl\", rev=\"dev\")","category":"page"},{"location":"tutorials/multi/","page":"Recourse for multi-class targets","title":"Recourse for multi-class targets","text":"CurrentModule = AlgorithmicRecourse ","category":"page"},{"location":"tutorials/multi/#Recourse-for-multi-class-targets","page":"Recourse for multi-class targets","title":"Recourse for multi-class targets","text":"","category":"section"},{"location":"tutorials/multi/","page":"Recourse for multi-class targets","title":"Recourse for multi-class targets","text":"TO BE COMPLETED","category":"page"},{"location":"reference/","page":"Reference","title":"Reference","text":"CurrentModule = AlgorithmicRecourse ","category":"page"},{"location":"reference/#All-functions-and-types","page":"Reference","title":"All functions and types","text":"","category":"section"},{"location":"reference/","page":"Reference","title":"Reference","text":"","category":"page"},{"location":"reference/#Exported-functions","page":"Reference","title":"Exported functions","text":"","category":"section"},{"location":"reference/","page":"Reference","title":"Reference","text":"Modules = [AlgorithmicRecourse, AlgorithmicRecourse.Generators, AlgorithmicRecourse.Models, AlgorithmicRecourse.Losses]\nPrivate = false","category":"page"},{"location":"reference/#AlgorithmicRecourse.generate_recourse-Tuple{Generator, AbstractArray, AlgorithmicRecourse.Models.FittedModel, Float64, Float64}","page":"Reference","title":"AlgorithmicRecourse.generate_recourse","text":"generate_recourse(generator::Generator, xÃÖ::AbstractArray, ùë¥::Models.FittedModel, target::Float64, Œ≥::Float64; T=1000)\n\nTakes a recourse generator, the factual sample xÃÖ, the fitted model ùë¥, the target label and its desired threshold probability Œ≥. Returns the generated recourse (an object of type Recourse).\n\nExamples\n\nGeneric generators\n\nw = [1.0,-2.0] # true coefficients\nb = [0]\nxÃÖ = reshape([-1,0.5],1,2)\ntarget = 1.0\nŒ≥ = 0.9\nùë¥ = AlgorithmicRecourse.Models.LogisticModel(w, b);\ngenerator = GenericGenerator(0.1,0.1,1e-5,:logitbinarycrossentropy,nothing)\nrecourse = generate_recourse(generator, xÃÖ, ùë¥, target, Œ≥); # generate recourse\n\nGreedy generator for Bayesian model\n\nusing Random, LinearAlgebra\nRandom.seed!(1234)\nŒº = [0, 1.0,-2.0] # MAP coefficients\nŒ£ = Symmetric(reshape(randn(9),3,3).*0.1 + UniformScaling(1.0)) # MAP covariance matrix\nxÃÖ = reshape([-1,0.5],1,2)\ntarget = 1.0\nŒ≥ = 0.9\nùë¥ = AlgorithmicRecourse.Models.BayesianLogisticModel(Œº, Œ£);\ngenerator = GreedyGenerator(0.01,20,:logitbinarycrossentropy,nothing)\nrecourse = generate_recourse(generator, xÃÖ, ùë¥, target, Œ≥); # generate recourse\n\nSee also:\n\nGenericGenerator(Œª::Float64, œµ::Float64, œÑ::Float64, loss::Symbol, ùë≠::Union{Nothing,Vector{Symbol}})\nGreedyGenerator(Œ¥::Float64, n::Int64, loss::Symbol, ùë≠::Union{Nothing,Vector{Symbol}}).\n\n\n\n\n\n","category":"method"},{"location":"reference/#AlgorithmicRecourse.Generators.Generator","page":"Reference","title":"AlgorithmicRecourse.Generators.Generator","text":"Generator\n\nAn abstract type that serves as the base type for recourse generators. \n\n\n\n\n\n","category":"type"},{"location":"reference/#AlgorithmicRecourse.Generators.GenericGenerator","page":"Reference","title":"AlgorithmicRecourse.Generators.GenericGenerator","text":"GenericGenerator(Œª::Float64, œµ::Float64, œÑ::Float64, loss::Symbol, ùë≠::Union{Nothing,Vector{Symbol}})\n\nA constructor for a generic recourse generator. It takes values for the complexity penalty Œª, the learning rate œµ, the tolerance for convergence œÑ,      the type of loss function to be used in the recourse objective and a mutability constraint mask ùë≠.\n\nExamples\n\ngenerator = GenericGenerator(0.1,0.1,1e-5,:logitbinarycrossentropy,nothing)\n\nSee also:\n\ngenerate_recourse(generator::Generator, xÃÖ::AbstractArray, ùë¥::Models.FittedModel, target::Float64; T=1000)\n\n\n\n\n\n","category":"type"},{"location":"reference/#AlgorithmicRecourse.Generators.GreedyGenerator","page":"Reference","title":"AlgorithmicRecourse.Generators.GreedyGenerator","text":"GreedyGenerator(Œ¥::Float64, n::Int64, loss::Symbol, ùë≠::Union{Nothing,Vector{Symbol}})\n\nConstructs a greedy recourse generator for Bayesian models. It takes values for the perturbation size Œ¥, the maximum number of times n that any feature can be changed,      the type of loss function to be used in the recourse objective and a mutability constraint mask ùë≠.\n\nExamples\n\ngenerator = GreedyGenerator(0.01,20,:logitbinarycrossentropy, nothing)\n\nSee also:\n\ngenerate_recourse(generator::Generator, xÃÖ::AbstractArray, ùë¥::Models.FittedModel, target::Float64; T=1000)\n\n\n\n\n\n","category":"type"},{"location":"reference/#AlgorithmicRecourse.Losses.hinge_loss-Tuple{Any, Any}","page":"Reference","title":"AlgorithmicRecourse.Losses.hinge_loss","text":"hinge_loss(yÃÇ, y)\n\nUses Flux.Losses.hinge_loss to compute Hinge loss. If provided labels are in {0,1} they are mapped to {-1,1}. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Internal-functions","page":"Reference","title":"Internal functions","text":"","category":"section"},{"location":"reference/","page":"Reference","title":"Reference","text":"Modules = [AlgorithmicRecourse, AlgorithmicRecourse.Generators, AlgorithmicRecourse.Models, AlgorithmicRecourse.Losses]\nPublic = false","category":"page"},{"location":"reference/#AlgorithmicRecourse.Recourse","page":"Reference","title":"AlgorithmicRecourse.Recourse","text":"Recourse(xÃ≤::AbstractArray, yÃ≤::Float64, path::Matrix{Float64}, generator::Generators.Generator, xÃÖ::AbstractArray, yÃÖ::Float64, ùë¥::Models.FittedModel, target::Float64)\n\nCollects all variables relevant to the recourse outcome. \n\n\n\n\n\n","category":"type"},{"location":"reference/#AlgorithmicRecourse.apply_mutability-Tuple{AbstractArray, Vector{Symbol}}","page":"Reference","title":"AlgorithmicRecourse.apply_mutability","text":"apply_mutability(ŒîxÃ≤::AbstractArray, ùë≠::Vector{Symbol})\n\nApply mutability constraints to ŒîxÃ≤ based on vector of constraints ùë≠.\n\nExamples\n\nùë≠ = [:both, :increase, :decrease, :none] _mutability([-1,1,-1,1], ùë≠) # all but :none pass _mutability([-1,-1,-1,1], ùë≠) # all but :increase and :none pass _mutability([-1,1,1,1], ùë≠) # all but :decrease and :none pass _mutability([-1,-1,1,1], ùë≠) # only :both passes\n\n\n\n\n\n","category":"method"},{"location":"reference/#AlgorithmicRecourse.threshold_reached-Tuple{AlgorithmicRecourse.Models.FittedModel, AbstractArray, Float64, Float64}","page":"Reference","title":"AlgorithmicRecourse.threshold_reached","text":"threshold_reached(ùë¥::Models.FittedModel, xÃ≤::AbstractArray, target::Float64, Œ≥::Float64)\n\nChecks if confidence threshold has been reached. \n\n\n\n\n\n","category":"method"},{"location":"reference/#AlgorithmicRecourse.Models.BayesianLogisticModel","page":"Reference","title":"AlgorithmicRecourse.Models.BayesianLogisticModel","text":"BayesianLogisticModel(Œº::AbstractArray,Œ£::AbstractArray)\n\nConstructs a Bayesian logistic classifier based on maximum a posteriori (MAP) estimates Œº (coefficients including constant term(s)) and Œ£ (covariance matrix). \n\nExamples\n\nusing Random, LinearAlgebra\nRandom.seed!(1234)\nŒº = [0, 1.0,-2.0] # MAP coefficients\nŒ£ = Symmetric(reshape(randn(9),3,3).*0.1 + UniformScaling(1.0)) # MAP covariance matrix\nùë¥ = AlgorithmicRecourse.Models.BayesianLogisticModel(Œº, Œ£);\n\nSee also:\n\nlogits(ùë¥::BayesianLogisticModel, X::AbstractArray)\nprobs(ùë¥::BayesianLogisticModel, X::AbstractArray)\n\n\n\n\n\n","category":"type"},{"location":"reference/#AlgorithmicRecourse.Models.LogisticModel","page":"Reference","title":"AlgorithmicRecourse.Models.LogisticModel","text":"LogisticModel(w::AbstractArray,b::AbstractArray)\n\nConstructs a logistic classifier based on arrays containing coefficients w and constant terms b.\n\nExamples\n\nw = [1.0,-2.0] # estimated coefficients\nb = [0] # estimated constant\nùë¥ = AlgorithmicRecourse.Models.LogisticModel(w, b);\n\nSee also: \n\nlogits(ùë¥::LogisticModel, X::AbstractArray)\nprobs(ùë¥::LogisticModel, X::AbstractArray)\n\n\n\n\n\n","category":"type"},{"location":"reference/#AlgorithmicRecourse.Models.logits-Tuple{AlgorithmicRecourse.Models.BayesianLogisticModel, AbstractArray}","page":"Reference","title":"AlgorithmicRecourse.Models.logits","text":"logits(ùë¥::BayesianLogisticModel, X::AbstractArray)\n\nComputes logits as [1 X]Œº.\n\nExamples\n\nusing Random, LinearAlgebra\nRandom.seed!(1234)\nŒº = [0, 1.0,-2.0] # MAP coefficients\nŒ£ = Symmetric(reshape(randn(9),3,3).*0.1 + UniformScaling(1.0)) # MAP covariance matrix\nùë¥ = AlgorithmicRecourse.Models.BayesianLogisticModel(Œº, Œ£);\nx = reshape([1,1],1,2)\nlogits(ùë¥, x)\n\nSee also BayesianLogisticModel(w::AbstractArray,b::AbstractArray)\n\n\n\n\n\n","category":"method"},{"location":"reference/#AlgorithmicRecourse.Models.logits-Tuple{AlgorithmicRecourse.Models.LogisticModel, AbstractArray}","page":"Reference","title":"AlgorithmicRecourse.Models.logits","text":"logits(ùë¥::LogisticModel, X::AbstractArray)\n\nComputes logits as Xw+b.\n\nExamples\n\nw = [1.0,-2.0] # estimated coefficients\nb = [0] # estimated constant\nùë¥ = AlgorithmicRecourse.Models.LogisticModel(w, b);\nx = reshape([1,1],1,2)\nlogits(ùë¥, x)\n\nSee also LogisticModel(w::AbstractArray,b::AbstractArray).\n\n\n\n\n\n","category":"method"},{"location":"reference/#AlgorithmicRecourse.Models.probs-Tuple{AlgorithmicRecourse.Models.BayesianLogisticModel, AbstractArray}","page":"Reference","title":"AlgorithmicRecourse.Models.probs","text":"probs(ùë¥::BayesianLogisticModel, X::AbstractArray)\n\nComputes predictive probabilities using a Probit approximation. \n\nExamples\n\nusing Random, LinearAlgebra\nRandom.seed!(1234)\nŒº = [0, 1.0,-2.0] # MAP coefficients\nŒ£ = Symmetric(reshape(randn(9),3,3).*0.1 + UniformScaling(1.0)) # MAP covariance matrix\nùë¥ = AlgorithmicRecourse.Models.BayesianLogisticModel(Œº, Œ£);\nx = reshape([1,1],1,2)\nprobs(ùë¥, x)\n\nSee also BayesianLogisticModel(w::AbstractArray,b::AbstractArray)\n\n\n\n\n\n","category":"method"},{"location":"reference/#AlgorithmicRecourse.Models.probs-Tuple{AlgorithmicRecourse.Models.LogisticModel, AbstractArray}","page":"Reference","title":"AlgorithmicRecourse.Models.probs","text":"probs(ùë¥::LogisticModel, X::AbstractArray)\n\nComputes predictive probabilities from logits as œÉ(Xw+b) where 'œÉ' is the sigmoid function. \n\nExamples\n\nw = [1.0,-2.0] # estimated coefficients\nb = [0] # estimated constant\nùë¥ = AlgorithmicRecourse.Models.LogisticModel(w, b);\nx = reshape([1,1],1,2)\nprobs(ùë¥, x)\n\nSee also LogisticModel(w::AbstractArray,b::AbstractArray).\n\n\n\n\n\n","category":"method"},{"location":"tutorials/loss/","page":"Loss functions","title":"Loss functions","text":"CurrentModule = AlgorithmicRecourse ","category":"page"},{"location":"tutorials/loss/#Loss-functions-and-gradients","page":"Loss functions","title":"Loss functions and gradients","text":"","category":"section"},{"location":"tutorials/loss/","page":"Loss functions","title":"Loss functions","text":"This is a short tutorial on loss functions and gradients typically involved in counterfactual search. It involves more maths than perhaps some of the other tutorials.","category":"page"},{"location":"tutorials/loss/","page":"Loss functions","title":"Loss functions","text":"using Zygote\nusing Plots\nusing PlotThemes\ntheme(:juno)\nusing LinearAlgebra","category":"page"},{"location":"tutorials/loss/#General-setup","page":"Loss functions","title":"General setup","text":"","category":"section"},{"location":"tutorials/loss/","page":"Loss functions","title":"Loss functions","text":"We begin by restating the general setup for generic counterfactual search. Let tin01 denote the target label, M the model (classifier) and underlinexinmathbbR^D the vector of counterfactual features (we will assume all features are continuous). Then the differentiable optimization problem in algorithmic recourse is generally of the following form","category":"page"},{"location":"tutorials/loss/","page":"Loss functions","title":"Loss functions","text":"underlinex = arg min_underlinex  ell(M(underlinex)t) + lambda h(underlinex)","category":"page"},{"location":"tutorials/loss/","page":"Loss functions","title":"Loss functions","text":"where ell denotes some loss function targeting the deviation between the target label and the predicted label and h(cdot) acts as a complexity penality generally addressing the realism or cost of the proposed counterfactual. ","category":"page"},{"location":"tutorials/loss/#Loss-function-\\ell","page":"Loss functions","title":"Loss function ell","text":"","category":"section"},{"location":"tutorials/loss/","page":"Loss functions","title":"Loss functions","text":"Different choices for ell come to mind, each potentially leading to very different counterfactual outcomes. In practice, ell is often implemented with respect to the logits a=mathbfw^Tx rather than the probabilities p(underliney=1underlinex)=sigma(a) predicted by the classifier. We follow this convention here, but as we shall see depeding on the label domain this convention does not work well for every type of loss function. Common choices for ell in the literature include margin-based loss function like Hinge loss and logit binary crossentropy (or log) loss. Some use distance-based loss such as mean squared error loss (MSE).","category":"page"},{"location":"tutorials/loss/#Hinge-loss","page":"Loss functions","title":"Hinge loss","text":"","category":"section"},{"location":"tutorials/loss/","page":"Loss functions","title":"Loss functions","text":"With respect to the logits a=mathbfwx Hinge loss can be defined as follows","category":"page"},{"location":"tutorials/loss/","page":"Loss functions","title":"Loss functions","text":"ell(at^*)=(1-acdot t^*)_+=max01-acdot t^*","category":"page"},{"location":"tutorials/loss/","page":"Loss functions","title":"Loss functions","text":"where t^* is the target label in -11. Since above we defined tin01 we need a mapping h 01 mapsto -11. Specifically, we want to plug in h(t)=t^* where h(cdot) is just the following conditional:","category":"page"},{"location":"tutorials/loss/","page":"Loss functions","title":"Loss functions","text":"beginaligned\nh(t)=begincases\n-1  textif  t=0  1  textif  t=1\nendcases\nendaligned","category":"page"},{"location":"tutorials/loss/","page":"Loss functions","title":"Loss functions","text":"Then our loss function as function of t can restated as follows:","category":"page"},{"location":"tutorials/loss/","page":"Loss functions","title":"Loss functions","text":"ell(at^*)=ell(at)=(1-acdot h(t))_+=max01-acdot h(t)","category":"page"},{"location":"tutorials/loss/","page":"Loss functions","title":"Loss functions","text":"The first-order derivative of Hinge loss with respect to the logits a is simply","category":"page"},{"location":"tutorials/loss/","page":"Loss functions","title":"Loss functions","text":"beginaligned\nell(at)=begincases\n-h(t)  textif  a cdot h(t)=1  0  textotherwise \nendcases\nendaligned","category":"page"},{"location":"tutorials/loss/","page":"Loss functions","title":"Loss functions","text":"In the context of counterfactual search the gradient with respect to the feature vector is then:","category":"page"},{"location":"tutorials/loss/","page":"Loss functions","title":"Loss functions","text":"beginaligned\n nabla_underlinex ell(at)= begincases\n-h(t)mathbfw  textif  h(t)mathbfw^Tunderlinex=1  0  textotherwise \nendcases\nendaligned","category":"page"},{"location":"tutorials/loss/","page":"Loss functions","title":"Loss functions","text":"In practice gradients are commonly computed through autodifferentiation. In this tutorial we use the Zygote.jl package which is at the core of Flux.jl, the main deep learning library for Julia.","category":"page"},{"location":"tutorials/loss/","page":"Loss functions","title":"Loss functions","text":"The side-by-side plot below visualises the loss function and its derivative. The plot further below serves as a simple sanity check to verify that autodifferentiation indeed yields the same result as the closed-form solution for the gradient.","category":"page"},{"location":"tutorials/loss/","page":"Loss functions","title":"Loss functions","text":"h(t) = ifelse(t==1,1,-1)\nhinge(a,t) = max(0,1-a*h(t))","category":"page"},{"location":"tutorials/loss/","page":"Loss functions","title":"Loss functions","text":"hinge (generic function with 1 method)","category":"page"},{"location":"tutorials/loss/","page":"Loss functions","title":"Loss functions","text":"default(size=(500,500))\na = -2:0.05:2\np1 = plot(a, [hinge(a,1) for a=a], title=\"Loss, t=1\", xlab=\"logits\")\np2 = plot(a, [gradient(hinge,a,1)[1] for a=a], title=\"Gradient, t=1\", xlab=\"logits\")\np3 = plot(a, [hinge(a,0) for a=a], title=\"Loss, t=0\", xlab=\"logits\")\np4 = plot(a, [gradient(hinge,a,0)[1] for a=a], title=\"Gradient, t=0\", xlab=\"logits\")\nplot(p1, p2, p3, p4, layout = (2, 2), legend = false)\nsavefig(\"www/loss_grad_hinge.png\")","category":"page"},{"location":"tutorials/loss/","page":"Loss functions","title":"Loss functions","text":"(Image: )","category":"page"},{"location":"tutorials/loss/","page":"Loss functions","title":"Loss functions","text":"# Just verifying that the formula for the gradient above indeed yields the same result.\nfunction gradient_man(x,w,t)\n    ùê† = ifelse(h(t)*w'x<=1, -h(t)*w, 0)\n    return ùê†\nend;\nplot(a, [gradient_man(a,1,1) for a=a], legend=:bottomright, label=\"Manual\", title=\"Gradient\", xlab=\"logits\")\nscatter!(a, [gradient(hinge,a,1)[1] for a=a], label=\"Autodiff\")\nsavefig(\"www/loss_grad_hinge_test.png\")","category":"page"},{"location":"tutorials/loss/","page":"Loss functions","title":"Loss functions","text":"(Image: )","category":"page"},{"location":"tutorials/loss/#Logit-binary-crossentropy-loss","page":"Loss functions","title":"Logit binary crossentropy loss","text":"","category":"section"},{"location":"tutorials/loss/","page":"Loss functions","title":"Loss functions","text":"Logit binary crossentropy loss loss (sometimes referred to as log loss) is defined as follows:","category":"page"},{"location":"tutorials/loss/","page":"Loss functions","title":"Loss functions","text":"beginaligned\n ell(at)=- left( t cdot log(sigma(a)) + (1-t) cdot log (1-sigma(a)) right) \nendaligned","category":"page"},{"location":"tutorials/loss/","page":"Loss functions","title":"Loss functions","text":"where sigma(a) is the logit/sigmoid link function.","category":"page"},{"location":"tutorials/loss/","page":"Loss functions","title":"Loss functions","text":"Once again for the purpose of counter factual search we are interested in the first-order derivative with respect to our feature vector underlinex. You can verify that the partial derivative with respect to feature underlinex_d is as follows:","category":"page"},{"location":"tutorials/loss/","page":"Loss functions","title":"Loss functions","text":"beginaligned\n fracpartial ell(at)partial underlinex_d= (sigma(a) - t) w_d \nendaligned","category":"page"},{"location":"tutorials/loss/","page":"Loss functions","title":"Loss functions","text":"The gradient just corresponds to the stacked vector of partial derivatives:","category":"page"},{"location":"tutorials/loss/","page":"Loss functions","title":"Loss functions","text":"beginaligned\n nabla_underlinex ell(at)= (sigma(a) - t) mathbfw \nendaligned","category":"page"},{"location":"tutorials/loss/","page":"Loss functions","title":"Loss functions","text":"As before implementation below is done through autodifferentiation. As before the side-by-side plot shows the resulting loss function and its gradient and the plot further below is a simple sanity check.","category":"page"},{"location":"tutorials/loss/","page":"Loss functions","title":"Loss functions","text":"# sigmoid function:\nfunction ùõî(a)\n    trunc = 8.0 # truncation to avoid numerical over/underflow\n    a = clamp.(a,-trunc,trunc)\n    p = exp.(a)\n    p = p ./ (1 .+ p)\n    return p\nend\n\n# Logit binary crossentropy:\nlogitbinarycrossentropy(a, t) = - (t * log(ùõî(a)) + (1-t) * log(1-ùõî(a)))","category":"page"},{"location":"tutorials/loss/","page":"Loss functions","title":"Loss functions","text":"logitbinarycrossentropy (generic function with 1 method)","category":"page"},{"location":"tutorials/loss/","page":"Loss functions","title":"Loss functions","text":"(Image: )","category":"page"},{"location":"tutorials/loss/","page":"Loss functions","title":"Loss functions","text":"p1 = plot(a, [logitbinarycrossentropy(a,1) for a=a], title=\"Loss, t=1\", xlab=\"logits\")\np2 = plot(a, [gradient(logitbinarycrossentropy,a,1)[1] for a=a], title=\"Gradient, t=1\", xlab=\"logits\")\np3 = plot(a, [logitbinarycrossentropy(a,0) for a=a], title=\"Loss, t=0\", xlab=\"logits\")\np4 = plot(a, [gradient(logitbinarycrossentropy,a,0)[1] for a=a], title=\"Gradient, t=0\", xlab=\"logits\")\nplot(p1, p2, p3, p4, layout = (2, 2), legend = false)\nsavefig(\"www/loss_grad_log.png\")","category":"page"},{"location":"tutorials/loss/","page":"Loss functions","title":"Loss functions","text":"(Image: )","category":"page"},{"location":"tutorials/loss/","page":"Loss functions","title":"Loss functions","text":"# Just verifying that the formula for the gradient above indeed yields the same result.\nfunction gradient_man(x,w,y)\n    ùê† = (ùõî(w'x) - y) .* w\n    return ùê†\nend;\nplot(a, [gradient_man(a,1,1) for a=a], legend=:bottomright, label=\"Manual\", title=\"Gradient\", xlab=\"logits\")\nscatter!(a, [gradient(logitbinarycrossentropy,a,1)[1] for a=a], label=\"Autodiff\")\nsavefig(\"www/loss_grad_log_test.png\")","category":"page"},{"location":"tutorials/loss/#Mean-squared-error","page":"Loss functions","title":"Mean squared error","text":"","category":"section"},{"location":"tutorials/loss/","page":"Loss functions","title":"Loss functions","text":"Some authors work with distance-based loss functions instead. Since in general we are interested in providing valid recourse, that is counterfactual explanations that indeed lead to the desired label switch, using one of the margin-based loss functions introduced above seems like a more natural choice. Nonetheless, we shall briefly introduce one of the common distance-based loss functions as well. ","category":"page"},{"location":"tutorials/loss/","page":"Loss functions","title":"Loss functions","text":"The mean squared error for counterfactual search implemented with respect to the logits is simply the squared ell^2 norm between the target label and a=mathbfw^Tx:","category":"page"},{"location":"tutorials/loss/","page":"Loss functions","title":"Loss functions","text":"beginaligned\n ell(at)= t-a^2\nendaligned","category":"page"},{"location":"tutorials/loss/","page":"Loss functions","title":"Loss functions","text":"The gradient with respect to the vector of features is then:","category":"page"},{"location":"tutorials/loss/","page":"Loss functions","title":"Loss functions","text":"beginaligned\n nabla_underlinex ell(at)= 2(a - t) mathbfw \nendaligned","category":"page"},{"location":"tutorials/loss/","page":"Loss functions","title":"Loss functions","text":"As before implementation and visualizations follow below.","category":"page"},{"location":"tutorials/loss/","page":"Loss functions","title":"Loss functions","text":"mse(a,t) = norm(t - a)^2","category":"page"},{"location":"tutorials/loss/","page":"Loss functions","title":"Loss functions","text":"mse (generic function with 1 method)","category":"page"},{"location":"tutorials/loss/","page":"Loss functions","title":"Loss functions","text":"NOTE: I hinted above that the convention of taking derivatives with respect to logits can go wrong depending on the loss function we choose. The plot below demonstrates this point: for t=0 the global minimum of the MSE is of course also at 0. The implication for counterfactual search is that for t=0 the search stops when mathbfw^Tunderlinex=0. But at this point sigma(mathbfw^Tunderlinex)=05, in other words we stop right at the decision boundary, but never cross it. We will see an example of this below. Key takeaway: carefully think about the choice of your loss function and DON'T us distance-based loss functions when optimizing with respect to logits.","category":"page"},{"location":"tutorials/loss/","page":"Loss functions","title":"Loss functions","text":"p1 = plot(a, [mse(a,1) for a=a], title=\"Loss, t=1\", xlab=\"logits\")\np2 = plot(a, [gradient(mse,a,1)[1] for a=a], title=\"Gradient, t=1\", xlab=\"logits\")\np3 = plot(a, [mse(a,0) for a=a], title=\"Loss, t=0\", xlab=\"logits\")\np4 = plot(a, [gradient(mse,a,0)[1] for a=a], title=\"Gradient, t=0\", xlab=\"logits\")\nplot(p1, p2, p3, p4, layout = (2, 2), legend = false)\nsavefig(\"www/loss_grad_mse.png\")","category":"page"},{"location":"tutorials/loss/","page":"Loss functions","title":"Loss functions","text":"(Image: )","category":"page"},{"location":"tutorials/loss/","page":"Loss functions","title":"Loss functions","text":"# Just verifying that the formula for the gradient above indeed yields the same result.\nfunction gradient_man(x,w,y)\n    ùê† = 2*(w'x - y) .* w\n    return ùê†\nend;\nplot(a, [gradient_man(a,1,1) for a=a], legend=:bottomright, label=\"Manual\", title=\"Gradient\", xlab=\"logits\")\nscatter!(a, [gradient(mse,a,1)[1] for a=a], label=\"Autodiff\")\nsavefig(\"www/loss_grad_mse_test.png\")","category":"page"},{"location":"tutorials/loss/","page":"Loss functions","title":"Loss functions","text":"(Image: )","category":"page"},{"location":"tutorials/loss/#Example-in-2D","page":"Loss functions","title":"Example in 2D","text":"","category":"section"},{"location":"tutorials/loss/","page":"Loss functions","title":"Loss functions","text":"To understand the properties of the different loss functions we will now look at a toy example in 2D. The code below generates some random features and assigns labels based on a fixed vector of coefficients using the sigmoid function.","category":"page"},{"location":"tutorials/loss/","page":"Loss functions","title":"Loss functions","text":"# Some random data:\nusing Flux\nusing Random\nRandom.seed!(1234);\nN = 25\nw = reshape([1.0,-2.0],2,1) # true coefficients\nb = 0\nX = reshape(randn(2*N),N,2).*1 # random features\ny = Int.(round.(Flux.œÉ.(X*w .+ b))); # label based on sigmoid","category":"page"},{"location":"tutorials/loss/","page":"Loss functions","title":"Loss functions","text":"The plot below shows the samples coloured by label along with the decision boundary. You can think of this as representing the outcome of some automated decision making system. The highlighted sample was chosen to receive algorithmic recourse in the following: we will search for a counterfactual that leads to a label switch.","category":"page"},{"location":"tutorials/loss/","page":"Loss functions","title":"Loss functions","text":"# Plot with random sample chose for recourse\nfunction plot_data(;clegend=true,title=\"\",size=1.2.*(400,300))\n    x_range = collect(range(minimum(X[:,1]),stop=maximum(X[:,1]),length=50))\n    y_range = collect(range(minimum(X[:,2]),stop=maximum(X[:,2]),length=50))\n    Z = [Flux.œÉ.([x y]*w .+ b)[1] for x=x_range, y=y_range]\n    plt = contourf(\n        x_range, y_range, Z', color=:viridis, legend=clegend, title=title, size=size\n    )\n    scatter!(plt, X[reshape(y.==1,25),1],X[reshape(y.==1,25),2],label=\"y=1\",color=1) # features\n    scatter!(plt, X[reshape(y.==0,25),1],X[reshape(y.==0,25),2],label=\"y=0\",color=0) # features\n    Plots.abline!(plt,0.5,b,color=\"black\",label=\"\",lw=2) # decision boundary\n    return plt\nend\n\nplt = plot_data()\nxÃÖ = reshape(X[5,:],1,2)\nyÃÖ = round.(Flux.œÉ.(xÃÖ*w .+ b))[1]\nscatter!(plt,[xÃÖ[1]],[xÃÖ[2]],color=Int.(yÃÖ),markersize=10,label=\"\")\nsavefig(plt, \"www/loss_examlpe.png\")","category":"page"},{"location":"tutorials/loss/","page":"Loss functions","title":"Loss functions","text":"(Image: )","category":"page"},{"location":"tutorials/loss/","page":"Loss functions","title":"Loss functions","text":"Next we will generating recourse using the AlgorithmicRecourse.jl package. First we intantiate our model and based on the assigned label we identify the target (the opposite label).","category":"page"},{"location":"tutorials/loss/","page":"Loss functions","title":"Loss functions","text":"using AlgorithmicRecourse\n# import AlgorithmicRecourse: convergence, update_recourse # import explicitly to extend below\nùë¥ = AlgorithmicRecourse.Models.LogisticModel(w, [b]);\ntarget = ifelse(yÃÖ==1.0,0.0,1.0)\nŒ≥ = ifelse(target==1.0,0.75,0.25);","category":"page"},{"location":"tutorials/loss/","page":"Loss functions","title":"Loss functions","text":"Now we instantiate different generators for our different loss functions and different choices of lambda. Finally we generate recourse for each of them:","category":"page"},{"location":"tutorials/loss/","page":"Loss functions","title":"Loss functions","text":"# Generating recourse\nŒõ = [0, 1, 5] # varying complexity penalties\nlosses = [:hinge_loss, :logitbinarycrossentropy, :mse]\nrecourses = []\nfor loss in losses\n    for Œª in Œõ\n        gen = GenericGenerator(Œª,0.1,1e-5,loss) \n        rec = generate_recourse(gen, xÃÖ, ùë¥, target, Œ≥, T=25)\n        recourses = vcat(recourses, (rec=rec, Œª=Œª, loss=loss))\n    end\nend","category":"page"},{"location":"tutorials/loss/","page":"Loss functions","title":"Loss functions","text":"The code below plots the resulting counterfactual paths. ","category":"page"},{"location":"tutorials/loss/","page":"Loss functions","title":"Loss functions","text":"Complexity penalty lambda: has the expected effect of penalizing long counterfactual paths: as the distance between overlinex and underlinex the penalty exerts more and more pressure on the gradient in the opposite direction nablaell. For large choices of lambda valid recourse is not attainable.\nConfidence threshold gamma: note how for both log loss and hinge loss we overshoot a bit, that is we end up well beyond the decision boundary. This is because above we chose a confidence threshold of gamma=075. In the context of recourse this choice matters a lot: we have a longer distance to travel (=higher costs for the individual), but we can be more confident that recourse will remain valid. There is of course an interplay between lambda and gamma.\nThe choice of the loss function matters: the distance-based MSE does NOT work without further ajustments when optimizing with respect to logits, as discussed above. ","category":"page"},{"location":"tutorials/loss/","page":"Loss functions","title":"Loss functions","text":"Overall, in the context of this toy example log loss arguably generates the most reasonable outcome: firstly, we can observe that the step size decreases at an increasing rate as the search approaches convergence (which may be desirable); secondly, it appears that increasing lambda leads to a roughly proportional decrease in the distance of the final counterfactual. This stands in contrast to the outcome for Hinge loss, where increasing lambda from 0 to 1 barely has any effect at all.","category":"page"},{"location":"tutorials/loss/","page":"Loss functions","title":"Loss functions","text":"# Plotting\nk = length(recourses)\nfunction plot_recourse(rec, idx)\n    plt = plot_data(clegend=false, size=(floor(sqrt(k)) * 350, ceil(sqrt(k)) * 350))\n    idx_path = minimum([idx, size(rec.rec.path)[1]])\n    scatter!(plt, rec.rec.path[1:idx_path,1], rec.rec.path[1:idx_path,2], color=Int(yÃÖ))\n    scatter!(plt, [rec.rec.path[idx_path,1]],[rec.rec.path[idx_path,2]],color=Int(yÃÖ),markersize=10)\nend\nmax_path_length = maximum(map(rec -> size(rec.rec.path)[1], recourses))\nanim = @animate for i in 1:max_path_length\n    plots = map(rec -> plot_recourse(rec, i), recourses);\n    plot(plots..., layout = (Int(floor(sqrt(k))), Int(ceil(sqrt(k)))), legend = false, plot_title=\"Iteration: \" * string(i))\nend\ngif(anim, \"www/loss_paths.gif\", fps=5);","category":"page"},{"location":"tutorials/loss/","page":"Loss functions","title":"Loss functions","text":"‚îå Info: Saved animation to \n‚îÇ   fn = /Users/FA31DU/OneDrive - Delft University of Technology/git/AlgorithmicRecourse.jl/docs/src/tutorials/www/loss_paths.gif\n‚îî @ Plots /Users/FA31DU/.julia/packages/Plots/Zuo5g/src/animation.jl:114","category":"page"},{"location":"tutorials/loss/","page":"Loss functions","title":"Loss functions","text":"(Image: )","category":"page"},{"location":"","page":"Home","title":"Home","text":"CurrentModule = AlgorithmicRecourse","category":"page"},{"location":"#AlgorithmicRecourse","page":"Home","title":"AlgorithmicRecourse","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Documentation for AlgorithmicRecourse.jl.","category":"page"},{"location":"","page":"Home","title":"Home","text":"A package for counterfactual explanations (CE) and algorithmic recourse (AR) in Julia. The former (CE) is a common approach towards explaining machine learning models. The latter (AR) uses counterfactual explanations to systematically provide recourse to individuals faced with an undesirable algorithmic outcome. ","category":"page"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"CurrentModule = AlgorithmicRecourse ","category":"page"},{"location":"tutorials/models/#Models","page":"Models","title":"Models","text":"","category":"section"},{"location":"tutorials/models/#Default-models","page":"Models","title":"Default models","text":"","category":"section"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"There are currently structures for two default models that can be used with AlgorithmicRecourse.jl:","category":"page"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"LogisticModel(w::AbstractArray,b::AbstractArray)\nBayesianLogisticModel(Œº::AbstractArray,Œ£::AbstractArray)","category":"page"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"Both take sets of estimated parameters at the point of instantiation: the constructors will not fit a model for you, but assume that you have already estimated the respective model yourself and have access to its parameter estimates. Based on the supplied parameters methods to predict logits and probabilities are already implemented and used in the counterfactual search. ","category":"page"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"For the simple logistic regression model logits are computed as a=Xw + b and probabilities are simply sigma(a). For the Bayesian logistic regression model logits are computed as Xmu and the predictive posterior is computed through Laplace approximation.","category":"page"},{"location":"tutorials/models/#Custom-models","page":"Models","title":"Custom models","text":"","category":"section"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"Apart from the default models you can use any arbitrary (differentiable) model and generate recourse in the same way as before. Only two steps are necessary to make your own model compatible with AlgorithmicRecourse.jl:","category":"page"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"The model needs to be declared as a subtype of AlgorithmicRecourse.Models.FittedModel.\nYou need to extend the functions AlgorithmicRecourse.Models.logits and AlgorithmicRecourse.Models.probs to accept your custom model.","category":"page"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"Below we will go through a simple example to see how this can be done in practice. ","category":"page"},{"location":"tutorials/models/#Neural-network","page":"Models","title":"Neural network","text":"","category":"section"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"In this example we will build a simple artificial neural network using Flux.jl for a binary classification task.","category":"page"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"# Import libraries.\nusing Flux, Plots, Random, PlotThemes, Statistics\ntheme(:juno)\nusing Logging\ndisable_logging(Logging.Info)","category":"page"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"LogLevel(1)","category":"page"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"First we generate some toy data below. The code that generates this data was borrowed from a great tutorial about Bayesian neural networks provided by Turing.jl, which you may find here. ","category":"page"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"The plot below shows the generated samples in the 2D feature space where colours indicate the associated labels. Clearly this data is not linearly separable and the default LogisticModel would be ill suited for this classification task.","category":"page"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"# Number of points to generate.\nN = 80\nM = round(Int, N / 4)\nRandom.seed!(1234)\n\n# Generate artificial data.\nx1s = rand(M) * 4.5; x2s = rand(M) * 4.5; \nxt1s = Array([[x1s[i] + 0.5; x2s[i] + 0.5] for i = 1:M])\nx1s = rand(M) * 4.5; x2s = rand(M) * 4.5; \nappend!(xt1s, Array([[x1s[i] - 5; x2s[i] - 5] for i = 1:M]))\n\nx1s = rand(M) * 4.5; x2s = rand(M) * 4.5; \nxt0s = Array([[x1s[i] + 0.5; x2s[i] - 5] for i = 1:M])\nx1s = rand(M) * 4.5; x2s = rand(M) * 4.5; \nappend!(xt0s, Array([[x1s[i] - 5; x2s[i] + 0.5] for i = 1:M]))\n\n# Store all the data for later.\nxs = [xt1s; xt0s]\nX = hcat(xs...) # bring into tabular format\nts = [ones(2*M); zeros(2*M)]\n\nplt = plot()\n\n# Plot data points.\nfunction plot_data!(plt)\n    x1 = map(e -> e[1], xt1s)\n    y1 = map(e -> e[2], xt1s)\n    x2 = map(e -> e[1], xt0s)\n    y2 = map(e -> e[2], xt0s)\n\n    Plots.scatter!(plt, x1,y1, color=1, clim = (0,1), label=\"y=1\")\n    Plots.scatter!(plt, x2,y2, color=0, clim = (0,1), label=\"y=0\")\nend\n\nplt = plot_data!(plt);\nsavefig(plt, \"www/models_samples.png\")","category":"page"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"(Image: )","category":"page"},{"location":"tutorials/models/#Training-the-model","page":"Models","title":"Training the model","text":"","category":"section"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"Instead we will build a simple artificial neural network nn with one hidden layer. For additional resources on how to do deep learning with Flux.jl just have a look at their documentation. ","category":"page"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"function build_model(;input_dim=2,n_hidden=32,output_dim=1)\n    \n    # Params:\n    W‚ÇÅ = input_dim\n    b‚ÇÅ = n_hidden\n    W‚ÇÄ = n_hidden\n    b‚ÇÄ = output_dim\n    \n    nn = Chain(\n        Dense(W‚ÇÅ, b‚ÇÅ, œÉ),\n        Dense(W‚ÇÄ, b‚ÇÄ))  \n\n    return nn\n\nend\nnn = build_model()\nloss(x, y) = Flux.Losses.logitbinarycrossentropy(nn(x), y)\nps = Flux.params(nn)\ndata = zip(xs,ts);","category":"page"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"The code below trains the neural network for the task at hand. The plot shows the (training) loss over time. Note that normally we would be interested in loss with respect to a validation data set. But since we are primarily interested in generated recourse for a trained classifier, here we will just keep things very simple.","category":"page"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"using Flux.Optimise: update!, ADAM\nopt = ADAM()\nepochs = 200\navg_loss(data) = mean(map(d -> loss(d[1],d[2]), data))\n\nusing Plots\nanim = Animation()\nplt = plot(ylim=(0,avg_loss(data)), xlim=(0,epochs), legend=false, xlab=\"Epoch\")\navg_l = []\n\nfor epoch = 1:epochs\n  for d in data\n    gs = gradient(params(nn)) do\n      l = loss(d...)\n    end\n    update!(opt, params(nn), gs)\n  end\n  avg_l = vcat(avg_l,avg_loss(data))\n  plot!(plt, avg_l, color=1, title=\"Average (training) loss\")\n  frame(anim, plt)\nend\n\ngif(anim, \"www/models_loss.gif\");","category":"page"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"(Image: )","category":"page"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"The plot below shows the predicted probabilities in the feature domain. Evidently our simple neural network is doing very well on the training data, as explected. ","category":"page"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"# Plot the posterior distribution with a contour plot.\nx_range = collect(range(-6,stop=6,length=25))\ny_range = collect(range(-6,stop=6,length=25))\nZ = [œÉ.(nn([x, y]))[1] for x=x_range, y=y_range]\nfunction plot_contour(;clegend=true, title=\"\")\n    plt = contourf(x_range, y_range, Z, color=:viridis, legend=clegend, title=title)\n    plot_data!(plt)\nend\nplt = plot_contour();\nsavefig(plt, \"www/models_contour.png\")","category":"page"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"(Image: )","category":"page"},{"location":"tutorials/models/#Generating-recourse","page":"Models","title":"Generating recourse","text":"","category":"section"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"Now it's game time: we have a fitted model M mathcalX mapsto y and are interested in generating recourse for some individual overlinexinmathcalX. As mentioned above we need to do a bit more work to prepare the model to be used by AlgorithmicRecourse.jl. ","category":"page"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"The code below takes care of all of that: in step 1) it declares our model as a subtype of Models.FittedModel and in step 2) it just extends the two functions. ","category":"page"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"using AlgorithmicRecourse, AlgorithmicRecourse.Models\nimport AlgorithmicRecourse.Models: logits, probs # import functions in order to extend\n\n# Step 1)\nstruct NeuralNetwork <: Models.FittedModel\n    nn::Any\nend\n\n# Step 2)\nlogits(ùë¥::NeuralNetwork, X::AbstractArray) = ùë¥.nn(X)\nprobs(ùë¥::NeuralNetwork, X::AbstractArray)= œÉ.(logits(ùë¥, X))\nùë¥ = NeuralNetwork(nn)","category":"page"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"NeuralNetwork(Chain(Dense(2, 32, œÉ), Dense(32, 1)))","category":"page"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"Now we just select a random sample from our data and based on its current label we set as our target the opposite label and desired threshold for the predicted probability.","category":"page"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"using Random\nRandom.seed!(1234)\nxÃÖ = X[:,rand(1:size(X)[2])]\nyÃÖ = round(probs(ùë¥, xÃÖ)[1])\ntarget = ifelse(yÃÖ==1.0,0.0,1.0) # opposite label as target\nŒ≥ = ifelse(target==1.0,0.75,0.25); # desired threshold based on target","category":"page"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"Then finally we use the GenericGenerator to generate recourse. The plot further below shows the resulting counterfactual path.","category":"page"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"generator = GenericGenerator(0.1,0.1,1e-5,:logitbinarycrossentropy,nothing)\nrecourse = generate_recourse(generator, xÃÖ, ùë¥, target, Œ≥); # generate recourse","category":"page"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"T = size(recourse.path)[1]\nyÃÇ = probs(recourse.ùë¥, recourse.path')\np1 = plot_contour(;clegend=false, title=\"Neural network\")\nanim = @animate for t in 1:T\n    scatter!(p1, [recourse.path[t,1]], [recourse.path[t,2]], ms=5, color=Int(yÃÖ))\n    p2 = plot(1:t, yÃÇ[1:t], xlim=(0,T), ylim=(0, 1), label=\"p(yÃ≤=1)\", title=\"Validity\")\n    Plots.abline!(p2,0,Œ≥,label=\"threshold Œ≥\") # decision boundary\n    plot(p1,p2,size=(800,400))\nend\ngif(anim, \"www/models_generic_recourse.gif\", fps=5);","category":"page"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"(Image: )","category":"page"},{"location":"tutorials/models/#Ensemble-of-neural-networks","page":"Models","title":"Ensemble of neural networks","text":"","category":"section"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"In the context of Bayesian classifiers the GreedyGenerator can be used since minimizing the predictive uncertainty acts as a proxy for realism and unambiquity. In other words, if we have a model that incorporates uncertainty, we can generate realistic counterfactuals without the need for a complexity penalty. ","category":"page"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"One efficient way to produce uncertainty estimates in the context of deep learning is to simply use an ensemble of artificial neural networks (also referred to as deep ensemble). To this end we can use the build_model function from above repeatedly to compose an ensemble of K neural networks:","category":"page"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"K = 50\n\nfunction build_ensemble(K::Int;kw=(input_dim=2,n_hidden=32,output_dim=1))\n    ensemble = [build_model(;kw...) for i in 1:K]\n    return ensemble\nend\n\nùìú = build_ensemble(K);","category":"page"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"Now we need to be able to train this ensemble, which boils down to training each neural network separately. For this purpose will just summarize the process for training a single neural network (as per above) in a wrapper function:","category":"page"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"function forward_nn(nn, loss, data, opt; n_epochs=200, plotting=nothing)\n\n    avg_l = []\n    \n    for epoch = 1:n_epochs\n      for d in data\n        gs = gradient(params(nn)) do\n          l = loss(d...)\n        end\n        update!(opt, params(nn), gs)\n      end\n      if !isnothing(plotting)\n        plt = plotting[1]\n        anim = plotting[2]\n        idx = plotting[3]\n        avg_loss(data) = mean(map(d -> loss(d[1],d[2]), data))\n        avg_l = vcat(avg_l,avg_loss(data))\n        if epoch % plotting[4]==0\n          plot!(plt, avg_l, color=idx, alpha=0.3)\n          frame(anim, plt)\n        end\n      end\n    end\n    \nend","category":"page"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"forward_nn (generic function with 1 method)","category":"page"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"This wrapper function is used as a subroutine in forward below, which returns are an ensemble of fitted neural networks. The animation below shows the training loss for each of them. As we can see the different networks produce different outcomes: their parameters were initialized at different random values. This is how we introduce stochasticity and hence incorporate uncertainty around our estimates.","category":"page"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"using Statistics\n\nfunction forward(ùìú, data, opt; loss_type=:logitbinarycrossentropy, plot_loss=true, n_epochs=200, plot_every=20) \n\n    anim = nothing\n    if plot_loss\n        anim = Animation()\n        plt = plot(ylim=(0,1), xlim=(0,n_epochs), legend=false, xlab=\"Epoch\", title=\"Average (training) loss\")\n        for i in 1:length(ùìú)\n            nn = ùìú[i]\n            loss(x, y) = getfield(Flux.Losses,loss_type)(nn(x), y)\n            forward_nn(nn, loss, data, opt, n_epochs=n_epochs, plotting=(plt, anim, i, plot_every))\n        end\n    else\n        plt = nothing\n        for nn in ùìú\n            loss(x, y) = getfield(Flux.Losses,loss_type)(nn(x), y)\n            forward_nn(nn, loss, data, opt, n_epochs=n_epochs, plt=plt)\n        end\n    end\n\n    return ùìú, anim\nend;","category":"page"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"ùìú, anim = forward(ùìú, data, opt, n_epochs=100); # fit the ensemble\ngif(anim, \"www/models_ensemble_loss.gif\", fps=50);","category":"page"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"(Image: )","category":"page"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"Once again it is straight-forward to make the model compatible with the package. Note that for an ensemble model the predicted logits and probabilities are just averages over predictions produced by all K models.","category":"page"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"# Step 1)\nstruct FittedEnsemble <: Models.FittedModel\n    ùìú::AbstractArray\nend\n\n# Step 2)\nlogits(ùë¥::FittedEnsemble, X::AbstractArray) = mean(Flux.flatten(Flux.stack([nn(X) for nn in ùë¥.ùìú],1)),dims=1)\nprobs(ùë¥::FittedEnsemble, X::AbstractArray) = mean(Flux.flatten(Flux.stack([œÉ.(nn(X)) for nn in ùë¥.ùìú],1)),dims=1)\n\nùë¥=FittedEnsemble(ùìú);","category":"page"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"Again we plot the predicted probabilities in the feature domain. As expected the ensemble is more conservative because it incorporates uncertainty: the predicted probabilities splash out more than before, especially in regions that are not populated by samples.","category":"page"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"Z = [probs(ùë¥,[x, y])[1] for x=x_range, y=y_range]\nfunction plot_contour(;clegend=true, title=\"\")\n    plt = contourf(x_range, y_range, Z, color=:viridis, legend=clegend, title=title)\n    plot_data!(plt)\nend\nplt = plot_contour();\nsavefig(plt, \"www/models_ensemble_contour.png\")","category":"page"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"(Image: )","category":"page"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"Finally, we use the GreedyGenerator for the counterfactual search. For the same desired threshold gamma as before, the counterfactual ends up somewhat closer to a cluster of original samples. In other words we end up providing more realisitic albeit likely more costly recourse.","category":"page"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"generator = GreedyGenerator(0.1,20,:logitbinarycrossentropy,nothing)\nrecourse = generate_recourse(generator, xÃÖ, ùë¥, target, Œ≥); # generate recourse","category":"page"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"T = size(recourse.path)[1]\nyÃÇ = probs(recourse.ùë¥, recourse.path')\np1 = plot_contour(;clegend=false, title=\"Deep Ensemble\")\nt = 1\nanim = @animate for t in 1:T\n    scatter!(p1, [recourse.path[t,1]], [recourse.path[t,2]], ms=5, color=Int(yÃÖ))\n    p2 = plot(1:t, yÃÇ[1:t], xlim=(0,T), ylim=(0, 1), label=\"p(yÃ≤=1)\", title=\"Validity\")\n    Plots.abline!(p2,0,Œ≥,label=\"threshold Œ≥\") # decision boundary\n    plot(p1,p2,size=(800,400))\nend\ngif(anim, \"www/models_greedy_recourse.gif\", fps=5);","category":"page"},{"location":"tutorials/models/","page":"Models","title":"Models","text":"(Image: )","category":"page"},{"location":"tutorials/binary/","page":"Binary target","title":"Binary target","text":"CurrentModule = AlgorithmicRecourse ","category":"page"},{"location":"tutorials/binary/#Generating-recourse","page":"Binary target","title":"Generating recourse","text":"","category":"section"},{"location":"tutorials/binary/","page":"Binary target","title":"Binary target","text":"using Flux\nusing Random\nusing Plots\nusing PlotThemes\ntheme(:juno)\nusing Logging\ndisable_logging(Logging.Info)","category":"page"},{"location":"tutorials/binary/","page":"Binary target","title":"Binary target","text":"LogLevel(1)","category":"page"},{"location":"tutorials/binary/","page":"Binary target","title":"Binary target","text":"To understand the core functionality of AlgorithmicRecourse.jl we will look at two example use cases of the generate_recourse function. This function takes a structure of type Generator as its main argument. Users can utilize one of the default generators: GenericGenerator <: Generator, GreedyGenerator <: Generator. Alternatively, users can also create their own custom generator. ","category":"page"},{"location":"tutorials/binary/#Default-generators","page":"Binary target","title":"Default generators","text":"","category":"section"},{"location":"tutorials/binary/#GenericGenerator","page":"Binary target","title":"GenericGenerator","text":"","category":"section"},{"location":"tutorials/binary/","page":"Binary target","title":"Binary target","text":"Let tin01 denote the target label, M the model (classifier) and underlinexinmathbbR^D the vector of counterfactual features. In order to generate recourse the GenericGenerator optimizes the following objective function through steepest descent","category":"page"},{"location":"tutorials/binary/","page":"Binary target","title":"Binary target","text":"underlinex = arg min_underlinex  ell(M(underlinex)t) + lambda h(underlinex)","category":"page"},{"location":"tutorials/binary/","page":"Binary target","title":"Binary target","text":"where ell denotes some loss function targeting the deviation between the target label and the predicted label and h(cdot) as a complexity penality generally addressing the realism or cost of the proposed counterfactual. ","category":"page"},{"location":"tutorials/binary/","page":"Binary target","title":"Binary target","text":"Let's generate some toy data:","category":"page"},{"location":"tutorials/binary/","page":"Binary target","title":"Binary target","text":"# Some random data:\nRandom.seed!(1234);\nN = 25\nw = reshape([1.0,-2.0],2,1) # true coefficients\nb = 0\nX = reshape(randn(2*N),N,2).*1 # random features\ny = Int.(round.(Flux.œÉ.(X*w .+ b))); # label based on sigmoid\n# Choose sample and plot:\nxÃÖ = reshape(X[5,:],1,2);","category":"page"},{"location":"tutorials/binary/","page":"Binary target","title":"Binary target","text":"For this toy data we will now implement algorithmic recourse as follows:","category":"page"},{"location":"tutorials/binary/","page":"Binary target","title":"Binary target","text":"Use the coefficients w and b to define our model using AlgorithmicRecourse.Models.LogisticModel(w, b).\nDefine our GenericGenerator.\nGenerate recourse.","category":"page"},{"location":"tutorials/binary/","page":"Binary target","title":"Binary target","text":"using AlgorithmicRecourse\nùë¥ = AlgorithmicRecourse.Models.LogisticModel(w, [b]);\nyÃÖ = round.(AlgorithmicRecourse.Models.probs(ùë¥, xÃÖ))[1]\ntarget = ifelse(yÃÖ==1.0,0.0,1.0)\nŒ≥ = ifelse(target==1.0,0.75,0.25)\ngenerator = GenericGenerator(0.1,0.1,1e-5,:logitbinarycrossentropy,nothing)\nrecourse = generate_recourse(generator, xÃÖ, ùë¥, target, Œ≥); # generate recourse","category":"page"},{"location":"tutorials/binary/","page":"Binary target","title":"Binary target","text":"Now let's plot the resulting counterfactual path in the 2-D feature space (left) and the predicted probability (right):","category":"page"},{"location":"tutorials/binary/","page":"Binary target","title":"Binary target","text":"x1 = (minimum(X[:,1])-1):0.1:(maximum(X[:,1])+1)\nx2 = (minimum(X[:,2])-1):0.1:(maximum(X[:,2])+1)\np1 = Plots.contourf(\n    x1,x2,(x, y) -> AlgorithmicRecourse.Models.probs(recourse.ùë¥, reshape([x,y],(1,2)))[1],\n    color = :viridis,\n    linewidth = 0,\n    legend=false\n)\nscatter!(p1,X[:,1],X[:,2],legend=false,color=y,title=\"Logistic Regression\") # features\nPlots.abline!(p1, -w[1]/w[2],0,color=\"black\") # decision boundary\nT = size(recourse.path)[1]\nprobs = AlgorithmicRecourse.Models.probs(recourse.ùë¥, recourse.path)\nanim = @animate for t in 1:T\n    scatter!(p1, [recourse.path[t,1]], [recourse.path[t,2]], ms=5, color=Int(yÃÖ))\n    p2 = plot(1:t, probs[1:t], xlim=(0,T), ylim=(0, 1), label=\"p(yÃ≤=1)\", title=\"Validity\")\n    Plots.abline!(p2,0,Œ≥,label=\"threshold Œ≥\") # decision boundary\n    plot(p1,p2,size=(800,400))\nend\ngif(anim, \"www/generic_recourse.gif\", fps=5);","category":"page"},{"location":"tutorials/binary/","page":"Binary target","title":"Binary target","text":"(Image: )","category":"page"},{"location":"tutorials/binary/#GreedyGenerator","page":"Binary target","title":"GreedyGenerator","text":"","category":"section"},{"location":"tutorials/binary/","page":"Binary target","title":"Binary target","text":"Next we will repeat the exercise above, but instead use the GreedyGenerator in the context of a Bayesian classifier. This generator is greedy in the sense that it simply chooses the most salient feature underlinexd where d=argmax_d in 1D nabla_underlinex ell(M(underlinex)t) and perturbs it by a fixed amount delta. In other words, optimization is penalty-free. This is possible in the Bayesian context, because maximizing the predictive probability gamma corresponds to minimizing the predictive uncertainty: by construction the generated counterfactual will therefore be realistic (low epistemic uncertainty) and unambiguous (low aleotoric uncertainty).","category":"page"},{"location":"tutorials/binary/","page":"Binary target","title":"Binary target","text":"using LinearAlgebra\nŒ£ = Symmetric(reshape(randn(9),3,3).*0.01 + UniformScaling(1)) # MAP covariance matrix\nŒº = vcat(b, w)\nùë¥ = AlgorithmicRecourse.Models.BayesianLogisticModel(Œº, Œ£);\ngenerator = GreedyGenerator(0.1,12,:logitbinarycrossentropy,nothing)\nrecourse = generate_recourse(generator, xÃÖ, ùë¥, target, Œ≥); # generate recourse","category":"page"},{"location":"tutorials/binary/","page":"Binary target","title":"Binary target","text":"Once again we plot the resulting counterfactual path (left) and changes in the predicted probability (right). For the Bayesian classifier predicted probabilities splash out: uncertainty increases in regions with few samples. Note how the greedy approach selects the same most salient feature over and over again until its exhausted (i.e. it has been chosen GreedyGenerator.n times).","category":"page"},{"location":"tutorials/binary/","page":"Binary target","title":"Binary target","text":"p1 = Plots.contourf(\n    x1,x2,(x, y) -> AlgorithmicRecourse.Models.probs(recourse.ùë¥, reshape([x,y],(1,2)))[1],\n    color = :viridis,\n    linewidth = 0,\n    legend=false\n)\nscatter!(p1,X[:,1],X[:,2],legend=false,color=y,title=\"Bayesian Logistic Regression\") # features\nPlots.abline!(p1, -w[1]/w[2],0,color=\"black\") # decision boundary\nT = size(recourse.path)[1]\nprobs = AlgorithmicRecourse.Models.probs(recourse.ùë¥, recourse.path)\nanim = @animate for t in 1:T\n    scatter!(p1, [recourse.path[t,1]], [recourse.path[t,2]], ms=5, color=Int(yÃÖ))\n    p2 = plot(1:t, probs[1:t], xlim=(0,T), ylim=(0, 1), label=\"p(yÃ≤=1)\", title=\"Validity\")\n    Plots.abline!(p2,0,Œ≥,label=\"threshold Œ≥\") # decision boundary\n    plot(p1,p2,size=(800,400))\nend\ngif(anim, \"www/greedy_recourse.gif\", fps=5);","category":"page"},{"location":"tutorials/binary/","page":"Binary target","title":"Binary target","text":"(Image: )","category":"page"}]
}
