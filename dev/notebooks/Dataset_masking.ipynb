{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14e30426-1457-4c05-ba3f-272e9241b139",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Transformers.TextEncoders\n",
    "using Transformers.HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30228c72-e074-43ab-9b28-129c5811963e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTextEncoder(\n",
       "├─ TextTokenizer(MatchTokenization(WordPieceTokenization(bert_uncased_tokenizer, WordPiece(vocab_size = 30522, unk = [UNK], max_char = 100)), 5 patterns)),\n",
       "├─ vocab = Vocab{String, SizedArray}(size = 30522, unk = [UNK], unki = 101),\n",
       "├─ startsym = [CLS],\n",
       "├─ endsym = [SEP],\n",
       "├─ padsym = [PAD],\n",
       "├─ trunc = 512,\n",
       "└─ process = Pipelines:\n",
       "  ╰─ target[token] := TextEncodeBase.nestedcall(string_getvalue, source)\n",
       "  ╰─ target[token] := Transformers.TextEncoders.grouping_sentence(target.token)\n",
       "  ╰─ target[(token, segment)] := SequenceTemplate{String}([CLS]:<type=1> Input[1]:<type=1> [SEP]:<type=1> (Input[2]:<type=2> [SEP]:<type=2>)...)(target.token)\n",
       "  ╰─ target[attention_mask] := (NeuralAttentionlib.LengthMask ∘ Transformers.TextEncoders.getlengths(512))(target.token)\n",
       "  ╰─ target[token] := TextEncodeBase.trunc_and_pad(512, [PAD], tail, tail)(target.token)\n",
       "  ╰─ target[token] := TextEncodeBase.nested2batch(target.token)\n",
       "  ╰─ target[segment] := TextEncodeBase.trunc_and_pad(512, 1, tail, tail)(target.segment)\n",
       "  ╰─ target[segment] := TextEncodeBase.nested2batch(target.segment)\n",
       "  ╰─ target := (target.token, target.segment, target.attention_mask)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_enc = hgf\"bert-base-uncased:tokenizer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96d7bb3c-85a8-4fdd-bd72-c98ee6904758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(token = Bool[0 0 … 0 0; 0 0 … 0 0; … ; 0 0 … 0 0; 0 0 … 0 0;;; 0 0 … 1 1; 0 0 … 0 0; … ; 0 0 … 0 0; 0 0 … 0 0], segment = [1 1; 1 1; … ; 1 1; 1 1], attention_mask = NeuralAttentionlib.LengthMask{1, Vector{Int32}}(Int32[11, 9]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode(bert_enc, [\"hello [MASK] world [MASK] [MASK] and my [MASK]!\", \"bonjour mes [MASK].\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72aefb08-9c24-4c99-afe6-f3cafe743c22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.2",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
