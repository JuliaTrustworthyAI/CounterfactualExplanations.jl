{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a521610f-12dc-4e6e-80e7-b51328794d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `C:\\Users\\drobi\\Desktop\\uni\\master_thesis\\CounterfactualExplanations.jl\\dev\\notebooks\\Project.toml`\n",
      "\u001b[33m⌅\u001b[39m \u001b[90m[62b44479] \u001b[39m\u001b[92m+ CUDNN_jll v8.9.4+0\u001b[39m\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\drobi\\Desktop\\uni\\master_thesis\\CounterfactualExplanations.jl\\dev\\notebooks\\Manifest.toml`\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.add(\"CUDNN_jll\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0de19327-1494-4f9c-a799-d5551fac5826",
   "metadata": {},
   "outputs": [],
   "source": [
    "using DataFrames\n",
    "using Transformers\n",
    "using Transformers.TextEncoders\n",
    "using Transformers.HuggingFace\n",
    "using TrillionDollarWords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e29646-4837-4121-a9fe-6426a352811e",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a9c6c853-d63f-4f48-b188-0d12d9a11be0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>10×7 DataFrame</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">sentence</th><th style = \"text-align: left;\">year</th><th style = \"text-align: left;\">label</th><th style = \"text-align: left;\">seed</th><th style = \"text-align: left;\">sentence_splitting</th><th style = \"text-align: left;\">event_type</th><th style = \"text-align: left;\">split</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"String\" style = \"text-align: left;\">String</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"InlineStrings.String7\" style = \"text-align: left;\">String7</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Bool\" style = \"text-align: left;\">Bool</th><th title = \"InlineStrings.String31\" style = \"text-align: left;\">String31</th><th title = \"InlineStrings.String7\" style = \"text-align: left;\">String7</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: left;\">remained well below their levels at the beginning of the year, and that weaker demand and earlier declines in oil prices had been holding down consumer price inflation.</td><td style = \"text-align: right;\">1996</td><td style = \"text-align: left;\">hawkish</td><td style = \"text-align: right;\">5768</td><td style = \"text-align: right;\">true</td><td style = \"text-align: left;\">meeting minutes</td><td style = \"text-align: left;\">test</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: left;\">A few participants also noted that uncertainty about the extent of resource slack in the economy was considerable and that it was quite possible that the economy could soon be operating close to potential, particularly if labor force participation rates did not turn up much while employment continued to register gains.</td><td style = \"text-align: right;\">1996</td><td style = \"text-align: left;\">neutral</td><td style = \"text-align: right;\">5768</td><td style = \"text-align: right;\">true</td><td style = \"text-align: left;\">meeting minutes</td><td style = \"text-align: left;\">test</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: left;\">inflation was projected to pick up gradually in association with a partial reversal of the decline in energy prices this year.</td><td style = \"text-align: right;\">1996</td><td style = \"text-align: left;\">neutral</td><td style = \"text-align: right;\">5768</td><td style = \"text-align: right;\">true</td><td style = \"text-align: left;\">meeting minutes</td><td style = \"text-align: left;\">test</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: left;\">They noted that the realization of such a development could make it harder for the Committee to achieve 2 percent inflation over the longer run.</td><td style = \"text-align: right;\">1996</td><td style = \"text-align: left;\">neutral</td><td style = \"text-align: right;\">5768</td><td style = \"text-align: right;\">true</td><td style = \"text-align: left;\">meeting minutes</td><td style = \"text-align: left;\">test</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5</td><td style = \"text-align: left;\">In the view of one member, however, aggregate final demand was so strong that, with economic activity and the associated demand for labor having expanded at an unsustainable pace for some time, one could be reasonably confident that inflation would most likely pick up in the absence of policy action.</td><td style = \"text-align: right;\">1996</td><td style = \"text-align: left;\">hawkish</td><td style = \"text-align: right;\">5768</td><td style = \"text-align: right;\">true</td><td style = \"text-align: left;\">meeting minutes</td><td style = \"text-align: left;\">test</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">6</td><td style = \"text-align: left;\">In the circumstances, most members endorsed a proposal to delete as no longer necessary the previous summary statement relating to the risks to growth and inflation taken together.</td><td style = \"text-align: right;\">1996</td><td style = \"text-align: left;\">neutral</td><td style = \"text-align: right;\">5768</td><td style = \"text-align: right;\">true</td><td style = \"text-align: left;\">meeting minutes</td><td style = \"text-align: left;\">test</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">7</td><td style = \"text-align: left;\">In the staff forecast prepared for this meeting, the economy was seen as likely to expand at a moderate pace, supported by accommodative monetary policy and financial conditions.</td><td style = \"text-align: right;\">1996</td><td style = \"text-align: left;\">dovish</td><td style = \"text-align: right;\">5768</td><td style = \"text-align: right;\">true</td><td style = \"text-align: left;\">meeting minutes</td><td style = \"text-align: left;\">test</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">8</td><td style = \"text-align: left;\">Housing starts and the demand for new homes had declined further, house prices in many parts of the country were falling faster than they had towards the end of 2007, and inventories of unsold homes remained quite elevated.</td><td style = \"text-align: right;\">1996</td><td style = \"text-align: left;\">dovish</td><td style = \"text-align: right;\">5768</td><td style = \"text-align: right;\">true</td><td style = \"text-align: left;\">meeting minutes</td><td style = \"text-align: left;\">test</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">9</td><td style = \"text-align: left;\">Pressures on resources would rise as the anticipated upturn and possible above-trend growth brought the economy closer to full capacity utilization.</td><td style = \"text-align: right;\">1996</td><td style = \"text-align: left;\">hawkish</td><td style = \"text-align: right;\">5768</td><td style = \"text-align: right;\">true</td><td style = \"text-align: left;\">meeting minutes</td><td style = \"text-align: left;\">test</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">10</td><td style = \"text-align: left;\">Price inflation had picked up a little but, abstracting from energy, had remained relatively subdued.</td><td style = \"text-align: right;\">1996</td><td style = \"text-align: left;\">neutral</td><td style = \"text-align: right;\">5768</td><td style = \"text-align: right;\">true</td><td style = \"text-align: left;\">meeting minutes</td><td style = \"text-align: left;\">test</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cc}\n",
       "\t& sentence & \\\\\n",
       "\t\\hline\n",
       "\t& String & \\\\\n",
       "\t\\hline\n",
       "\t1 & remained well below their levels at the beginning of the year, and that weaker demand and earlier declines in oil prices had been holding down consumer price inflation. & $\\dots$ \\\\\n",
       "\t2 & A few participants also noted that uncertainty about the extent of resource slack in the economy was considerable and that it was quite possible that the economy could soon be operating close to potential, particularly if labor force participation rates did not turn up much while employment continued to register gains. & $\\dots$ \\\\\n",
       "\t3 & inflation was projected to pick up gradually in association with a partial reversal of the decline in energy prices this year. & $\\dots$ \\\\\n",
       "\t4 & They noted that the realization of such a development could make it harder for the Committee to achieve 2 percent inflation over the longer run. & $\\dots$ \\\\\n",
       "\t5 & In the view of one member, however, aggregate final demand was so strong that, with economic activity and the associated demand for labor having expanded at an unsustainable pace for some time, one could be reasonably confident that inflation would most likely pick up in the absence of policy action. & $\\dots$ \\\\\n",
       "\t6 & In the circumstances, most members endorsed a proposal to delete as no longer necessary the previous summary statement relating to the risks to growth and inflation taken together. & $\\dots$ \\\\\n",
       "\t7 & In the staff forecast prepared for this meeting, the economy was seen as likely to expand at a moderate pace, supported by accommodative monetary policy and financial conditions. & $\\dots$ \\\\\n",
       "\t8 & Housing starts and the demand for new homes had declined further, house prices in many parts of the country were falling faster than they had towards the end of 2007, and inventories of unsold homes remained quite elevated. & $\\dots$ \\\\\n",
       "\t9 & Pressures on resources would rise as the anticipated upturn and possible above-trend growth brought the economy closer to full capacity utilization. & $\\dots$ \\\\\n",
       "\t10 & Price inflation had picked up a little but, abstracting from energy, had remained relatively subdued. & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m10×7 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m sentence                          \u001b[0m\u001b[1m year  \u001b[0m\u001b[1m label   \u001b[0m\u001b[1m seed  \u001b[0m\u001b[1m sentence_spli\u001b[0m ⋯\n",
       "     │\u001b[90m String                            \u001b[0m\u001b[90m Int64 \u001b[0m\u001b[90m String7 \u001b[0m\u001b[90m Int64 \u001b[0m\u001b[90m Bool         \u001b[0m ⋯\n",
       "─────┼──────────────────────────────────────────────────────────────────────────\n",
       "   1 │ remained well below their levels…   1996  hawkish   5768                ⋯\n",
       "   2 │ A few participants also noted th…   1996  neutral   5768\n",
       "   3 │ inflation was projected to pick …   1996  neutral   5768\n",
       "   4 │ They noted that the realization …   1996  neutral   5768\n",
       "   5 │ In the view of one member, howev…   1996  hawkish   5768                ⋯\n",
       "   6 │ In the circumstances, most membe…   1996  neutral   5768\n",
       "   7 │ In the staff forecast prepared f…   1996  dovish    5768\n",
       "   8 │ Housing starts and the demand fo…   1996  dovish    5768\n",
       "   9 │ Pressures on resources would ris…   1996  hawkish   5768                ⋯\n",
       "  10 │ Price inflation had picked up a …   1996  neutral   5768\n",
       "\u001b[36m                                                               3 columns omitted\u001b[0m"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 10\n",
    "data = load_training_sentences()\n",
    "texts = filter(:split => n -> n == \"test\", data)[1:n, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c716f911-920d-468b-92e8-8ca639367303",
   "metadata": {},
   "source": [
    "### Get attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e00a7c85-2a74-41bf-ad75-899f3317dac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m    CondaPkg \u001b[22m\u001b[39m\u001b[0mFound dependencies: C:\\Users\\drobi\\Desktop\\uni\\master_thesis\\CounterfactualExplanations.jl\\dev\\notebooks\\CondaPkg.toml\n",
      "\u001b[32m\u001b[1m    CondaPkg \u001b[22m\u001b[39m\u001b[0mFound dependencies: C:\\Users\\drobi\\.julia\\packages\\PythonCall\\wXfah\\CondaPkg.toml\n",
      "\u001b[32m\u001b[1m    CondaPkg \u001b[22m\u001b[39m\u001b[0mResolving changes\n",
      "\u001b[32m\u001b[1m             \u001b[22m\u001b[39m\u001b[32m+ transformers-interpret\u001b[39m\n",
      "\u001b[32m\u001b[1m    CondaPkg \u001b[22m\u001b[39m\u001b[0mInstalling packages\n",
      "\u001b[32m\u001b[1m             \u001b[22m\u001b[39m│ \u001b[90mC:\\Users\\drobi\\.julia\\conda\\3\\x86_64\\Scripts\\mamba.exe\u001b[39m\n",
      "\u001b[32m\u001b[1m             \u001b[22m\u001b[39m│ \u001b[90minstall\u001b[39m\n",
      "\u001b[32m\u001b[1m             \u001b[22m\u001b[39m│ \u001b[90m-y\u001b[39m\n",
      "\u001b[32m\u001b[1m             \u001b[22m\u001b[39m│ \u001b[90m-p C:\\Users\\drobi\\Desktop\\uni\\master_thesis\\CounterfactualExplanations.jl\\dev\\notebooks\\.CondaPkg\\env\u001b[39m\n",
      "\u001b[32m\u001b[1m             \u001b[22m\u001b[39m│ \u001b[90m--override-channels\u001b[39m\n",
      "\u001b[32m\u001b[1m             \u001b[22m\u001b[39m│ \u001b[90m--no-channel-priority\u001b[39m\n",
      "\u001b[32m\u001b[1m             \u001b[22m\u001b[39m│ \u001b[90mpython[version='>=3.8,<4']\u001b[39m\n",
      "\u001b[32m\u001b[1m             \u001b[22m\u001b[39m│ \u001b[90mpython[version='>=3.7,<4',channel='anaconda']\u001b[39m\n",
      "\u001b[32m\u001b[1m             \u001b[22m\u001b[39m│ \u001b[90mpytorch[version='*']\u001b[39m\n",
      "\u001b[32m\u001b[1m             \u001b[22m\u001b[39m│ \u001b[90mpytorch-cuda[version='12.1']\u001b[39m\n",
      "\u001b[32m\u001b[1m             \u001b[22m\u001b[39m│ \u001b[90mtransformers[version='4.15.0']\u001b[39m\n",
      "\u001b[32m\u001b[1m             \u001b[22m\u001b[39m│ \u001b[90mtransformers-interpret[version='*']\u001b[39m\n",
      "\u001b[32m\u001b[1m             \u001b[22m\u001b[39m│ \u001b[90m-c anaconda\u001b[39m\n",
      "\u001b[32m\u001b[1m             \u001b[22m\u001b[39m│ \u001b[90m-c conda-forge\u001b[39m\n",
      "\u001b[32m\u001b[1m             \u001b[22m\u001b[39m│ \u001b[90m-c nvidia\u001b[39m\n",
      "\u001b[32m\u001b[1m             \u001b[22m\u001b[39m└ \u001b[90m-c pytorch\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anaconda/win-64                                             Using cache\n",
      "anaconda/noarch                                             Using cache\n",
      "conda-forge/win-64                                          Using cache\n",
      "conda-forge/noarch                                          Using cache\n",
      "nvidia/win-64                                               Using cache\n",
      "nvidia/noarch                                               Using cache\n",
      "pytorch/win-64                                              Using cache\n",
      "pytorch/noarch                                              Using cache\n",
      "anaconda/win-64                                             Using cache\n",
      "anaconda/noarch                                             Using cache\n",
      "Transaction\n",
      "\n",
      "  Prefix: C:\\Users\\drobi\\Desktop\\uni\\master_thesis\\CounterfactualExplanations.jl\\dev\\notebooks\\.CondaPkg\\env\n",
      "\n",
      "  Updating specs:\n",
      "\n",
      "   - python[version='>=3.8,<4']\n",
      "   - anaconda::python[version='>=3.7,<4']\n",
      "   - pytorch=*\n",
      "   - pytorch-cuda==12.1\n",
      "   - transformers==4.15.0\n",
      "   - transformers-interpret=*\n",
      "   - ca-certificates\n",
      "   - certifi\n",
      "   - openssl\n",
      "\n",
      "\n",
      "  Package                    Version  Build            Channel           Size\n",
      "-------------------------------------------------------------------------------\n",
      "  Install:\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  + xorg-libxau               1.0.11  hcd874cb_0       conda-forge       51kB\n",
      "  + libjpeg-turbo              3.0.0  hcfcfb64_1       conda-forge      823kB\n",
      "  + lerc                       4.0.0  h63175ca_0       conda-forge      194kB\n",
      "  + libdeflate                  1.19  hcfcfb64_0       conda-forge      153kB\n",
      "  + libbrotlicommon            1.1.0  hcfcfb64_1       conda-forge       71kB\n",
      "  + libpng                    1.6.43  h19919ed_0       conda-forge      348kB\n",
      "  + pthread-stubs                0.4  hcd874cb_1001    conda-forge        6kB\n",
      "  + xorg-libxdmcp              1.1.3  hcd874cb_0       conda-forge       68kB\n",
      "  + libbrotlienc               1.1.0  hcfcfb64_1       conda-forge      247kB\n",
      "  + libbrotlidec               1.1.0  hcfcfb64_1       conda-forge       33kB\n",
      "  + libxcb                      1.15  hcd874cb_0       conda-forge      970kB\n",
      "  + brotli-bin                 1.1.0  hcfcfb64_1       conda-forge       21kB\n",
      "  + brotli                     1.1.0  hcfcfb64_1       conda-forge       20kB\n",
      "  + libwebp-base               1.3.2  h2bbff1b_0       anaconda         338kB\n",
      "  + lz4-c                      1.9.4  h2bbff1b_0       anaconda         143kB\n",
      "  + freetype                  2.12.1  ha860e81_0       anaconda         528kB\n",
      "  + zstd                       1.5.5  hd43e919_0       anaconda           2MB\n",
      "  + backcall                   0.2.0  pyhd3eb1b0_0     anaconda          14kB\n",
      "  + munkres                    1.1.4  py_0             anaconda          13kB\n",
      "  + parso                      0.8.3  pyhd3eb1b0_0     anaconda          71kB\n",
      "  + pickleshare                0.7.5  pyhd3eb1b0_1003  anaconda          13kB\n",
      "  + decorator                  5.1.1  pyhd3eb1b0_0     anaconda          12kB\n",
      "  + zipp                      3.17.0  pyhd8ed1ab_0     conda-forge     Cached\n",
      "  + python-dateutil            2.9.0  pyhd8ed1ab_0     conda-forge     Cached\n",
      "  + pyparsing                  3.1.2  pyhd8ed1ab_0     conda-forge       89kB\n",
      "  + cycler                    0.12.1  pyhd8ed1ab_0     conda-forge       13kB\n",
      "  + wcwidth                   0.2.13  pyhd8ed1ab_0     conda-forge     Cached\n",
      "  + traitlets                 5.14.2  pyhd8ed1ab_0     conda-forge     Cached\n",
      "  + pygments                  2.17.2  pyhd8ed1ab_0     conda-forge     Cached\n",
      "  + jedi                      0.19.1  pyhd8ed1ab_0     conda-forge     Cached\n",
      "  + importlib_resources        6.3.0  pyhd8ed1ab_0     conda-forge       31kB\n",
      "  + prompt-toolkit            3.0.42  pyha770c72_0     conda-forge     Cached\n",
      "  + importlib-resources        6.3.0  pyhd8ed1ab_0     conda-forge       10kB\n",
      "  + unicodedata2              15.1.0  py39ha55989b_0   conda-forge      373kB\n",
      "  + kiwisolver                 1.4.5  py39h1f6ef14_1   conda-forge       56kB\n",
      "  + contourpy                  1.2.0  py39h1f6ef14_0   conda-forge      186kB\n",
      "  + libtiff                    4.6.0  h6e2ebb7_2       conda-forge      787kB\n",
      "  + fonttools                 4.49.0  py39ha55989b_0   conda-forge        2MB\n",
      "  + openjpeg                   2.5.2  h3d672ee_0       conda-forge      238kB\n",
      "  + lcms2                       2.16  h67d730c_0       conda-forge      508kB\n",
      "  + pillow                    10.2.0  py39h368b509_0   conda-forge       42MB\n",
      "  + matplotlib-base            3.8.3  py39hf19769e_0   conda-forge        7MB\n",
      "  + matplotlib-inline          0.1.6  py39haa95532_0   anaconda          18kB\n",
      "  + captum                     0.7.0  0                pytorch            1MB\n",
      "  + ipython                   7.33.0  py39hcbf5309_0   conda-forge        1MB\n",
      "  + transformers-interpret     0.8.1  pyhd8ed1ab_0     conda-forge       35kB\n",
      "\n",
      "  Reinstall:\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  o ca-certificates         2024.2.2  h56e8100_0       conda-forge     Cached\n",
      "  o openssl                    3.2.1  hcfcfb64_0       conda-forge     Cached\n",
      "  o python                    3.9.18  h1aa4202_0       anaconda        Cached\n",
      "  o certifi                 2024.2.2  pyhd8ed1ab_0     conda-forge     Cached\n",
      "\n",
      "  Summary:\n",
      "\n",
      "  Install: 46 packages\n",
      "  Reinstall: 4 packages\n",
      "\n",
      "  Total download: 61MB\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Looking for: [\"python[version='>=3.8,<4']\", \"anaconda::python[version='>=3.7,<4']\", 'pytorch=', 'pytorch-cuda==12.1', 'transformers==4.15.0', 'transformers-interpret=']\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages: ...working... done\n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n"
     ]
    }
   ],
   "source": [
    "using CondaPkg\n",
    "# CondaPkg.add(\"pytorch\")\n",
    "# CondaPkg.add(\"transformers\"; version=\"4.15.0\")\n",
    "# CondaPkg.add(\"transformers-interpret\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a605169-6109-41fb-973b-7d5a044e71f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1mPrecompiling\u001b[22m\u001b[39m PythonCall\n",
      "\u001b[32m  ✓ \u001b[39mPythonCall\n",
      "  1 dependency successfully precompiled in 20 seconds. 24 already precompiled.\n"
     ]
    }
   ],
   "source": [
    "using PythonCall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12c9f296-f8bb-4142-a7db-ece5061b635e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Python: <module 'transformers' from 'C:\\\\Users\\\\drobi\\\\Desktop\\\\uni\\\\master_thesis\\\\CounterfactualExplanations.jl\\\\dev\\\\notebooks\\\\.CondaPkg\\\\env\\\\lib\\\\site-packages\\\\transformers\\\\__init__.py'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformers_interpret = PythonCall.pyimport(\"transformers_interpret\")\n",
    "transformers = PythonCall.pyimport(\"transformers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4ced2a6-e9dd-4179-b917-007e377cccd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Python: PreTrainedTokenizerFast(name_or_path='gtfintechlab/FOMC-RoBERTa', vocab_size=50265, model_max_len=512, is_fast=True, padding_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=False)})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load pre-trained classifier and corresponding tokenizer\n",
    "model = transformers.RobertaForSequenceClassification.from_pretrained(\"model\", local_files_only=true)\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\"gtfintechlab/FOMC-RoBERTa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "21ab1d00-867f-4bd4-a2f6-83e4940554be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Python: <transformers_interpret.explainers.sequence_classification.SequenceClassificationExplainer object at 0x000001FDDBFEC760>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scorer = transformers_interpret.SequenceClassificationExplainer(model, tokenizer, attribution_type=\"lig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ec54e441-653c-44ef-9cf5-684267a663bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Python: [('<s>', 0.0), ('rem', -0.09617849663936606), ('ained', -0.29702715615956665), ('well', 0.25551209840018674), ('below', -0.4015987185377847), ('their', -0.013975036770146217), ('levels', -0.13794157805498133), ('at', -0.002103001077563767), ('the', 0.14926277592717438), ('beginning', 0.08228264530334284), ('of', 0.08006335674570937), ('the', 0.24284418735078794), ('year', 0.20003154332566433), (',', 0.13104142887853437), ('and', 0.17795123590947837), ('that', 0.177958452206897), ('weaker', 0.07827504560711215), ('demand', 0.06225654464144761), ('and', 0.20338402474663345), ('earlier', -0.2643532357406369), ('declines', 0.14990056209456956), ('in', -0.3258371366392156), ('oil', -0.06976564966318043), ('prices', 0.011989646035101107), ('had', -0.15355389676950998), ('been', -0.10492307025848874), ('holding', -0.07771222018418246), ('down', -0.024919108109520634), ('consumer', 0.09788758630638592), ('price', 0.011979387105458176), ('inflation', -0.09257150340664654), ('.', 0.15492799445950947), ('', -0.3214473479860127), ('</s>', 0.0)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scorer(texts[1, :].sentence, index=0, internal_batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2c5458-657c-4f69-8499-6fc46aa27760",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b25039fe-329f-46e4-b308-33bc42c734ea",
   "metadata": {},
   "source": [
    "### Mask the word attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48278c99-7368-4eaa-b26f-1b91674fc514",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mfuse_unk is unsupported, the tokenization result might be slightly different in some cases.\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ Transformers.HuggingFace C:\\Users\\drobi\\.julia\\packages\\Transformers\\lD5nW\\src\\huggingface\\tokenizer\\utils.jl:42\u001b[39m\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mmatch token `<mask>` require to match with space on either side but that is not implemented here, the tokenization result might be slightly different in some cases.\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ Transformers.HuggingFace C:\\Users\\drobi\\.julia\\packages\\Transformers\\lD5nW\\src\\huggingface\\tokenizer\\utils.jl:42\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BaselineModel(GPT2TextEncoder(\n",
       "├─ TextTokenizer(MatchTokenization(CodeNormalizer(BPETokenization(GPT2Tokenization, bpe = CachedBPE(BPE(50000 merges))), codemap = CodeMap{UInt8 => UInt16}(3 code-ranges)), 5 patterns)),\n",
       "├─ vocab = Vocab{String, SizedArray}(size = 50265, unk = <unk>, unki = 4),\n",
       "├─ codemap = CodeMap{UInt8 => UInt16}(3 code-ranges),\n",
       "├─ startsym = <s>,\n",
       "├─ endsym = </s>,\n",
       "├─ padsym = <pad>,\n",
       "├─ trunc = 256,\n",
       "└─ process = Pipelines:\n",
       "  ╰─ target[token] := TextEncodeBase.nestedcall(string_getvalue, source)\n",
       "  ╰─ target[token] := Transformers.TextEncoders.grouping_sentence(target.token)\n",
       "  ╰─ target[(token, segment)] := SequenceTemplate{String}(<s>:<type=1> Input:<type=1> </s>:<type=1> (</s>:<type=1> Input:<type=1> </s>:<type=1>)...)(target.token)\n",
       "  ╰─ target[attention_mask] := (NeuralAttentionlib.LengthMask ∘ Transformers.TextEncoders.getlengths(256))(target.token)\n",
       "  ╰─ target[token] := TextEncodeBase.trunc_or_pad(256, <pad>, tail, tail)(target.token)\n",
       "  ╰─ target[token] := TextEncodeBase.nested2batch(target.token)\n",
       "  ╰─ target := (target.token, target.attention_mask)\n",
       "), HGFRobertaForSequenceClassification(HGFRobertaModel(Chain(CompositeEmbedding(token = Embed(1024, 50265), position = ApplyEmbed(.+, FixedLenPositionEmbed(1024, 514), Transformers.HuggingFace.roberta_pe_indices(1,)), segment = ApplyEmbed(.+, Embed(1024, 1), Transformers.HuggingFace.bert_ones_like)), DropoutLayer<nothing>(LayerNorm(1024, ϵ = 1.0e-5))), Transformer<24>(PostNormTransformerBlock(DropoutLayer<nothing>(SelfAttention(MultiheadQKVAttenOp(head = 16, p = nothing), Fork<3>(Dense(W = (1024, 1024), b = true)), Dense(W = (1024, 1024), b = true))), LayerNorm(1024, ϵ = 1.0e-5), DropoutLayer<nothing>(Chain(Dense(σ = NNlib.gelu, W = (1024, 4096), b = true), Dense(W = (4096, 1024), b = true))), LayerNorm(1024, ϵ = 1.0e-5))), nothing), Branch{(:logit,) = (:hidden_state,)}(Chain(DropoutLayer<nothing>(Transformers.HuggingFace.FirstTokenPooler()), DropoutLayer<nothing>(Dense(σ = NNlib.tanh_fast, W = (1024, 1024), b = true)), Dense(W = (1024, 3), b = true)))), Transformers.HuggingFace.HGFConfig{:roberta, JSON3.Object{Vector{UInt8}, Vector{UInt64}}, Dict{Symbol, Any}}(:use_cache => true, :torch_dtype => \"float32\", :vocab_size => 50265, :output_hidden_states => true, :hidden_act => \"gelu\", :num_hidden_layers => 24, :num_attention_heads => 16, :classifier_dropout => nothing, :type_vocab_size => 1, :intermediate_size => 4096…))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls = TrillionDollarWords.load_model(; output_hidden_states=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9badf647-2250-450d-95c5-e83f79117514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256-element Vector{String}:\n",
       " \"<s>\"\n",
       " \"rem\"\n",
       " \"ained\"\n",
       " \" well\"\n",
       " \" below\"\n",
       " \" their\"\n",
       " \" levels\"\n",
       " \" at\"\n",
       " \" the\"\n",
       " \" beginning\"\n",
       " \" of\"\n",
       " \" the\"\n",
       " \" year\"\n",
       " ⋮\n",
       " \"<pad>\"\n",
       " \"<pad>\"\n",
       " \"<pad>\"\n",
       " \"<pad>\"\n",
       " \"<pad>\"\n",
       " \"<pad>\"\n",
       " \"<pad>\"\n",
       " \"<pad>\"\n",
       " \"<pad>\"\n",
       " \"<pad>\"\n",
       " \"<pad>\"\n",
       " \"<pad>\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toks = decode(cls.tkr, encode(cls.tkr, texts[1, :].sentence).token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c4729b8-962e-447d-8219-4696ed9b9a2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "merge_truncated_tokens (generic function with 2 methods)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded = Vector{Char}()\n",
    "for token in toks\n",
    "    token = string(token)\n",
    "    if startswith(token, \"<\")\n",
    "        continue\n",
    "    else\n",
    "        if startswith(token, \" \")\n",
    "            append!(decoded, token)\n",
    "        else\n",
    "            if length(decoded) == 0\n",
    "                append!(decoded, token)\n",
    "            else\n",
    "                last = pop!(decoded)\n",
    "                new_token = last * token\n",
    "                append!(decoded, new_token)\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9c6a175-ffa9-47a4-818a-04ec2b6445aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"remained well below their levels at the beginning of the year, and that weaker demand and earlier declines in oil prices had been holding down consumer price inflation.\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "String(decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1faeb671-dead-4ba1-867f-39eaf990a507",
   "metadata": {},
   "source": [
    "### Fill in masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a596f684-1b82-4823-987b-adc633545977",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_enc = hgf\"bert-base-uncased:tokenizer\"\n",
    "bert_model = hgf\"bert-base-uncased:ForMaskedLM\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ff831709-34d2-4823-9b6d-021a61eaf132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(hidden_state = Float32[0.019434169 -0.006751724 … -0.3122035 0.96587026; 0.28009748 0.6731811 … 0.13828917 0.39761153; … ; -0.123422645 -0.15654448 … 0.09904317 -0.6344952; -0.05732409 -0.19550925 … 0.006869527 -0.23544282;;; -0.33048484 -0.22132668 … -0.24672607 -0.2684891; 0.046722244 -0.2989306 … 0.27542412 0.28430456; … ; 0.08061004 -0.17982382 … 0.35699606 0.35447824; 0.06478204 0.4334174 … 0.28634638 0.2961332], attention_mask = NeuralAttentionlib.LengthMask{1, Vector{Int32}}(Int32[11, 9]), logit = Float32[-6.646805 -11.58166 … -11.6885395 -12.899181; -6.594739 -11.566789 … -11.892482 -12.609668; … ; -5.804957 -10.092522 … -10.914755 -10.116999; -3.9648962 -9.437453 … -4.6001024 -10.999382;;; -6.8107824 -10.228295 … -6.8980503 -6.914237; -6.7649107 -10.272557 … -7.056045 -7.0753527; … ; -5.953972 -7.588567 … -6.2830176 -6.3007765; -3.8673246 -5.0237412 … -3.1228065 -3.1453354])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = bert_model(encode(bert_enc, [\"hello [MASK] world [MASK] [MASK] and my [MASK]!\", \"bonjour mes [MASK].\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a1a1381f-a69f-47dd-ad61-8609f1103bbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11×2 Matrix{String}:\n",
       " \".\"        \".\"\n",
       " \"hello\"    \"bon\"\n",
       " \",\"        \"##jou\"\n",
       " \"world\"    \"##s\"\n",
       " \",\"        \"me\"\n",
       " \"me\"       \"##s\"\n",
       " \"and\"      \"##nant\"\n",
       " \"my\"       \".\"\n",
       " \"friends\"  \".\"\n",
       " \"!\"        \"de\"\n",
       " \".\"        \"de\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = decode(bert_enc, out.logit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b014982f-8df6-4f10-b675-b60822dcfea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "merge_truncated_words (generic function with 4 methods)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function merge_truncated_words(tokens, in_word=\"##\", between_word=\"\", separators=[\".\", \"de\"])\n",
    "    decoded = Vector{Char}()\n",
    "    for token in tokens\n",
    "        token = string(token)\n",
    "        if token in separators\n",
    "            continue\n",
    "        else\n",
    "            if startswith(token, in_word)\n",
    "                if length(decoded) == 0\n",
    "                    append!(decoded, token)\n",
    "                else\n",
    "                    last = pop!(decoded)\n",
    "                    new_token = last * chop(token, head=2, tail=0)\n",
    "                    append!(decoded, new_token)\n",
    "                end\n",
    "            else\n",
    "                append!(decoded, \" \" * token)\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return decoded\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8adb05cb-84f0-4b14-a74b-1cfec686280a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" hello , world , me and my friends ! bonjous mesnant\""
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "String(merge_truncated_words(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d8ee90-b306-4237-a76f-dab338639c96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.2",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
