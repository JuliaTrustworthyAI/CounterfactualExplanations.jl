<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Latent Space Search · CounterfactualExplanations.jl</title><script data-outdated-warner src="../../../assets/warner.js"></script><link rel="canonical" href="https://pat-alt.github.io/CounterfactualExplanations.jl/generators/gradient_based/latent_space_generator/"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../../assets/documenter.js"></script><script src="../../../siteinfo.js"></script><script src="../../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../../../">CounterfactualExplanations.jl</a></span></div><form class="docs-search" action="../../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../../">Home</a></li><li><a class="tocitem" href="../../../cats_dogs/">Motivating example</a></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../../../tutorials/">Overview</a></li><li><a class="tocitem" href="../../../tutorials/binary/">Binary target</a></li><li><a class="tocitem" href="../../../tutorials/models/">Custom models</a></li><li><a class="tocitem" href="../../../tutorials/multi/">Multi-class target</a></li><li><a class="tocitem" href="../../../tutorials/generators/">Custom generators</a></li><li><a class="tocitem" href="../../../tutorials/mutability/">Mutability constraints</a></li><li><a class="tocitem" href="../../../tutorials/interop/">Interoperability</a></li></ul></li><li><span class="tocitem">Counterfactual Generators</span><ul><li class="is-active"><a class="tocitem" href>Latent Space Search</a><ul class="internal"><li><a class="tocitem" href="#Synthetic-data"><span>Synthetic data</span></a></li><li><a class="tocitem" href="#MNIST-data"><span>MNIST data</span></a></li><li><a class="tocitem" href="#References"><span>References</span></a></li></ul></li><li><a class="tocitem" href="../dice/">Diverse Counterfactuals</a></li></ul></li><li><span class="tocitem">More examples</span><ul><li><input class="collapse-toggle" id="menuitem-5-1" type="checkbox"/><label class="tocitem" for="menuitem-5-1"><span class="docs-label">Image data</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../../examples/image/MNIST/">MNIST</a></li></ul></li></ul></li><li><span class="tocitem">Contributor&#39;s Guide</span><ul><li><a class="tocitem" href="../../../contributing/">Overview</a></li><li><a class="tocitem" href="../../../contributing/interop/">Interoperability</a></li><li><a class="tocitem" href="../../../contributing/loss/">Loss functions</a></li></ul></li><li><a class="tocitem" href="../../../reference/">Reference</a></li><li><a class="tocitem" href="../../../resources/resources/">Additional Resources</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Counterfactual Generators</a></li><li class="is-active"><a href>Latent Space Search</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Latent Space Search</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/pat-alt/CounterfactualExplanations.jl/blob/main/docs/src/generators/gradient_based/latent_space_generator.md#" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Latent-Space-Search"><a class="docs-heading-anchor" href="#Latent-Space-Search">Latent Space Search</a><a id="Latent-Space-Search-1"></a><a class="docs-heading-anchor-permalink" href="#Latent-Space-Search" title="Permalink"></a></h1><p>The current consensus in the literature is that Counterfactual Explanations should realistic: the generated counterfactuals should look like they were generated by the data generating process (DGP) that governs the problem at hand. With respect to Algorithmic Recourse it is certainly true that counterfactuals should be realistic in order to be actionable for individuals.[1] To address this need, researchers have come up with various different approaches in recent years. Among the most popular approaches is <strong>Latent Space Search</strong>, which was first proposed in Joshi et al. (2019): instead of traversing the feature space directly, this approach relies on a separate generative model that learns a latent space representation of the DGP. Assuming the generative model is well-specified, access to the learned latent embeddings of the data comes with two <strong>advantages</strong>:</p><ol><li>Since the learned DGP is encoded in the latent space, the generated counterfactuals will respect the learned representation of the data. In practice this means that counterfactuals will be realistic.</li><li>The latent space is typically a compressed (i.e. lower dimensional) version of the feature space. This makes the counterfactual search less costly.</li></ol><p>There are also certain <strong>disadvantages</strong> though:</p><ol><li>Learning generative models is (typically) an expensive task, which may well outweigh the benefits associated with utlimately traversing a lower dimensional space.</li><li>If the generative model is poorly specified, this will affect the quality of the counterfactuals.[2]</li></ol><p>Anyway, traversing latent embeddings is a powerful idea that may be very useful depending on the specific context. This tutorial introduces the concept and how it is implemented in this package.</p><h2 id="Synthetic-data"><a class="docs-heading-anchor" href="#Synthetic-data">Synthetic data</a><a id="Synthetic-data-1"></a><a class="docs-heading-anchor-permalink" href="#Synthetic-data" title="Permalink"></a></h2><p>We start by looking at synthetic data.</p><h3 id="D-Example"><a class="docs-heading-anchor" href="#D-Example">2D Example</a><a id="D-Example-1"></a><a class="docs-heading-anchor-permalink" href="#D-Example" title="Permalink"></a></h3><p>The first few code snippets below generate the synthetic data, set up a simple neural network in Flux and train it for the binary classification task.</p><pre><code class="language-julia hljs">using CounterfactualExplanations
using Random
input_dim = 2
n = 100
η = 3
μ₀ = rand(-input_dim:input_dim,input_dim) .* η
μ₁ = rand(-input_dim:input_dim,input_dim) .* η
X₀ = μ₀ .+ randn(input_dim, n) 
X₁ = μ₁ .+ randn(input_dim, n) 
X = hcat(X₀, X₁)
using MLUtils
xs = MLUtils.unstack(X,dims=2)
ys = hcat(zeros(1,n), ones(1,n))</code></pre><pre><code class="language-julia hljs">using Flux
n_hidden = 50
nn = Chain(
    Dense(input_dim, n_hidden, relu),
    Dense(n_hidden, 1)
)  
loss(x, y) = Flux.Losses.logitbinarycrossentropy(nn(x), y)
data = zip(xs,ys)</code></pre><pre><code class="language-julia hljs">using Flux.Optimise: update!, ADAM
opt = ADAM()
epochs = 100
using Statistics: mean
avg_loss(data) = mean(map(d -&gt; loss(d[1],d[2]), data))
show_every = epochs/10

for epoch = 1:epochs
  for d in data
    gs = gradient(Flux.params(nn)) do
      l = loss(d...)
    end
    update!(opt, Flux.params(nn), gs)
  end
  if epoch % show_every == 0
    println(&quot;Epoch &quot; * string(epoch))
    @show avg_loss(data)
  end
end

M = FluxModel(nn)</code></pre><p>We then draw a random factual and generate two counterfactuals - one using generic search in the feature space and one using generic search in the latent space. The default generative model - a Variational Autoencoder (VAE) - is set up and trained under the hood. The resulting counterfactual paths are shown in the animation below: note how latent space search results in faster convergence to an optimum that sits right within the cluster of samples in the target class. For generic search in the feature space we instead end up just crossing the decision boundary before converging.</p><pre><code class="language-julia hljs">counterfactual_data = CounterfactualData(X,ys)
using Random
# Random.seed!(123)
x = select_factual(counterfactual_data, rand(1:size(X)[2])) 
y = round(probs(M, x)[1])
target = ifelse(y==1.0,0.0,1.0) # opposite label as target</code></pre><pre><code class="language-julia hljs"># Define generator:
generator = GenericGenerator()
# Generate recourse:
counterfactual = generate_counterfactual(x, target, counterfactual_data, M, generator, latent_space=false)
counterfactual_latent = generate_counterfactual(x, target, counterfactual_data, M, generator, latent_space=true)</code></pre><p><img src="../../www/latent_2d.gif" alt="Counterfactuals generated through generic search in feature space (left) and latent space (right)."/></p><h3 id="D-Example-2"><a class="docs-heading-anchor" href="#D-Example-2">3D Example</a><a class="docs-heading-anchor-permalink" href="#D-Example-2" title="Permalink"></a></h3><p>This second example is largely analogous to what we just saw above. The figure below demonstrates the idea of searching counterfactuals in a lower dimensional latent space.</p><pre><code class="language-julia hljs">using CounterfactualExplanations
using Random
input_dim = 3
n = 100
η = 3
μ₀ = rand(-input_dim:input_dim,input_dim) .* η
μ₁ = rand(-input_dim:input_dim,input_dim) .* η
X₀ = μ₀ .+ randn(input_dim, n) 
X₁ = μ₁ .+ randn(input_dim, n) 
X = hcat(X₀, X₁)
using MLUtils
xs = MLUtils.unstack(X,dims=2)
ys = hcat(zeros(1,n), ones(1,n))</code></pre><pre><code class="language-julia hljs">using Flux
n_hidden = 50
nn = Chain(
    Dense(input_dim, n_hidden, relu),
    Dense(n_hidden, 1)
)  
loss(x, y) = Flux.Losses.logitbinarycrossentropy(nn(x), y)
data = zip(xs,ys)</code></pre><pre><code class="language-julia hljs">using Flux.Optimise: update!, ADAM
opt = ADAM()
epochs = 100
using Statistics: mean
avg_loss(data) = mean(map(d -&gt; loss(d[1],d[2]), data))
show_every = epochs/10

for epoch = 1:epochs
  for d in data
    gs = gradient(Flux.params(nn)) do
      l = loss(d...)
    end
    update!(opt, Flux.params(nn), gs)
  end
  if epoch % show_every == 0
    println(&quot;Epoch &quot; * string(epoch))
    @show avg_loss(data)
  end
end

M = FluxModel(nn)</code></pre><pre><code class="language-julia hljs">counterfactual_data = CounterfactualData(X,ys)</code></pre><pre><code class="language-julia hljs">using Random
Random.seed!(123)
x = select_factual(counterfactual_data, rand(1:size(X)[2])) 
y = round(probs(M, x)[1])
target = ifelse(y==1.0,0.0,1.0) # opposite label as target</code></pre><pre><code class="language-julia hljs"># Define generator:
generator = GenericGenerator()
# Generate recourse:
counterfactual = generate_counterfactual(x, target, counterfactual_data, M, generator, latent_space=true)</code></pre><p><img src="../../www/example_3d.png" alt/></p><h2 id="MNIST-data"><a class="docs-heading-anchor" href="#MNIST-data">MNIST data</a><a id="MNIST-data-1"></a><a class="docs-heading-anchor-permalink" href="#MNIST-data" title="Permalink"></a></h2><p>Finally, let’s take the ideas introduced above to a more complex example. We first load the MNIST data and a simple pre-trained neural network. The test set accuracy is shown below.</p><pre><code class="language-julia hljs">using Flux
using CounterfactualExplanations.Data: mnist_data, mnist_model
X, ys = mnist_data()
model = mnist_model()
ensemble = mnist_ensemble()
M = FluxModel(model, likelihood=:classification_multi)</code></pre><pre><code class="language-julia hljs">using MLDatasets
data_test = MNIST(:test)
test_x, test_y = data_test[:]
ys_test = Flux.onehotbatch(test_y, 0:9)
X_test = Flux.flatten(test_x)
bs = Int(round(size(X)[2]/10))
data_test = DataLoader((X_test,ys_test),batchsize=bs)
accuracy(data) = mean(map(d -&gt; mean(Flux.onecold(Flux.softmax(model(d[1])), 0:9) .== Flux.onecold(d[2], 0:9)), data))
accuracy(data_test)</code></pre><h3 id="Training-the-VAE"><a class="docs-heading-anchor" href="#Training-the-VAE">Training the VAE</a><a id="Training-the-VAE-1"></a><a class="docs-heading-anchor-permalink" href="#Training-the-VAE" title="Permalink"></a></h3><p>Here we show how a custom generative model can be trained …</p><pre><code class="language-julia hljs">input_dim = size(X)[1]
using CounterfactualExplanations.GenerativeModels: VAE, train!
vae = VAE(input_dim; nll=Flux.logitbinarycrossentropy, epochs=100, λ=0.0001, latent_dim=28)
train!(vae, X, ys)
using BSON: @save
@save joinpath(www_path, &quot;vae.bson&quot;) vae</code></pre><pre><code class="language-julia hljs">draw_mnist(i) = reshape(X[:,rand(findall(Flux.onecold(ys,0:9).==i))],input_dim,1)
reconstruct_mnist(x) = σ.(CounterfactualExplanations.GenerativeModels.reconstruct(vae,x)[1]) reshape_mnist(x) = reshape(x,28,28)
plt_list = []
for i in 0:9
  x = draw_mnist(i)
  x_rec = reconstruct_mnist(x)
  img = plot(convert2image(MNIST,reshape_mnist(x)), title=&quot;Original&quot;, axis=nothing)
  img_rec = plot(convert2image(MNIST,reshape_mnist(x_rec)), title=&quot;Rec&quot;, axis=nothing)
  plt = plot(img, img_rec)
  plt_list = vcat(plt_list, plt)
end
plt = plot(plt_list..., layout=(10,1), size=(200,1000))
savefig(plt, joinpath(www_path, &quot;vae_reconstruct.png&quot;))</code></pre><p>… and supplied to an instance of type <code>CounterfactualData</code>. The figure below shows randomly selected MNIST images (left) and their reconstructions (right).</p><pre><code class="language-julia hljs">counterfactual_data = CounterfactualData(X,ys)
counterfactual_data.generative_model = vae # assign generative model</code></pre><p><img src="../../www/vae_reconstruct.png" alt="Randomly selected MNIST images (left) and their reconstructions (right)."/></p><h3 id="Counterfactual-search"><a class="docs-heading-anchor" href="#Counterfactual-search">Counterfactual search</a><a id="Counterfactual-search-1"></a><a class="docs-heading-anchor-permalink" href="#Counterfactual-search" title="Permalink"></a></h3><p>Since the image reconstructions are decent, we can expect the counterfactual search through the latent embedding to yield realistic counterfactuals. Below we put this to the test: we select a random nine (9) and use generic search in the latent space to generate a four (4). Note, that we have set the threshold probability to 90% and we have chosen not to penalize the distance of the counterfactual from its factual. The result shown in the figure below is convincing.</p><pre><code class="language-julia hljs"># Randomly selected factual:
factual = 10
using Random
Random.seed!(1234)
x = reshape(X[:,rand(findall(Flux.onecold(ys,1:10).==factual))],input_dim,1)
target = 5
γ = 0.90</code></pre><pre><code class="language-julia hljs"># Define generator:
generator = GenericGenerator(;ϵ=1.0,λ=0.0)
# Generate recourse:
counterfactual = generate_counterfactual(x, target, counterfactual_data, M, generator, latent_space=true, γ=γ)</code></pre><pre><code class="language-julia hljs">p1 = plot(convert2image(MNIST, reshape(x,28,28)),axis=nothing, title=&quot;Factual&quot;)
target_prob = round(target_probs(counterfactual)[1],digits=2)
ŷ = CounterfactualExplanations.Counterfactuals.counterfactual_label(counterfactual)[1]-1
p2 = plot(
  convert2image(MNIST, reshape(counterfactual.f(counterfactual.s′),28,28)),
  axis=nothing,title=&quot;ŷ=$(ŷ); p̂(y=$(target-1))=$(target_prob)&quot;
)
plt = plot(p1,p2,size=(500,200))
savefig(plt, joinpath(www_path, &quot;mnist_$(factual-1)to$(target-1)_latent.png&quot;))</code></pre><pre><code class="language-julia hljs"># Generate recourse:
counterfactual = generate_counterfactual(x, target, counterfactual_data, M, generator, latent_space=false, γ=0.95)</code></pre><pre><code class="language-julia hljs">p1 = plot(convert2image(MNIST, reshape(x,28,28)),axis=nothing, title=&quot;Factual&quot;)
target_prob = round(target_probs(counterfactual)[1],digits=2)
ŷ = CounterfactualExplanations.Counterfactuals.counterfactual_label(counterfactual)[1]-1
p2 = plot(
  convert2image(MNIST, reshape(counterfactual.f(counterfactual.s′),28,28)),
  axis=nothing,title=&quot;ŷ=$(ŷ); p̂(y=$(target-1))=$(target_prob)&quot;
)
plt = plot(p1,p2,size=(500,200))
savefig(plt, joinpath(www_path, &quot;mnist_$(factual-1)to$(target-1)_wachter.png&quot;))</code></pre><p><img src="../../www/mnist_9to4_latent.png" alt/></p><h2 id="References"><a class="docs-heading-anchor" href="#References">References</a><a id="References-1"></a><a class="docs-heading-anchor-permalink" href="#References" title="Permalink"></a></h2><p>Joshi, Shalmali, Oluwasanmi Koyejo, Warut Vijitbenjaronk, Been Kim, and Joydeep Ghosh. 2019. “Towards Realistic Individual Recourse and Actionable Explanations in Black-Box Decision Making Systems.” <em>arXiv Preprint arXiv:1907.09615</em>.</p><p>[1] In general, we believe that there may be a trade-off between creating counterfactuals that respect the DGP vs. counterfactuals reflect the behaviour of the black-model in question - both accurately and complete.</p><p>[2] We believe that there is another potentially crucial disadvantage of relying on a separate generative model: it reallocates the task of learning realisitic explanations for the data from the black-box model to the generative model.</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../../../tutorials/interop/">« Interoperability</a><a class="docs-footer-nextpage" href="../dice/">Diverse Counterfactuals »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.23 on <span class="colophon-date" title="Thursday 22 September 2022 14:38">Thursday 22 September 2022</span>. Using Julia version 1.8.1.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
