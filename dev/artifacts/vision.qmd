# Vision Data and Models

```{julia}
#| echo: false
include("$(pwd())/dev/artifacts/setup.jl")
eval(setup)
www_path = www_dir("vision")
data_path = data_dir("vision")
model_path = model_dir("vision")
www_name = "www-vision"
data_name = "data-vision"
model_name = "model-vision"
```

## MNIST 

```{julia}
counterfactual_data = load_mnist()
X = counterfactual_data.X
y = counterfactual_data.output_encoder.y  
input_dim, n_obs = size(X)
```

### Classifiers

```{julia}
flux_training_params.batchsize = Int(round(n_obs/10))
flux_training_params.verbose = true
M = fit_model(counterfactual_data, :MLP, n_hidden=32)
M_ens = fit_model(counterfactual_data, :DeepEnsemble, n_hidden=32)
CounterfactualExplanations.reset!(flux_training_params)
```

```{julia}
test_data = load_mnist_test()
println("MLP test score (F1): $(model_evaluation(M, test_data))")
println("Deep Ensemble test score (F1): $(model_evaluation(M_ens, test_data))")
```

```{julia}
Serialization.serialize(joinpath(model_path,"mnist_mlp.jls"),M)
Serialization.serialize(joinpath(model_path,"mnist_ensemble.jls"),M_ens)
```

### Generative Model

```{julia}
using CounterfactualExplanations.GenerativeModels: VAE, train!
vae = VAE(input_dim; nll=Flux.Losses.mse, epochs=100, λ=0.0001, latent_dim=28, hidden_dim=50)
flux_training_params.verbose = true
train!(vae, X, y)
Serialization.serialize(joinpath(model_path,"mnist_vae_strong.jls"),vae)
```

```{julia}
using CounterfactualExplanations.GenerativeModels: reconstruct
images = []
rec_images = []
for i in 0:9
    j = 0
    while j < 10
        x = X[:,rand(findall(y .== i))]
        x̂ = reconstruct(vae, x)[1] |> 
            x̂ -> clamp.((x̂ .+ 1.0) ./ 2.0, 0.0, 1.0) |>
            x̂ -> reshape(x̂, 28,28) |>
            x̂ -> convert2image(MNIST, x̂)
        x = clamp.((x .+ 1.0) ./ 2.0, 0.0, 1.0) |> 
            x -> reshape(x, 28,28) |>
            x -> convert2image(MNIST, x)
        push!(images, x)
        push!(rec_images, x̂)
        j += 1
    end
end
p1 = plot(mosaic(images..., ncol=10), title="Images")
p2 = plot(mosaic(rec_images..., ncol=10), title="Reconstructions")
plt = plot(p1, p2, axis=false, size=(800,375))
savefig(plt, joinpath(www_path, "mnist_vae_strong.png"))
```

```{julia}
vae = VAE(input_dim; nll=Flux.Losses.mse, epochs=100, λ=0.05, latent_dim=2, hidden_dim=5)
flux_training_params.verbose = true
train!(vae, X, y)
Serialization.serialize(joinpath(model_path,"mnist_vae_weak.jls"),vae)
```

```{julia}
using CounterfactualExplanations.GenerativeModels: reconstruct
images = []
rec_images = []
for i in 0:9
    j = 0
    while j < 10
        x = X[:,rand(findall(y .== i))]
        x̂ = reconstruct(vae, x)[1] |> 
            x̂ -> clamp.((x̂ .+ 1.0) ./ 2.0, 0.0, 1.0) |>
            x̂ -> reshape(x̂, 28,28) |>
            x̂ -> convert2image(MNIST, x̂)
        x = clamp.((x .+ 1.0) ./ 2.0, 0.0, 1.0) |> 
            x -> reshape(x, 28,28) |>
            x -> convert2image(MNIST, x)
        push!(images, x)
        push!(rec_images, x̂)
        j += 1
    end
end
p1 = plot(mosaic(images..., ncol=10), title="Images")
p2 = plot(mosaic(rec_images..., ncol=10), title="Reconstructions")
plt = plot(p1, p2, axis=false, size=(800,375))
savefig(plt, joinpath(www_path, "mnist_vae_weak.png"))
```

## FashionMNIST 

```{julia}
counterfactual_data = load_fashion_mnist()
X = counterfactual_data.X
y = counterfactual_data.output_encoder.y  
input_dim, n_obs = size(X)
```

```{julia}
images = []
for i in 0:9
    j = 0
    while j < 10
        x = X[:,rand(findall(y .== i))]
        x = clamp.((x .+ 1.0) ./ 2.0, 0.0, 1.0) |> 
            x -> reshape(x, 28,28) |>
            x -> convert2image(FashionMNIST, x)
        push!(images, x)
        j += 1
    end
end
mosaic(images..., ncol=10) |> display
```

### Classifiers

```{julia}
flux_training_params.batchsize = Int(round(n_obs/10))
flux_training_params.verbose = true
M = fit_model(counterfactual_data, :MLP, n_hidden=64)
M_ens = fit_model(counterfactual_data, :DeepEnsemble, n_hidden=64)
CounterfactualExplanations.reset!(flux_training_params)
```

```{julia}
test_data = load_fashion_mnist_test()
println("MLP test score (F1): $(model_evaluation(M, test_data)[1])")
println("Deep Ensemble test score (F1): $(model_evaluation(M_ens, test_data)[1])")
```

```{julia}
Serialization.serialize(joinpath(model_path,"fashion_mnist_mlp.jls"),M)
Serialization.serialize(joinpath(model_path,"fashion_mnist_ensemble.jls"),M_ens)
```

### Generative Model

```{julia}
using CounterfactualExplanations.GenerativeModels: VAE, train!
vae = VAE(input_dim; nll=Flux.Losses.mse, epochs=100, λ=0.0001, latent_dim=32, hidden_dim=64)
flux_training_params.verbose = true
train!(vae, X, y)
Serialization.serialize(joinpath(model_path,"fashion_mnist_vae_strong.jls"),vae)
```

```{julia}
using CounterfactualExplanations.GenerativeModels: reconstruct
rec_images = []
for i in 0:9
    j = 0
    while j < 10
        x = X[:,rand(findall(y .== i))]
        x̂ = reconstruct(vae, x)[1] |> 
            x̂ -> clamp.((x̂ .+ 1.0) ./ 2.0, 0.0, 1.0) |>
            x̂ -> reshape(x̂, 28,28) |>
            x̂ -> convert2image(FashionMNIST, x̂)
        push!(rec_images, x̂)
        j += 1
    end
end
p1 = plot(mosaic(images..., ncol=10), title="Images")
p2 = plot(mosaic(rec_images..., ncol=10), title="Reconstructions")
plt = plot(p1, p2, axis=false, size=(800,375))
savefig(plt, joinpath(www_path, "fashion_mnist_vae_strong.png"))
```

```{julia}
vae = VAE(input_dim; nll=Flux.Losses.mse, epochs=100, λ=0.05, latent_dim=2, hidden_dim=10)
flux_training_params.verbose = true
train!(vae, X, y)
Serialization.serialize(joinpath(model_path,"fashion_mnist_vae_weak.jls"),vae)
```

```{julia}
using CounterfactualExplanations.GenerativeModels: reconstruct
rec_images = []
for i in 0:9
    j = 0
    while j < 10
        x = X[:,rand(findall(y .== i))]
        x̂ = reconstruct(vae, x)[1] |> 
            x̂ -> clamp.((x̂ .+ 1.0) ./ 2.0, 0.0, 1.0) |>
            x̂ -> reshape(x̂, 28,28) |>
            x̂ -> convert2image(FashionMNIST, x̂)
        push!(rec_images, x̂)
        j += 1
    end
end
p1 = plot(mosaic(images..., ncol=10), title="Images")
p2 = plot(mosaic(rec_images..., ncol=10), title="Reconstructions")
plt = plot(p1, p2, axis=false, size=(800,375))
savefig(plt, joinpath(www_path, "fashion_mnist_vae_weak.png"))
```

## Generate Artifacts

```{julia}
artifact_name = "$(model_name)-$(Int(VERSION.major)).$(Int(VERSION.minor))"
generate_artifacts(model_path; artifact_name=artifact_name)
```

## CIFAR 10

```{julia}
counterfactual_data = load_cifar_10()
X = counterfactual_data.X
y = counterfactual_data.output_encoder.y  
input_dim, n_obs = size(X)
```
```{julia}
images = []

for i in 0:9
    for j in 0:9
        x = X[:,rand(findall(y .== i))]
        # println(size(x, 1))
        x = clamp.((x .+ 1.0) ./ 2.0, 0.0, 1.0) |>
            x -> reshape(x, 32, 32, 3) |>
            x -> convert2image(CIFAR10, x)
        push!(images, x)
    end
end

mosaic(images..., ncol=10) |> display
```

### Classifiers

```{julia}
flux_training_params.batchsize = Int(round(n_obs/10))
flux_training_params.verbose = true
M = fit_model(counterfactual_data, :MLP, n_hidden=64)
M_ens = fit_model(counterfactual_data, :DeepEnsemble, n_hidden=64)
CounterfactualExplanations.reset!(flux_training_params)
```

```{julia}
test_data = load_cifar_10_test()
println("MLP test score (F1): $(model_evaluation(M, test_data)[1])")
println("Deep Ensemble test score (F1): $(model_evaluation(M_ens, test_data)[1])")
```

```{julia}
Serialization.serialize(joinpath(model_path,"cifar_10_mlp.jls"),M)
Serialization.serialize(joinpath(model_path,"cifar_10_ensemble.jls"),M_ens)
```

### Generative Model

```{julia}
using CounterfactualExplanations.GenerativeModels: VAE, train!

vae = VAE(input_dim; nll=Flux.Losses.mse, epochs=100, λ=0.0001, latent_dim=32, hidden_dim=64)
flux_training_params.verbose = true
train!(vae, X, y)
Serialization.serialize(joinpath(model_path,"cifar_10_vae_strong.jls"),vae)
```

```{julia}
using CounterfactualExplanations.GenerativeModels: reconstruct
rec_images = []
for i in 0:9
    j = 0
    while j < 10
        x = X[:,rand(findall(y .== i))]
        x̂ = reconstruct(vae, x)[1] |> 
            x̂ -> clamp.((x̂ .+ 1.0) ./ 2.0, 0.0, 1.0) |>
            x̂ -> reshape(x̂, 32, 32, 3) |>
            x̂ -> convert2image(CIFAR10, x̂)
        push!(rec_images, x̂)
        j += 1
    end
end
p1 = plot(mosaic(images..., ncol=10), title="Images")
p2 = plot(mosaic(rec_images..., ncol=10), title="Reconstructions")
plt = plot(p1, p2, axis=false, size=(800,375))
savefig(plt, joinpath(www_path, "cifar_10_vae_strong.png"))
```

```{julia}
vae = VAE(input_dim; nll=Flux.Losses.mse, epochs=100, λ=0.05, latent_dim=2, hidden_dim=10)
flux_training_params.verbose = true
train!(vae, X, y)
Serialization.serialize(joinpath(model_path,"cifar_10_vae_weak.jls"),vae)
```

```{julia}
using CounterfactualExplanations.GenerativeModels: reconstruct
rec_images = []
for i in 0:9
    for j in 0:9
        x = X[:,rand(findall(y .== i))]
        x̂ = reconstruct(vae, x)[1] |> 
            x̂ -> clamp.((x̂ .+ 1.0) ./ 2.0, 0.0, 1.0) |>
            x̂ -> reshape(x̂, 32, 32, 3) |>
            x̂ -> convert2image(CIFAR10, x̂)
        push!(rec_images, x̂)
    end
end
p1 = plot(mosaic(images..., ncol=10), title="Images")
p2 = plot(mosaic(rec_images..., ncol=10), title="Reconstructions")
plt = plot(p1, p2, axis=false, size=(800,375))
savefig(plt, joinpath(www_path, "cifar_10_vae_weak.png"))
```